{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LT0yi6wj6C-V",
        "FAYrUJtiBcNu",
        "gEdnjPOACGi8",
        "A5sKAHS7DfcP"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "fast and light are 2 libs.   \n",
        "fast has more advanced architecture, and sota models to download (training problem with amp).   \n",
        "light has simpler training (trained models urls are available from gdown)  \n",
        "need to install only one lib (note different data transorms)"
      ],
      "metadata": {
        "id": "v4wwlt0EDgVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install lightreid"
      ],
      "metadata": {
        "id": "LT0yi6wj6C-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1cVQV2mMIjkoySs7rwdlDgwNOpMwf4IVq\n",
        "!unzip light-reid-final.zip"
      ],
      "metadata": {
        "id": "ITL54k4LHx8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd light-reid\n",
        "!pip install -r requirements\n",
        "!pip install -U PyYAML\n",
        "!pip install nvitop\n",
        "!pip install torchsummary"
      ],
      "metadata": {
        "id": "6Rl_5IpP6Mfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../"
      ],
      "metadata": {
        "id": "9TOv4InYJ5f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19da6575-7e65-407b-ce1d-b1590ad4195e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install fastreid"
      ],
      "metadata": {
        "id": "FAYrUJtiBcNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JDAI-CV/fast-reid"
      ],
      "metadata": {
        "id": "oJusg5flBzcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88128b6f-9cfb-4537-e71b-5f86ea95bd16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fast-reid'...\n",
            "remote: Enumerating objects: 5908, done.\u001b[K\n",
            "remote: Counting objects: 100% (771/771), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 5908 (delta 651), reused 602 (delta 600), pack-reused 5137\u001b[K\n",
            "Receiving objects: 100% (5908/5908), 13.82 MiB | 11.30 MiB/s, done.\n",
            "Resolving deltas: 100% (3651/3651), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fast-reid\n",
        "!pip install -r docs/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnOPTUY-GXNt",
        "outputId": "25c68517-e9ab-4823-e520-6d9e812e8059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fast-reid\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 4)) (1.25.2)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 6)) (1.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 8)) (6.0.1)\n",
            "Collecting yacs (from -r docs/requirements.txt (line 9))\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 10)) (2.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 11)) (0.9.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 12)) (2.15.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 13)) (4.8.0.76)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from -r docs/requirements.txt (line 19)) (5.1.0)\n",
            "Collecting faiss-gpu (from -r docs/requirements.txt (line 20))\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r docs/requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r docs/requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r docs/requirements.txt (line 1)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r docs/requirements.txt (line 1)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r docs/requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r docs/requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r docs/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->-r docs/requirements.txt (line 5)) (0.2.13)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r docs/requirements.txt (line 7)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r docs/requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r docs/requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r docs/requirements.txt (line 12)) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r docs/requirements.txt (line 12)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r docs/requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r docs/requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r docs/requirements.txt (line 12)) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r docs/requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r docs/requirements.txt (line 12)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r docs/requirements.txt (line 12)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r docs/requirements.txt (line 12)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r docs/requirements.txt (line 12)) (3.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->-r docs/requirements.txt (line 19)) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->-r docs/requirements.txt (line 19)) (3.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown->-r docs/requirements.txt (line 19)) (4.66.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r docs/requirements.txt (line 12)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r docs/requirements.txt (line 12)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r docs/requirements.txt (line 12)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r docs/requirements.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r docs/requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r docs/requirements.txt (line 12)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r docs/requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r docs/requirements.txt (line 12)) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r docs/requirements.txt (line 12)) (2.1.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->-r docs/requirements.txt (line 19)) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r docs/requirements.txt (line 12)) (1.7.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r docs/requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r docs/requirements.txt (line 12)) (3.2.2)\n",
            "Installing collected packages: faiss-gpu, yacs\n",
            "Successfully installed faiss-gpu-1.7.2 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B0XSwiAIqRo",
        "outputId": "8b4d5542-e0ab-47a8-80d3-0e76461842ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def dataset"
      ],
      "metadata": {
        "id": "gEdnjPOACGi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from prettytable import PrettyTable\n",
        "import copy\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "jk2trN_9IeRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageSamples:\n",
        "\n",
        "    def __init__(self, data_path):\n",
        "\n",
        "        # paths of train, query and gallery\n",
        "        train_path = os.path.join(data_path, 'bounding_box_train/')\n",
        "        query_path = os.path.join(data_path, 'query/')\n",
        "        gallery_path = os.path.join(data_path, 'bounding_box_test/')\n",
        "\n",
        "        # load samples\n",
        "        self.train = self._load_samples(train_path)\n",
        "        self.query = self._load_samples(query_path)\n",
        "        self.gallery = self._load_samples(gallery_path)\n",
        "\n",
        "    def _load_samples(self, folder_dir):\n",
        "        '''return (img_path, identity_id, camera_id)'''\n",
        "        samples = []\n",
        "        for root_path, dirs, files_name in os.walk(folder_dir):\n",
        "            for file_name in files_name:\n",
        "                if '.jpg' in file_name:\n",
        "                    person_id, camera_id = self._analyse_file_name(file_name)\n",
        "                    samples.append([root_path+file_name, person_id, camera_id])\n",
        "        return samples\n",
        "\n",
        "    def _analyse_file_name(self, file_name):\n",
        "        '''\n",
        "        :param file_name: format like 0844_c3s2_107328_01.jpg\n",
        "        :return: 0844, 3\n",
        "        '''\n",
        "        split_list = file_name.replace('.jpg', '').replace('c', '').replace('s', '_').split('_')\n",
        "        person_id, camera_id = int(split_list[0]), int(split_list[1])\n",
        "        return person_id, camera_id\n",
        "\n",
        "    def stats(self):\n",
        "        '''show sample statistics'''\n",
        "        def analyze(samples):\n",
        "            if samples is None:\n",
        "                return None, None, None\n",
        "            pid_num = len(set([sample[1] for sample in samples]))\n",
        "            cid_num = len(set([sample[2] for sample in samples]))\n",
        "            sample_num = len(samples)\n",
        "            return sample_num, pid_num, cid_num\n",
        "\n",
        "        table = PrettyTable([self.__class__.__name__, 'images', 'identities', 'cameras', 'imgs/id', 'imgs/cam', 'imgs/id&cam'])\n",
        "        for key, val in [('train', self.train), ('query', self.query), ('gallery', self.gallery)]:\n",
        "            info = analyze(val)\n",
        "            key_str = str(key)\n",
        "            img_num, pid_num, cid_num = info\n",
        "            imgs_per_id = round(img_num / float(pid_num), 2) if img_num is not None else None\n",
        "            imgs_per_cam = round(img_num / float(cid_num), 2) if img_num is not None else None\n",
        "            imgs_per_idcam = round(img_num / float(pid_num) / float(cid_num), 2) if img_num is not None else None\n",
        "            table.add_row([str(key_str), str(info[0]), str(info[1]), str(info[2]),\n",
        "                               str(imgs_per_id), str(imgs_per_cam), str(imgs_per_idcam)])\n",
        "        print(table)"
      ],
      "metadata": {
        "id": "rz-IlAjcCAlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReIDDataset:\n",
        "\n",
        "    def __init__(self, samples, transform, to_255 = False, normalize = False):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "        self.to_255 = to_255\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = copy.deepcopy(self.samples[index])\n",
        "        sample[0] = self._loader(sample[0])\n",
        "\n",
        "        if self.transform is not None:\n",
        "            if self.to_255:  # some models require 0-255 as input\n",
        "                sample[0] = self.transform(sample[0])*255\n",
        "            else:\n",
        "                sample[0] = self.transform(sample[0])\n",
        "        sample[1] = np.array(sample[1])\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def _loader(self, img_path):\n",
        "        return Image.open(img_path).convert('RGB')"
      ],
      "metadata": {
        "id": "e81s409cC55X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load data"
      ],
      "metadata": {
        "id": "A5sKAHS7DfcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd ../"
      ],
      "metadata": {
        "id": "be-z5GndvvVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "Kb73uzyfE-8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1TWlJwtb7foJwA02oxnN1oh4EZaOq9fGT\n",
        "!unzip Market-1501-v15.09.15.zip -d \"dataset\""
      ],
      "metadata": {
        "id": "FDUGpkauI9tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = ImageSamples(\"dataset/Market-1501-v15.09.15\")\n",
        "samples.stats()"
      ],
      "metadata": {
        "id": "8j3vSRSbDplW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7288651e-e7e0-42ee-ebbe-e8b1be11e4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------+------------+---------+---------+----------+-------------+\n",
            "| ImageSamples | images | identities | cameras | imgs/id | imgs/cam | imgs/id&cam |\n",
            "+--------------+--------+------------+---------+---------+----------+-------------+\n",
            "|    train     | 12936  |    751     |    6    |  17.23  |  2156.0  |     2.87    |\n",
            "|    query     |  3368  |    750     |    6    |   4.49  |  561.33  |     0.75    |\n",
            "|   gallery    | 19732  |    752     |    6    |  26.24  | 3288.67  |     4.37    |\n",
            "+--------------+--------+------------+---------+---------+----------+-------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# light\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((256, 128), interpolation=3),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "#     ])\n",
        "# query_dataset = ReIDDataset(samples.query, transform, to_255=False)\n",
        "# gallery_dataset = ReIDDataset(samples.gallery, transform, to_255=False)"
      ],
      "metadata": {
        "id": "1NQzSSq_DFzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fast\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((384, 128), interpolation=3), #384\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "query_dataset = ReIDDataset(samples.query, transform, to_255=True)\n",
        "gallery_dataset = ReIDDataset(samples.gallery, transform, to_255=True)"
      ],
      "metadata": {
        "id": "DnfROrthaFb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# build model fast"
      ],
      "metadata": {
        "id": "mEj9Z9-WGGKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fast-reid"
      ],
      "metadata": {
        "id": "MdTuVXwxGHpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a821dd0-99d0-4963-93a4-1491536def84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fast-reid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('.')\n",
        "\n",
        "# from fastreid.engine import DefaultTrainer, default_argument_parser, default_setup, launch\n",
        "# from fastreid.utils.checkpoint import Checkpointer"
      ],
      "metadata": {
        "id": "QCpLvziLGqbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastreid.config import get_cfg\n",
        "from fastreid.engine import default_setup\n",
        "\n",
        "from fastreid.modeling.meta_arch import build_model as fast_build"
      ],
      "metadata": {
        "id": "h0oDArLTEycl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://github.com/JDAI-CV/fast-reid/releases/download/v0.1.1/market_mgn_R50-ibn.pth"
      ],
      "metadata": {
        "id": "yaq5AsnRGINN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/JDAI-CV/fast-reid/releases/download/v0.1.1/market_sbs_R50-ibn.pth"
      ],
      "metadata": {
        "id": "yf-E63eEzjON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f4e16b-f7fa-44c8-b18d-9da89d56189f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-31 07:57:14--  https://github.com/JDAI-CV/fast-reid/releases/download/v0.1.1/market_sbs_R50-ibn.pth\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/136302835/447ddc00-d27f-11ea-810e-78a672f4cfa2?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230531%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230531T075714Z&X-Amz-Expires=300&X-Amz-Signature=4268940340c53869635105c4a9b52866cef2a7d1990ecdbc44384bc477eebade&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=136302835&response-content-disposition=attachment%3B%20filename%3Dmarket_sbs_R50-ibn.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-05-31 07:57:14--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/136302835/447ddc00-d27f-11ea-810e-78a672f4cfa2?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230531%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230531T075714Z&X-Amz-Expires=300&X-Amz-Signature=4268940340c53869635105c4a9b52866cef2a7d1990ecdbc44384bc477eebade&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=136302835&response-content-disposition=attachment%3B%20filename%3Dmarket_sbs_R50-ibn.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 301378459 (287M) [application/octet-stream]\n",
            "Saving to: ‘market_sbs_R50-ibn.pth’\n",
            "\n",
            "market_sbs_R50-ibn. 100%[===================>] 287.42M  97.3MB/s    in 3.0s    \n",
            "\n",
            "2023-05-31 07:57:17 (97.3 MB/s) - ‘market_sbs_R50-ibn.pth’ saved [301378459/301378459]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download model weights from url\n",
        "!wget https://github.com/JDAI-CV/fast-reid/releases/download/v0.1.1/market_bot_R50.pth"
      ],
      "metadata": {
        "id": "LHAuBUkyA2kf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7baf087-416b-414e-8356-4203c28a2049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-31 06:54:33--  https://github.com/JDAI-CV/fast-reid/releases/download/v0.1.1/market_bot_R50.pth\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/136302835/db32a480-d24f-11ea-9661-7ab30b5343a0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230531%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230531T065434Z&X-Amz-Expires=300&X-Amz-Signature=311afdf0216a6eee376f6ba13de5bdb6fef5de742f8e238aee4be336dde748fc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=136302835&response-content-disposition=attachment%3B%20filename%3Dmarket_bot_R50.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-05-31 06:54:34--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/136302835/db32a480-d24f-11ea-9661-7ab30b5343a0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230531%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230531T065434Z&X-Amz-Expires=300&X-Amz-Signature=311afdf0216a6eee376f6ba13de5bdb6fef5de742f8e238aee4be336dde748fc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=136302835&response-content-disposition=attachment%3B%20filename%3Dmarket_bot_R50.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 300955418 (287M) [application/octet-stream]\n",
            "Saving to: ‘market_bot_R50.pth’\n",
            "\n",
            "market_bot_R50.pth  100%[===================>] 287.01M   145MB/s    in 2.0s    \n",
            "\n",
            "2023-05-31 06:54:36 (145 MB/s) - ‘market_bot_R50.pth’ saved [300955418/300955418]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/JDAI-CV/fast-reid/releases/download/v0.1.1/market_sbs_R50.pth"
      ],
      "metadata": {
        "id": "HP3OEnAlHpvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd1dfacd-8ac6-41c5-e382-78b724629dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-31 07:55:53--  https://github.com/JDAI-CV/fast-reid/releases/download/v0.1.1/market_sbs_R50.pth\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/136302835/81969e00-d280-11ea-9751-06e2e5191884?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230531%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230531T075554Z&X-Amz-Expires=300&X-Amz-Signature=4f28f911cf657200ef541fd19f1cbab006a6b830967b5c7a2c1ca34c131f1844&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=136302835&response-content-disposition=attachment%3B%20filename%3Dmarket_sbs_R50.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-05-31 07:55:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/136302835/81969e00-d280-11ea-9751-06e2e5191884?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230531%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230531T075554Z&X-Amz-Expires=300&X-Amz-Signature=4f28f911cf657200ef541fd19f1cbab006a6b830967b5c7a2c1ca34c131f1844&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=136302835&response-content-disposition=attachment%3B%20filename%3Dmarket_sbs_R50.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 301369536 (287M) [application/octet-stream]\n",
            "Saving to: ‘market_sbs_R50.pth’\n",
            "\n",
            "market_sbs_R50.pth  100%[===================>] 287.41M   170MB/s    in 1.7s    \n",
            "\n",
            "2023-05-31 07:55:55 (170 MB/s) - ‘market_sbs_R50.pth’ saved [301369536/301369536]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://github.com/JDAI-CV/fast-reid/releases/download/v0.1.1/market_sbs_R50-ibn.pth\n",
        "!wget https://github.com/JDAI-CV/fast-reid/releases/download/v0.1.1/market_bot_R50-ibn.pth"
      ],
      "metadata": {
        "id": "HVzMP9Y4Hvla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e58cd7-1a0a-4f2c-f6ae-108250fa85a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-31 07:48:33--  https://github.com/JDAI-CV/fast-reid/releases/download/v0.1.1/market_bot_R50-ibn.pth\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/136302835/c49b4600-d26d-11ea-8143-b41cac5bd0ab?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230531%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230531T074833Z&X-Amz-Expires=300&X-Amz-Signature=07249a7692846bee74d54544c5be69adb567196deea72551034bd870a2491b7f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=136302835&response-content-disposition=attachment%3B%20filename%3Dmarket_bot_R50-ibn.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-05-31 07:48:33--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/136302835/c49b4600-d26d-11ea-8143-b41cac5bd0ab?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230531%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230531T074833Z&X-Amz-Expires=300&X-Amz-Signature=07249a7692846bee74d54544c5be69adb567196deea72551034bd870a2491b7f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=136302835&response-content-disposition=attachment%3B%20filename%3Dmarket_bot_R50-ibn.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 300964341 (287M) [application/octet-stream]\n",
            "Saving to: ‘market_bot_R50-ibn.pth’\n",
            "\n",
            "market_bot_R50-ibn. 100%[===================>] 287.02M   177MB/s    in 1.6s    \n",
            "\n",
            "2023-05-31 07:48:35 (177 MB/s) - ‘market_bot_R50-ibn.pth’ saved [300964341/300964341]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"market_bot_R50\"\n",
        "# model_name = \"market_bot_R50-ibn\"\n",
        "# model_name = \"market_sbs_R50-ibn\"\n",
        "# model_name = \"market_sbs_R50\""
      ],
      "metadata": {
        "id": "tdzdaGxcEzgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build config\n",
        "class Args:\n",
        "    pass\n",
        "\n",
        "args = Args()\n",
        "args.config_file='configs/Market1501/bagtricks_R50.yml'\n",
        "# args.config_file='configs/Market1501/bagtricks_R50-ibn.yml'\n",
        "# args.config_file='configs/Market1501/sbs_R50-ibn.yml'\n",
        "# args.config_file='configs/Market1501/sbs_R50.yml'\n",
        "# args.config_file='configs/Market1501/sbs_R101-ibn.yml'\n",
        "# args.config_file= '/content/fast-reid/configs/Market1501/mgn_R50-ibn.yml'\n",
        "# args.config_file=  '/content/fast-reid/configs/Market1501/bagtricks_R101-ibn.yml'\n",
        "\n",
        "args.resume=False\n",
        "args.eval_only=True\n",
        "args.num_gpus=1\n",
        "args.num_machines=1\n",
        "args.machine_rank=0\n",
        "args.dist_url='tcp://127.0.0.1:49152'\n",
        "\n",
        "# args.opts=['MODEL.WEIGHTS', f'{model_name}.pth', 'MODEL.DEVICE', 'cuda:0']\n",
        "args.opts=['MODEL.WEIGHTS', f'{model_name}.pth', 'MODEL.DEVICE', 'cpu']\n",
        "# args.opts=['MODEL.WEIGHTS', 'market_bot_R50.pth', 'MODEL.DEVICE', 'cuda:0']\n",
        "# args.opts=['MODEL.WEIGHTS', 'market_sbs_R50-ibn.pth', 'MODEL.DEVICE', 'cuda:0']\n",
        "# args.opts=['MODEL.WEIGHTS', 'market_sbs_R50.pth', 'MODEL.DEVICE', 'cuda:0']\n",
        "\n",
        "def setup(args):\n",
        "    \"\"\"\n",
        "    Create configs and perform basic setups.\n",
        "    \"\"\"\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(args.config_file)\n",
        "    cfg.merge_from_list(args.opts)\n",
        "    cfg.freeze()\n",
        "    default_setup(cfg, args)\n",
        "    return cfg\n",
        "\n",
        "cfg = setup(args)\n",
        "cfg.defrost()\n",
        "cfg.MODEL.BACKBONE.PRETRAIN = False\n",
        "\n",
        "model = fast_build(cfg)"
      ],
      "metadata": {
        "id": "p9NeW454G2kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# load wieghts\n",
        "\n",
        "model_path = f\"/content/fast-reid/{model_name}.pth\"\n",
        "# model_path = f\"/content/fast-reid/configs/Market1501/bagtricks_R50-ibn.pth\"\n",
        "# model_path = \"/content/fast-reid/market_sbs_R50.pth\"\n",
        "# model_path = \"/content/market_sbs_R50-ibn.pth\"\n",
        "# model_path = \"/content/fast-reid/market_bot_R50.pth\"\n",
        "# state_dict = torch.load(model_path, map_location='cuda:0')['model']\n",
        "state_dict = torch.load(model_path, map_location='cpu')['model']\n",
        "\n",
        "# rename the keys in the state dictionary to match the keys in your new model\n",
        "renamed_state_dict = {}\n",
        "for key, value in state_dict.items():\n",
        "    if key.startswith('heads.bnneck'):\n",
        "        new_key = key.replace('heads.bnneck', 'heads.bottleneck.0')\n",
        "    else:\n",
        "        new_key = key\n",
        "    renamed_state_dict[new_key] = value\n",
        "\n",
        "# classifier not used for inference\n",
        "model.load_state_dict(renamed_state_dict, strict=False)"
      ],
      "metadata": {
        "id": "GL6zbhHyHal8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20508057-07ff-4954-9a74-701ae6515af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['heads.weight'], unexpected_keys=['pixel_mean', 'pixel_std', 'heads.classifier.weight'])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# remove se identity"
      ],
      "metadata": {
        "id": "93VeVboBxTdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import copy"
      ],
      "metadata": {
        "id": "gdY4IEV2xXBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sprawdzenie początkowej liczby warstw\n",
        "print(\"Liczba warstw przed usunięciem:\", len(list(model.modules())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIIsd8PgnMxc",
        "outputId": "f1e68b00-e8f8-4f0c-db01-2cf009df0050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba warstw przed usunięciem: 171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_identity_layers(model):\n",
        "    identity_layers = []\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, nn.Identity):\n",
        "            identity_layers.append(name)\n",
        "        else:\n",
        "            remove_identity_layers(module)\n",
        "    for name in identity_layers:\n",
        "        delattr(model, name)"
      ],
      "metadata": {
        "id": "CeTO9CI9xX_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model without the identity layers\n",
        "new_model = copy.deepcopy(model)\n",
        "remove_identity_layers(new_model)"
      ],
      "metadata": {
        "id": "NFutT2tCxaAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Liczba warstw po usunięciu:\", len(list(new_model.modules())))"
      ],
      "metadata": {
        "id": "w5I5nEjnp-QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# summary"
      ],
      "metadata": {
        "id": "oxeE1uwiQFf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 256, 128)) #r50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZv7yjHV0bnq",
        "outputId": "f5ff24d1-e41f-4d06-eaed-98210ab8533e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "         BatchNorm-2          [-1, 64, 128, 64]             128\n",
            "              ReLU-3          [-1, 64, 128, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]           4,096\n",
            "         BatchNorm-6           [-1, 64, 64, 32]             128\n",
            "              ReLU-7           [-1, 64, 64, 32]               0\n",
            "            Conv2d-8           [-1, 64, 64, 32]          36,864\n",
            "         BatchNorm-9           [-1, 64, 64, 32]             128\n",
            "             ReLU-10           [-1, 64, 64, 32]               0\n",
            "           Conv2d-11          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-12          [-1, 256, 64, 32]             512\n",
            "           Conv2d-13          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-14          [-1, 256, 64, 32]             512\n",
            "             ReLU-15          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-16          [-1, 256, 64, 32]               0\n",
            "           Conv2d-17           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-18           [-1, 64, 64, 32]             128\n",
            "             ReLU-19           [-1, 64, 64, 32]               0\n",
            "           Conv2d-20           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-21           [-1, 64, 64, 32]             128\n",
            "             ReLU-22           [-1, 64, 64, 32]               0\n",
            "           Conv2d-23          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-24          [-1, 256, 64, 32]             512\n",
            "             ReLU-25          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-26          [-1, 256, 64, 32]               0\n",
            "           Conv2d-27           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-28           [-1, 64, 64, 32]             128\n",
            "             ReLU-29           [-1, 64, 64, 32]               0\n",
            "           Conv2d-30           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-31           [-1, 64, 64, 32]             128\n",
            "             ReLU-32           [-1, 64, 64, 32]               0\n",
            "           Conv2d-33          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-34          [-1, 256, 64, 32]             512\n",
            "             ReLU-35          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-36          [-1, 256, 64, 32]               0\n",
            "           Conv2d-37          [-1, 128, 64, 32]          32,768\n",
            "        BatchNorm-38          [-1, 128, 64, 32]             256\n",
            "             ReLU-39          [-1, 128, 64, 32]               0\n",
            "           Conv2d-40          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-41          [-1, 128, 32, 16]             256\n",
            "             ReLU-42          [-1, 128, 32, 16]               0\n",
            "           Conv2d-43          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-44          [-1, 512, 32, 16]           1,024\n",
            "           Conv2d-45          [-1, 512, 32, 16]         131,072\n",
            "        BatchNorm-46          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-47          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-48          [-1, 512, 32, 16]               0\n",
            "           Conv2d-49          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-50          [-1, 128, 32, 16]             256\n",
            "             ReLU-51          [-1, 128, 32, 16]               0\n",
            "           Conv2d-52          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-53          [-1, 128, 32, 16]             256\n",
            "             ReLU-54          [-1, 128, 32, 16]               0\n",
            "           Conv2d-55          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-56          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-57          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-58          [-1, 512, 32, 16]               0\n",
            "           Conv2d-59          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-60          [-1, 128, 32, 16]             256\n",
            "             ReLU-61          [-1, 128, 32, 16]               0\n",
            "           Conv2d-62          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-63          [-1, 128, 32, 16]             256\n",
            "             ReLU-64          [-1, 128, 32, 16]               0\n",
            "           Conv2d-65          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-66          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-67          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-68          [-1, 512, 32, 16]               0\n",
            "           Conv2d-69          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-70          [-1, 128, 32, 16]             256\n",
            "             ReLU-71          [-1, 128, 32, 16]               0\n",
            "           Conv2d-72          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-73          [-1, 128, 32, 16]             256\n",
            "             ReLU-74          [-1, 128, 32, 16]               0\n",
            "           Conv2d-75          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-76          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-77          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-78          [-1, 512, 32, 16]               0\n",
            "           Conv2d-79          [-1, 256, 32, 16]         131,072\n",
            "        BatchNorm-80          [-1, 256, 32, 16]             512\n",
            "             ReLU-81          [-1, 256, 32, 16]               0\n",
            "           Conv2d-82           [-1, 256, 16, 8]         589,824\n",
            "        BatchNorm-83           [-1, 256, 16, 8]             512\n",
            "             ReLU-84           [-1, 256, 16, 8]               0\n",
            "           Conv2d-85          [-1, 1024, 16, 8]         262,144\n",
            "        BatchNorm-86          [-1, 1024, 16, 8]           2,048\n",
            "           Conv2d-87          [-1, 1024, 16, 8]         524,288\n",
            "        BatchNorm-88          [-1, 1024, 16, 8]           2,048\n",
            "             ReLU-89          [-1, 1024, 16, 8]               0\n",
            "       Bottleneck-90          [-1, 1024, 16, 8]               0\n",
            "           Conv2d-91           [-1, 256, 16, 8]         262,144\n",
            "        BatchNorm-92           [-1, 256, 16, 8]             512\n",
            "             ReLU-93           [-1, 256, 16, 8]               0\n",
            "           Conv2d-94           [-1, 256, 16, 8]         589,824\n",
            "        BatchNorm-95           [-1, 256, 16, 8]             512\n",
            "             ReLU-96           [-1, 256, 16, 8]               0\n",
            "           Conv2d-97          [-1, 1024, 16, 8]         262,144\n",
            "        BatchNorm-98          [-1, 1024, 16, 8]           2,048\n",
            "             ReLU-99          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-100          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-101           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-102           [-1, 256, 16, 8]             512\n",
            "            ReLU-103           [-1, 256, 16, 8]               0\n",
            "          Conv2d-104           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-105           [-1, 256, 16, 8]             512\n",
            "            ReLU-106           [-1, 256, 16, 8]               0\n",
            "          Conv2d-107          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-108          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-109          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-110          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-111           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-112           [-1, 256, 16, 8]             512\n",
            "            ReLU-113           [-1, 256, 16, 8]               0\n",
            "          Conv2d-114           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-115           [-1, 256, 16, 8]             512\n",
            "            ReLU-116           [-1, 256, 16, 8]               0\n",
            "          Conv2d-117          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-118          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-119          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-120          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-121           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-122           [-1, 256, 16, 8]             512\n",
            "            ReLU-123           [-1, 256, 16, 8]               0\n",
            "          Conv2d-124           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-125           [-1, 256, 16, 8]             512\n",
            "            ReLU-126           [-1, 256, 16, 8]               0\n",
            "          Conv2d-127          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-128          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-129          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-130          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-131           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-132           [-1, 256, 16, 8]             512\n",
            "            ReLU-133           [-1, 256, 16, 8]               0\n",
            "          Conv2d-134           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-135           [-1, 256, 16, 8]             512\n",
            "            ReLU-136           [-1, 256, 16, 8]               0\n",
            "          Conv2d-137          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-138          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-139          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-140          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-141           [-1, 512, 16, 8]         524,288\n",
            "       BatchNorm-142           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-143           [-1, 512, 16, 8]               0\n",
            "          Conv2d-144           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-145           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-146           [-1, 512, 16, 8]               0\n",
            "          Conv2d-147          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-148          [-1, 2048, 16, 8]           4,096\n",
            "          Conv2d-149          [-1, 2048, 16, 8]       2,097,152\n",
            "       BatchNorm-150          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-151          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-152          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-153           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-154           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-155           [-1, 512, 16, 8]               0\n",
            "          Conv2d-156           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-157           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-158           [-1, 512, 16, 8]               0\n",
            "          Conv2d-159          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-160          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-161          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-162          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-163           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-164           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-165           [-1, 512, 16, 8]               0\n",
            "          Conv2d-166           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-167           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-168           [-1, 512, 16, 8]               0\n",
            "          Conv2d-169          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-170          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-171          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-172          [-1, 2048, 16, 8]               0\n",
            "          ResNet-173          [-1, 2048, 16, 8]               0\n",
            "   GlobalAvgPool-174           [-1, 2048, 1, 1]               0\n",
            "       BatchNorm-175           [-1, 2048, 1, 1]           4,096\n",
            "   EmbeddingHead-176                 [-1, 2048]               0\n",
            "================================================================\n",
            "Total params: 23,512,128\n",
            "Trainable params: 23,512,128\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 215.80\n",
            "Params size (MB): 89.69\n",
            "Estimated Total Size (MB): 305.86\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 256, 128)) #r50nl-ibn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8Yae2r5z_Hu",
        "outputId": "075280d9-dee9-4550-a0df-c232ffa07c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "         BatchNorm-2          [-1, 64, 128, 64]             128\n",
            "              ReLU-3          [-1, 64, 128, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]           4,096\n",
            "    InstanceNorm2d-6           [-1, 32, 64, 32]              64\n",
            "         BatchNorm-7           [-1, 32, 64, 32]              64\n",
            "               IBN-8           [-1, 64, 64, 32]               0\n",
            "              ReLU-9           [-1, 64, 64, 32]               0\n",
            "           Conv2d-10           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-11           [-1, 64, 64, 32]             128\n",
            "             ReLU-12           [-1, 64, 64, 32]               0\n",
            "           Conv2d-13          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-14          [-1, 256, 64, 32]             512\n",
            "           Conv2d-15          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-16          [-1, 256, 64, 32]             512\n",
            "             ReLU-17          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-18          [-1, 256, 64, 32]               0\n",
            "           Conv2d-19           [-1, 64, 64, 32]          16,384\n",
            "   InstanceNorm2d-20           [-1, 32, 64, 32]              64\n",
            "        BatchNorm-21           [-1, 32, 64, 32]              64\n",
            "              IBN-22           [-1, 64, 64, 32]               0\n",
            "             ReLU-23           [-1, 64, 64, 32]               0\n",
            "           Conv2d-24           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-25           [-1, 64, 64, 32]             128\n",
            "             ReLU-26           [-1, 64, 64, 32]               0\n",
            "           Conv2d-27          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-28          [-1, 256, 64, 32]             512\n",
            "             ReLU-29          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-30          [-1, 256, 64, 32]               0\n",
            "           Conv2d-31           [-1, 64, 64, 32]          16,384\n",
            "   InstanceNorm2d-32           [-1, 32, 64, 32]              64\n",
            "        BatchNorm-33           [-1, 32, 64, 32]              64\n",
            "              IBN-34           [-1, 64, 64, 32]               0\n",
            "             ReLU-35           [-1, 64, 64, 32]               0\n",
            "           Conv2d-36           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-37           [-1, 64, 64, 32]             128\n",
            "             ReLU-38           [-1, 64, 64, 32]               0\n",
            "           Conv2d-39          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-40          [-1, 256, 64, 32]             512\n",
            "             ReLU-41          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-42          [-1, 256, 64, 32]               0\n",
            "           Conv2d-43          [-1, 128, 64, 32]          32,768\n",
            "   InstanceNorm2d-44           [-1, 64, 64, 32]             128\n",
            "        BatchNorm-45           [-1, 64, 64, 32]             128\n",
            "              IBN-46          [-1, 128, 64, 32]               0\n",
            "             ReLU-47          [-1, 128, 64, 32]               0\n",
            "           Conv2d-48          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-49          [-1, 128, 32, 16]             256\n",
            "             ReLU-50          [-1, 128, 32, 16]               0\n",
            "           Conv2d-51          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-52          [-1, 512, 32, 16]           1,024\n",
            "           Conv2d-53          [-1, 512, 32, 16]         131,072\n",
            "        BatchNorm-54          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-55          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-56          [-1, 512, 32, 16]               0\n",
            "           Conv2d-57          [-1, 128, 32, 16]          65,536\n",
            "   InstanceNorm2d-58           [-1, 64, 32, 16]             128\n",
            "        BatchNorm-59           [-1, 64, 32, 16]             128\n",
            "              IBN-60          [-1, 128, 32, 16]               0\n",
            "             ReLU-61          [-1, 128, 32, 16]               0\n",
            "           Conv2d-62          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-63          [-1, 128, 32, 16]             256\n",
            "             ReLU-64          [-1, 128, 32, 16]               0\n",
            "           Conv2d-65          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-66          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-67          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-68          [-1, 512, 32, 16]               0\n",
            "           Conv2d-69          [-1, 128, 32, 16]          65,536\n",
            "   InstanceNorm2d-70           [-1, 64, 32, 16]             128\n",
            "        BatchNorm-71           [-1, 64, 32, 16]             128\n",
            "              IBN-72          [-1, 128, 32, 16]               0\n",
            "             ReLU-73          [-1, 128, 32, 16]               0\n",
            "           Conv2d-74          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-75          [-1, 128, 32, 16]             256\n",
            "             ReLU-76          [-1, 128, 32, 16]               0\n",
            "           Conv2d-77          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-78          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-79          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-80          [-1, 512, 32, 16]               0\n",
            "           Conv2d-81            [-1, 1, 32, 16]             513\n",
            "           Conv2d-82            [-1, 1, 32, 16]             513\n",
            "           Conv2d-83            [-1, 1, 32, 16]             513\n",
            "           Conv2d-84          [-1, 512, 32, 16]           1,024\n",
            "        BatchNorm-85          [-1, 512, 32, 16]           1,024\n",
            "        Non_local-86          [-1, 512, 32, 16]               0\n",
            "           Conv2d-87          [-1, 128, 32, 16]          65,536\n",
            "   InstanceNorm2d-88           [-1, 64, 32, 16]             128\n",
            "        BatchNorm-89           [-1, 64, 32, 16]             128\n",
            "              IBN-90          [-1, 128, 32, 16]               0\n",
            "             ReLU-91          [-1, 128, 32, 16]               0\n",
            "           Conv2d-92          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-93          [-1, 128, 32, 16]             256\n",
            "             ReLU-94          [-1, 128, 32, 16]               0\n",
            "           Conv2d-95          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-96          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-97          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-98          [-1, 512, 32, 16]               0\n",
            "           Conv2d-99            [-1, 1, 32, 16]             513\n",
            "          Conv2d-100            [-1, 1, 32, 16]             513\n",
            "          Conv2d-101            [-1, 1, 32, 16]             513\n",
            "          Conv2d-102          [-1, 512, 32, 16]           1,024\n",
            "       BatchNorm-103          [-1, 512, 32, 16]           1,024\n",
            "       Non_local-104          [-1, 512, 32, 16]               0\n",
            "          Conv2d-105          [-1, 256, 32, 16]         131,072\n",
            "  InstanceNorm2d-106          [-1, 128, 32, 16]             256\n",
            "       BatchNorm-107          [-1, 128, 32, 16]             256\n",
            "             IBN-108          [-1, 256, 32, 16]               0\n",
            "            ReLU-109          [-1, 256, 32, 16]               0\n",
            "          Conv2d-110           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-111           [-1, 256, 16, 8]             512\n",
            "            ReLU-112           [-1, 256, 16, 8]               0\n",
            "          Conv2d-113          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-114          [-1, 1024, 16, 8]           2,048\n",
            "          Conv2d-115          [-1, 1024, 16, 8]         524,288\n",
            "       BatchNorm-116          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-117          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-118          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-119           [-1, 256, 16, 8]         262,144\n",
            "  InstanceNorm2d-120           [-1, 128, 16, 8]             256\n",
            "       BatchNorm-121           [-1, 128, 16, 8]             256\n",
            "             IBN-122           [-1, 256, 16, 8]               0\n",
            "            ReLU-123           [-1, 256, 16, 8]               0\n",
            "          Conv2d-124           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-125           [-1, 256, 16, 8]             512\n",
            "            ReLU-126           [-1, 256, 16, 8]               0\n",
            "          Conv2d-127          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-128          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-129          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-130          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-131           [-1, 256, 16, 8]         262,144\n",
            "  InstanceNorm2d-132           [-1, 128, 16, 8]             256\n",
            "       BatchNorm-133           [-1, 128, 16, 8]             256\n",
            "             IBN-134           [-1, 256, 16, 8]               0\n",
            "            ReLU-135           [-1, 256, 16, 8]               0\n",
            "          Conv2d-136           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-137           [-1, 256, 16, 8]             512\n",
            "            ReLU-138           [-1, 256, 16, 8]               0\n",
            "          Conv2d-139          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-140          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-141          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-142          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-143           [-1, 256, 16, 8]         262,144\n",
            "  InstanceNorm2d-144           [-1, 128, 16, 8]             256\n",
            "       BatchNorm-145           [-1, 128, 16, 8]             256\n",
            "             IBN-146           [-1, 256, 16, 8]               0\n",
            "            ReLU-147           [-1, 256, 16, 8]               0\n",
            "          Conv2d-148           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-149           [-1, 256, 16, 8]             512\n",
            "            ReLU-150           [-1, 256, 16, 8]               0\n",
            "          Conv2d-151          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-152          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-153          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-154          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-155             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-156             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-157             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-158          [-1, 1024, 16, 8]           2,048\n",
            "       BatchNorm-159          [-1, 1024, 16, 8]           2,048\n",
            "       Non_local-160          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-161           [-1, 256, 16, 8]         262,144\n",
            "  InstanceNorm2d-162           [-1, 128, 16, 8]             256\n",
            "       BatchNorm-163           [-1, 128, 16, 8]             256\n",
            "             IBN-164           [-1, 256, 16, 8]               0\n",
            "            ReLU-165           [-1, 256, 16, 8]               0\n",
            "          Conv2d-166           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-167           [-1, 256, 16, 8]             512\n",
            "            ReLU-168           [-1, 256, 16, 8]               0\n",
            "          Conv2d-169          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-170          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-171          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-172          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-173             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-174             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-175             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-176          [-1, 1024, 16, 8]           2,048\n",
            "       BatchNorm-177          [-1, 1024, 16, 8]           2,048\n",
            "       Non_local-178          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-179           [-1, 256, 16, 8]         262,144\n",
            "  InstanceNorm2d-180           [-1, 128, 16, 8]             256\n",
            "       BatchNorm-181           [-1, 128, 16, 8]             256\n",
            "             IBN-182           [-1, 256, 16, 8]               0\n",
            "            ReLU-183           [-1, 256, 16, 8]               0\n",
            "          Conv2d-184           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-185           [-1, 256, 16, 8]             512\n",
            "            ReLU-186           [-1, 256, 16, 8]               0\n",
            "          Conv2d-187          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-188          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-189          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-190          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-191             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-192             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-193             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-194          [-1, 1024, 16, 8]           2,048\n",
            "       BatchNorm-195          [-1, 1024, 16, 8]           2,048\n",
            "       Non_local-196          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-197           [-1, 512, 16, 8]         524,288\n",
            "       BatchNorm-198           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-199           [-1, 512, 16, 8]               0\n",
            "          Conv2d-200           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-201           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-202           [-1, 512, 16, 8]               0\n",
            "          Conv2d-203          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-204          [-1, 2048, 16, 8]           4,096\n",
            "          Conv2d-205          [-1, 2048, 16, 8]       2,097,152\n",
            "       BatchNorm-206          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-207          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-208          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-209           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-210           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-211           [-1, 512, 16, 8]               0\n",
            "          Conv2d-212           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-213           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-214           [-1, 512, 16, 8]               0\n",
            "          Conv2d-215          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-216          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-217          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-218          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-219           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-220           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-221           [-1, 512, 16, 8]               0\n",
            "          Conv2d-222           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-223           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-224           [-1, 512, 16, 8]               0\n",
            "          Conv2d-225          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-226          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-227          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-228          [-1, 2048, 16, 8]               0\n",
            "          ResNet-229          [-1, 2048, 16, 8]               0\n",
            "GeneralizedMeanPoolingP-230           [-1, 2048, 1, 1]               0\n",
            "       BatchNorm-231           [-1, 2048, 1, 1]           4,096\n",
            "   EmbeddingHead-232                 [-1, 2048]               0\n",
            "================================================================\n",
            "Total params: 23,540,815\n",
            "Trainable params: 23,540,815\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 245.58\n",
            "Params size (MB): 89.80\n",
            "Estimated Total Size (MB): 335.76\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 256, 128)) #r50nl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAkaqKeFzsjD",
        "outputId": "8f16d0c3-2ea9-4fb0-ddca-63f07ad6f67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "         BatchNorm-2          [-1, 64, 128, 64]             128\n",
            "              ReLU-3          [-1, 64, 128, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]           4,096\n",
            "         BatchNorm-6           [-1, 64, 64, 32]             128\n",
            "              ReLU-7           [-1, 64, 64, 32]               0\n",
            "            Conv2d-8           [-1, 64, 64, 32]          36,864\n",
            "         BatchNorm-9           [-1, 64, 64, 32]             128\n",
            "             ReLU-10           [-1, 64, 64, 32]               0\n",
            "           Conv2d-11          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-12          [-1, 256, 64, 32]             512\n",
            "           Conv2d-13          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-14          [-1, 256, 64, 32]             512\n",
            "             ReLU-15          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-16          [-1, 256, 64, 32]               0\n",
            "           Conv2d-17           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-18           [-1, 64, 64, 32]             128\n",
            "             ReLU-19           [-1, 64, 64, 32]               0\n",
            "           Conv2d-20           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-21           [-1, 64, 64, 32]             128\n",
            "             ReLU-22           [-1, 64, 64, 32]               0\n",
            "           Conv2d-23          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-24          [-1, 256, 64, 32]             512\n",
            "             ReLU-25          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-26          [-1, 256, 64, 32]               0\n",
            "           Conv2d-27           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-28           [-1, 64, 64, 32]             128\n",
            "             ReLU-29           [-1, 64, 64, 32]               0\n",
            "           Conv2d-30           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-31           [-1, 64, 64, 32]             128\n",
            "             ReLU-32           [-1, 64, 64, 32]               0\n",
            "           Conv2d-33          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-34          [-1, 256, 64, 32]             512\n",
            "             ReLU-35          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-36          [-1, 256, 64, 32]               0\n",
            "           Conv2d-37          [-1, 128, 64, 32]          32,768\n",
            "        BatchNorm-38          [-1, 128, 64, 32]             256\n",
            "             ReLU-39          [-1, 128, 64, 32]               0\n",
            "           Conv2d-40          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-41          [-1, 128, 32, 16]             256\n",
            "             ReLU-42          [-1, 128, 32, 16]               0\n",
            "           Conv2d-43          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-44          [-1, 512, 32, 16]           1,024\n",
            "           Conv2d-45          [-1, 512, 32, 16]         131,072\n",
            "        BatchNorm-46          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-47          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-48          [-1, 512, 32, 16]               0\n",
            "           Conv2d-49          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-50          [-1, 128, 32, 16]             256\n",
            "             ReLU-51          [-1, 128, 32, 16]               0\n",
            "           Conv2d-52          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-53          [-1, 128, 32, 16]             256\n",
            "             ReLU-54          [-1, 128, 32, 16]               0\n",
            "           Conv2d-55          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-56          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-57          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-58          [-1, 512, 32, 16]               0\n",
            "           Conv2d-59          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-60          [-1, 128, 32, 16]             256\n",
            "             ReLU-61          [-1, 128, 32, 16]               0\n",
            "           Conv2d-62          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-63          [-1, 128, 32, 16]             256\n",
            "             ReLU-64          [-1, 128, 32, 16]               0\n",
            "           Conv2d-65          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-66          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-67          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-68          [-1, 512, 32, 16]               0\n",
            "           Conv2d-69            [-1, 1, 32, 16]             513\n",
            "           Conv2d-70            [-1, 1, 32, 16]             513\n",
            "           Conv2d-71            [-1, 1, 32, 16]             513\n",
            "           Conv2d-72          [-1, 512, 32, 16]           1,024\n",
            "        BatchNorm-73          [-1, 512, 32, 16]           1,024\n",
            "        Non_local-74          [-1, 512, 32, 16]               0\n",
            "           Conv2d-75          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-76          [-1, 128, 32, 16]             256\n",
            "             ReLU-77          [-1, 128, 32, 16]               0\n",
            "           Conv2d-78          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-79          [-1, 128, 32, 16]             256\n",
            "             ReLU-80          [-1, 128, 32, 16]               0\n",
            "           Conv2d-81          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-82          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-83          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-84          [-1, 512, 32, 16]               0\n",
            "           Conv2d-85            [-1, 1, 32, 16]             513\n",
            "           Conv2d-86            [-1, 1, 32, 16]             513\n",
            "           Conv2d-87            [-1, 1, 32, 16]             513\n",
            "           Conv2d-88          [-1, 512, 32, 16]           1,024\n",
            "        BatchNorm-89          [-1, 512, 32, 16]           1,024\n",
            "        Non_local-90          [-1, 512, 32, 16]               0\n",
            "           Conv2d-91          [-1, 256, 32, 16]         131,072\n",
            "        BatchNorm-92          [-1, 256, 32, 16]             512\n",
            "             ReLU-93          [-1, 256, 32, 16]               0\n",
            "           Conv2d-94           [-1, 256, 16, 8]         589,824\n",
            "        BatchNorm-95           [-1, 256, 16, 8]             512\n",
            "             ReLU-96           [-1, 256, 16, 8]               0\n",
            "           Conv2d-97          [-1, 1024, 16, 8]         262,144\n",
            "        BatchNorm-98          [-1, 1024, 16, 8]           2,048\n",
            "           Conv2d-99          [-1, 1024, 16, 8]         524,288\n",
            "       BatchNorm-100          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-101          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-102          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-103           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-104           [-1, 256, 16, 8]             512\n",
            "            ReLU-105           [-1, 256, 16, 8]               0\n",
            "          Conv2d-106           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-107           [-1, 256, 16, 8]             512\n",
            "            ReLU-108           [-1, 256, 16, 8]               0\n",
            "          Conv2d-109          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-110          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-111          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-112          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-113           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-114           [-1, 256, 16, 8]             512\n",
            "            ReLU-115           [-1, 256, 16, 8]               0\n",
            "          Conv2d-116           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-117           [-1, 256, 16, 8]             512\n",
            "            ReLU-118           [-1, 256, 16, 8]               0\n",
            "          Conv2d-119          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-120          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-121          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-122          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-123           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-124           [-1, 256, 16, 8]             512\n",
            "            ReLU-125           [-1, 256, 16, 8]               0\n",
            "          Conv2d-126           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-127           [-1, 256, 16, 8]             512\n",
            "            ReLU-128           [-1, 256, 16, 8]               0\n",
            "          Conv2d-129          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-130          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-131          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-132          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-133             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-134             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-135             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-136          [-1, 1024, 16, 8]           2,048\n",
            "       BatchNorm-137          [-1, 1024, 16, 8]           2,048\n",
            "       Non_local-138          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-139           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-140           [-1, 256, 16, 8]             512\n",
            "            ReLU-141           [-1, 256, 16, 8]               0\n",
            "          Conv2d-142           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-143           [-1, 256, 16, 8]             512\n",
            "            ReLU-144           [-1, 256, 16, 8]               0\n",
            "          Conv2d-145          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-146          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-147          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-148          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-149             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-150             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-151             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-152          [-1, 1024, 16, 8]           2,048\n",
            "       BatchNorm-153          [-1, 1024, 16, 8]           2,048\n",
            "       Non_local-154          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-155           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-156           [-1, 256, 16, 8]             512\n",
            "            ReLU-157           [-1, 256, 16, 8]               0\n",
            "          Conv2d-158           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-159           [-1, 256, 16, 8]             512\n",
            "            ReLU-160           [-1, 256, 16, 8]               0\n",
            "          Conv2d-161          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-162          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-163          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-164          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-165             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-166             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-167             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-168          [-1, 1024, 16, 8]           2,048\n",
            "       BatchNorm-169          [-1, 1024, 16, 8]           2,048\n",
            "       Non_local-170          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-171           [-1, 512, 16, 8]         524,288\n",
            "       BatchNorm-172           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-173           [-1, 512, 16, 8]               0\n",
            "          Conv2d-174           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-175           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-176           [-1, 512, 16, 8]               0\n",
            "          Conv2d-177          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-178          [-1, 2048, 16, 8]           4,096\n",
            "          Conv2d-179          [-1, 2048, 16, 8]       2,097,152\n",
            "       BatchNorm-180          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-181          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-182          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-183           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-184           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-185           [-1, 512, 16, 8]               0\n",
            "          Conv2d-186           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-187           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-188           [-1, 512, 16, 8]               0\n",
            "          Conv2d-189          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-190          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-191          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-192          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-193           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-194           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-195           [-1, 512, 16, 8]               0\n",
            "          Conv2d-196           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-197           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-198           [-1, 512, 16, 8]               0\n",
            "          Conv2d-199          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-200          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-201          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-202          [-1, 2048, 16, 8]               0\n",
            "          ResNet-203          [-1, 2048, 16, 8]               0\n",
            "GeneralizedMeanPoolingP-204           [-1, 2048, 1, 1]               0\n",
            "       BatchNorm-205           [-1, 2048, 1, 1]           4,096\n",
            "   EmbeddingHead-206                 [-1, 2048]               0\n",
            "================================================================\n",
            "Total params: 23,540,815\n",
            "Trainable params: 23,540,815\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 236.83\n",
            "Params size (MB): 89.80\n",
            "Estimated Total Size (MB): 327.01\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 256, 128)) #r50ibn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9b9YYE9y0iH",
        "outputId": "1a90307c-cf17-44ee-c822-7d80637e02a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "         BatchNorm-2          [-1, 64, 128, 64]             128\n",
            "              ReLU-3          [-1, 64, 128, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]           4,096\n",
            "    InstanceNorm2d-6           [-1, 32, 64, 32]              64\n",
            "         BatchNorm-7           [-1, 32, 64, 32]              64\n",
            "               IBN-8           [-1, 64, 64, 32]               0\n",
            "              ReLU-9           [-1, 64, 64, 32]               0\n",
            "           Conv2d-10           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-11           [-1, 64, 64, 32]             128\n",
            "             ReLU-12           [-1, 64, 64, 32]               0\n",
            "           Conv2d-13          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-14          [-1, 256, 64, 32]             512\n",
            "           Conv2d-15          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-16          [-1, 256, 64, 32]             512\n",
            "             ReLU-17          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-18          [-1, 256, 64, 32]               0\n",
            "           Conv2d-19           [-1, 64, 64, 32]          16,384\n",
            "   InstanceNorm2d-20           [-1, 32, 64, 32]              64\n",
            "        BatchNorm-21           [-1, 32, 64, 32]              64\n",
            "              IBN-22           [-1, 64, 64, 32]               0\n",
            "             ReLU-23           [-1, 64, 64, 32]               0\n",
            "           Conv2d-24           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-25           [-1, 64, 64, 32]             128\n",
            "             ReLU-26           [-1, 64, 64, 32]               0\n",
            "           Conv2d-27          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-28          [-1, 256, 64, 32]             512\n",
            "             ReLU-29          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-30          [-1, 256, 64, 32]               0\n",
            "           Conv2d-31           [-1, 64, 64, 32]          16,384\n",
            "   InstanceNorm2d-32           [-1, 32, 64, 32]              64\n",
            "        BatchNorm-33           [-1, 32, 64, 32]              64\n",
            "              IBN-34           [-1, 64, 64, 32]               0\n",
            "             ReLU-35           [-1, 64, 64, 32]               0\n",
            "           Conv2d-36           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-37           [-1, 64, 64, 32]             128\n",
            "             ReLU-38           [-1, 64, 64, 32]               0\n",
            "           Conv2d-39          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-40          [-1, 256, 64, 32]             512\n",
            "             ReLU-41          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-42          [-1, 256, 64, 32]               0\n",
            "           Conv2d-43          [-1, 128, 64, 32]          32,768\n",
            "   InstanceNorm2d-44           [-1, 64, 64, 32]             128\n",
            "        BatchNorm-45           [-1, 64, 64, 32]             128\n",
            "              IBN-46          [-1, 128, 64, 32]               0\n",
            "             ReLU-47          [-1, 128, 64, 32]               0\n",
            "           Conv2d-48          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-49          [-1, 128, 32, 16]             256\n",
            "             ReLU-50          [-1, 128, 32, 16]               0\n",
            "           Conv2d-51          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-52          [-1, 512, 32, 16]           1,024\n",
            "           Conv2d-53          [-1, 512, 32, 16]         131,072\n",
            "        BatchNorm-54          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-55          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-56          [-1, 512, 32, 16]               0\n",
            "           Conv2d-57          [-1, 128, 32, 16]          65,536\n",
            "   InstanceNorm2d-58           [-1, 64, 32, 16]             128\n",
            "        BatchNorm-59           [-1, 64, 32, 16]             128\n",
            "              IBN-60          [-1, 128, 32, 16]               0\n",
            "             ReLU-61          [-1, 128, 32, 16]               0\n",
            "           Conv2d-62          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-63          [-1, 128, 32, 16]             256\n",
            "             ReLU-64          [-1, 128, 32, 16]               0\n",
            "           Conv2d-65          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-66          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-67          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-68          [-1, 512, 32, 16]               0\n",
            "           Conv2d-69          [-1, 128, 32, 16]          65,536\n",
            "   InstanceNorm2d-70           [-1, 64, 32, 16]             128\n",
            "        BatchNorm-71           [-1, 64, 32, 16]             128\n",
            "              IBN-72          [-1, 128, 32, 16]               0\n",
            "             ReLU-73          [-1, 128, 32, 16]               0\n",
            "           Conv2d-74          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-75          [-1, 128, 32, 16]             256\n",
            "             ReLU-76          [-1, 128, 32, 16]               0\n",
            "           Conv2d-77          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-78          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-79          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-80          [-1, 512, 32, 16]               0\n",
            "           Conv2d-81          [-1, 128, 32, 16]          65,536\n",
            "   InstanceNorm2d-82           [-1, 64, 32, 16]             128\n",
            "        BatchNorm-83           [-1, 64, 32, 16]             128\n",
            "              IBN-84          [-1, 128, 32, 16]               0\n",
            "             ReLU-85          [-1, 128, 32, 16]               0\n",
            "           Conv2d-86          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-87          [-1, 128, 32, 16]             256\n",
            "             ReLU-88          [-1, 128, 32, 16]               0\n",
            "           Conv2d-89          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-90          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-91          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-92          [-1, 512, 32, 16]               0\n",
            "           Conv2d-93          [-1, 256, 32, 16]         131,072\n",
            "   InstanceNorm2d-94          [-1, 128, 32, 16]             256\n",
            "        BatchNorm-95          [-1, 128, 32, 16]             256\n",
            "              IBN-96          [-1, 256, 32, 16]               0\n",
            "             ReLU-97          [-1, 256, 32, 16]               0\n",
            "           Conv2d-98           [-1, 256, 16, 8]         589,824\n",
            "        BatchNorm-99           [-1, 256, 16, 8]             512\n",
            "            ReLU-100           [-1, 256, 16, 8]               0\n",
            "          Conv2d-101          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-102          [-1, 1024, 16, 8]           2,048\n",
            "          Conv2d-103          [-1, 1024, 16, 8]         524,288\n",
            "       BatchNorm-104          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-105          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-106          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-107           [-1, 256, 16, 8]         262,144\n",
            "  InstanceNorm2d-108           [-1, 128, 16, 8]             256\n",
            "       BatchNorm-109           [-1, 128, 16, 8]             256\n",
            "             IBN-110           [-1, 256, 16, 8]               0\n",
            "            ReLU-111           [-1, 256, 16, 8]               0\n",
            "          Conv2d-112           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-113           [-1, 256, 16, 8]             512\n",
            "            ReLU-114           [-1, 256, 16, 8]               0\n",
            "          Conv2d-115          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-116          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-117          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-118          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-119           [-1, 256, 16, 8]         262,144\n",
            "  InstanceNorm2d-120           [-1, 128, 16, 8]             256\n",
            "       BatchNorm-121           [-1, 128, 16, 8]             256\n",
            "             IBN-122           [-1, 256, 16, 8]               0\n",
            "            ReLU-123           [-1, 256, 16, 8]               0\n",
            "          Conv2d-124           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-125           [-1, 256, 16, 8]             512\n",
            "            ReLU-126           [-1, 256, 16, 8]               0\n",
            "          Conv2d-127          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-128          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-129          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-130          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-131           [-1, 256, 16, 8]         262,144\n",
            "  InstanceNorm2d-132           [-1, 128, 16, 8]             256\n",
            "       BatchNorm-133           [-1, 128, 16, 8]             256\n",
            "             IBN-134           [-1, 256, 16, 8]               0\n",
            "            ReLU-135           [-1, 256, 16, 8]               0\n",
            "          Conv2d-136           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-137           [-1, 256, 16, 8]             512\n",
            "            ReLU-138           [-1, 256, 16, 8]               0\n",
            "          Conv2d-139          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-140          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-141          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-142          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-143           [-1, 256, 16, 8]         262,144\n",
            "  InstanceNorm2d-144           [-1, 128, 16, 8]             256\n",
            "       BatchNorm-145           [-1, 128, 16, 8]             256\n",
            "             IBN-146           [-1, 256, 16, 8]               0\n",
            "            ReLU-147           [-1, 256, 16, 8]               0\n",
            "          Conv2d-148           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-149           [-1, 256, 16, 8]             512\n",
            "            ReLU-150           [-1, 256, 16, 8]               0\n",
            "          Conv2d-151          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-152          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-153          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-154          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-155           [-1, 256, 16, 8]         262,144\n",
            "  InstanceNorm2d-156           [-1, 128, 16, 8]             256\n",
            "       BatchNorm-157           [-1, 128, 16, 8]             256\n",
            "             IBN-158           [-1, 256, 16, 8]               0\n",
            "            ReLU-159           [-1, 256, 16, 8]               0\n",
            "          Conv2d-160           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-161           [-1, 256, 16, 8]             512\n",
            "            ReLU-162           [-1, 256, 16, 8]               0\n",
            "          Conv2d-163          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-164          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-165          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-166          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-167           [-1, 512, 16, 8]         524,288\n",
            "       BatchNorm-168           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-169           [-1, 512, 16, 8]               0\n",
            "          Conv2d-170           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-171           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-172           [-1, 512, 16, 8]               0\n",
            "          Conv2d-173          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-174          [-1, 2048, 16, 8]           4,096\n",
            "          Conv2d-175          [-1, 2048, 16, 8]       2,097,152\n",
            "       BatchNorm-176          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-177          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-178          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-179           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-180           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-181           [-1, 512, 16, 8]               0\n",
            "          Conv2d-182           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-183           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-184           [-1, 512, 16, 8]               0\n",
            "          Conv2d-185          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-186          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-187          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-188          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-189           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-190           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-191           [-1, 512, 16, 8]               0\n",
            "          Conv2d-192           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-193           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-194           [-1, 512, 16, 8]               0\n",
            "          Conv2d-195          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-196          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-197          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-198          [-1, 2048, 16, 8]               0\n",
            "          ResNet-199          [-1, 2048, 16, 8]               0\n",
            "   GlobalAvgPool-200           [-1, 2048, 1, 1]               0\n",
            "       BatchNorm-201           [-1, 2048, 1, 1]           4,096\n",
            "   EmbeddingHead-202                 [-1, 2048]               0\n",
            "================================================================\n",
            "Total params: 23,512,128\n",
            "Trainable params: 23,512,128\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 224.55\n",
            "Params size (MB): 89.69\n",
            "Estimated Total Size (MB): 314.61\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(new_model, (3, 256, 128)) #r50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n22XaPj8qOBL",
        "outputId": "bdf95079-b487-4974-df0d-384e3a4898cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "         BatchNorm-2          [-1, 64, 128, 64]             128\n",
            "              ReLU-3          [-1, 64, 128, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]           4,096\n",
            "         BatchNorm-6           [-1, 64, 64, 32]             128\n",
            "              ReLU-7           [-1, 64, 64, 32]               0\n",
            "            Conv2d-8           [-1, 64, 64, 32]          36,864\n",
            "         BatchNorm-9           [-1, 64, 64, 32]             128\n",
            "             ReLU-10           [-1, 64, 64, 32]               0\n",
            "           Conv2d-11          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-12          [-1, 256, 64, 32]             512\n",
            "           Conv2d-13          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-14          [-1, 256, 64, 32]             512\n",
            "             ReLU-15          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-16          [-1, 256, 64, 32]               0\n",
            "           Conv2d-17           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-18           [-1, 64, 64, 32]             128\n",
            "             ReLU-19           [-1, 64, 64, 32]               0\n",
            "           Conv2d-20           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-21           [-1, 64, 64, 32]             128\n",
            "             ReLU-22           [-1, 64, 64, 32]               0\n",
            "           Conv2d-23          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-24          [-1, 256, 64, 32]             512\n",
            "             ReLU-25          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-26          [-1, 256, 64, 32]               0\n",
            "           Conv2d-27           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-28           [-1, 64, 64, 32]             128\n",
            "             ReLU-29           [-1, 64, 64, 32]               0\n",
            "           Conv2d-30           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-31           [-1, 64, 64, 32]             128\n",
            "             ReLU-32           [-1, 64, 64, 32]               0\n",
            "           Conv2d-33          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-34          [-1, 256, 64, 32]             512\n",
            "             ReLU-35          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-36          [-1, 256, 64, 32]               0\n",
            "           Conv2d-37          [-1, 128, 64, 32]          32,768\n",
            "        BatchNorm-38          [-1, 128, 64, 32]             256\n",
            "             ReLU-39          [-1, 128, 64, 32]               0\n",
            "           Conv2d-40          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-41          [-1, 128, 32, 16]             256\n",
            "             ReLU-42          [-1, 128, 32, 16]               0\n",
            "           Conv2d-43          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-44          [-1, 512, 32, 16]           1,024\n",
            "           Conv2d-45          [-1, 512, 32, 16]         131,072\n",
            "        BatchNorm-46          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-47          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-48          [-1, 512, 32, 16]               0\n",
            "           Conv2d-49          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-50          [-1, 128, 32, 16]             256\n",
            "             ReLU-51          [-1, 128, 32, 16]               0\n",
            "           Conv2d-52          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-53          [-1, 128, 32, 16]             256\n",
            "             ReLU-54          [-1, 128, 32, 16]               0\n",
            "           Conv2d-55          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-56          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-57          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-58          [-1, 512, 32, 16]               0\n",
            "           Conv2d-59          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-60          [-1, 128, 32, 16]             256\n",
            "             ReLU-61          [-1, 128, 32, 16]               0\n",
            "           Conv2d-62          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-63          [-1, 128, 32, 16]             256\n",
            "             ReLU-64          [-1, 128, 32, 16]               0\n",
            "           Conv2d-65          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-66          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-67          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-68          [-1, 512, 32, 16]               0\n",
            "           Conv2d-69          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-70          [-1, 128, 32, 16]             256\n",
            "             ReLU-71          [-1, 128, 32, 16]               0\n",
            "           Conv2d-72          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-73          [-1, 128, 32, 16]             256\n",
            "             ReLU-74          [-1, 128, 32, 16]               0\n",
            "           Conv2d-75          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-76          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-77          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-78          [-1, 512, 32, 16]               0\n",
            "           Conv2d-79          [-1, 256, 32, 16]         131,072\n",
            "        BatchNorm-80          [-1, 256, 32, 16]             512\n",
            "             ReLU-81          [-1, 256, 32, 16]               0\n",
            "           Conv2d-82           [-1, 256, 16, 8]         589,824\n",
            "        BatchNorm-83           [-1, 256, 16, 8]             512\n",
            "             ReLU-84           [-1, 256, 16, 8]               0\n",
            "           Conv2d-85          [-1, 1024, 16, 8]         262,144\n",
            "        BatchNorm-86          [-1, 1024, 16, 8]           2,048\n",
            "           Conv2d-87          [-1, 1024, 16, 8]         524,288\n",
            "        BatchNorm-88          [-1, 1024, 16, 8]           2,048\n",
            "             ReLU-89          [-1, 1024, 16, 8]               0\n",
            "       Bottleneck-90          [-1, 1024, 16, 8]               0\n",
            "           Conv2d-91           [-1, 256, 16, 8]         262,144\n",
            "        BatchNorm-92           [-1, 256, 16, 8]             512\n",
            "             ReLU-93           [-1, 256, 16, 8]               0\n",
            "           Conv2d-94           [-1, 256, 16, 8]         589,824\n",
            "        BatchNorm-95           [-1, 256, 16, 8]             512\n",
            "             ReLU-96           [-1, 256, 16, 8]               0\n",
            "           Conv2d-97          [-1, 1024, 16, 8]         262,144\n",
            "        BatchNorm-98          [-1, 1024, 16, 8]           2,048\n",
            "             ReLU-99          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-100          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-101           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-102           [-1, 256, 16, 8]             512\n",
            "            ReLU-103           [-1, 256, 16, 8]               0\n",
            "          Conv2d-104           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-105           [-1, 256, 16, 8]             512\n",
            "            ReLU-106           [-1, 256, 16, 8]               0\n",
            "          Conv2d-107          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-108          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-109          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-110          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-111           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-112           [-1, 256, 16, 8]             512\n",
            "            ReLU-113           [-1, 256, 16, 8]               0\n",
            "          Conv2d-114           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-115           [-1, 256, 16, 8]             512\n",
            "            ReLU-116           [-1, 256, 16, 8]               0\n",
            "          Conv2d-117          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-118          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-119          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-120          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-121           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-122           [-1, 256, 16, 8]             512\n",
            "            ReLU-123           [-1, 256, 16, 8]               0\n",
            "          Conv2d-124           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-125           [-1, 256, 16, 8]             512\n",
            "            ReLU-126           [-1, 256, 16, 8]               0\n",
            "          Conv2d-127          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-128          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-129          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-130          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-131           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-132           [-1, 256, 16, 8]             512\n",
            "            ReLU-133           [-1, 256, 16, 8]               0\n",
            "          Conv2d-134           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-135           [-1, 256, 16, 8]             512\n",
            "            ReLU-136           [-1, 256, 16, 8]               0\n",
            "          Conv2d-137          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-138          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-139          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-140          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-141           [-1, 512, 16, 8]         524,288\n",
            "       BatchNorm-142           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-143           [-1, 512, 16, 8]               0\n",
            "          Conv2d-144           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-145           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-146           [-1, 512, 16, 8]               0\n",
            "          Conv2d-147          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-148          [-1, 2048, 16, 8]           4,096\n",
            "          Conv2d-149          [-1, 2048, 16, 8]       2,097,152\n",
            "       BatchNorm-150          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-151          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-152          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-153           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-154           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-155           [-1, 512, 16, 8]               0\n",
            "          Conv2d-156           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-157           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-158           [-1, 512, 16, 8]               0\n",
            "          Conv2d-159          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-160          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-161          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-162          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-163           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-164           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-165           [-1, 512, 16, 8]               0\n",
            "          Conv2d-166           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-167           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-168           [-1, 512, 16, 8]               0\n",
            "          Conv2d-169          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-170          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-171          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-172          [-1, 2048, 16, 8]               0\n",
            "          ResNet-173          [-1, 2048, 16, 8]               0\n",
            "   GlobalAvgPool-174           [-1, 2048, 1, 1]               0\n",
            "       BatchNorm-175           [-1, 2048, 1, 1]           4,096\n",
            "   EmbeddingHead-176                 [-1, 2048]               0\n",
            "================================================================\n",
            "Total params: 23,512,128\n",
            "Trainable params: 23,512,128\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 215.80\n",
            "Params size (MB): 89.69\n",
            "Estimated Total Size (MB): 305.86\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "# r50\n",
        "summary(model, (3, 256, 128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BrZilizl2JN",
        "outputId": "2594ed31-b50a-475a-cc8e-08591df933eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "         BatchNorm-2          [-1, 64, 128, 64]             128\n",
            "              ReLU-3          [-1, 64, 128, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]           4,096\n",
            "         BatchNorm-6           [-1, 64, 64, 32]             128\n",
            "              ReLU-7           [-1, 64, 64, 32]               0\n",
            "            Conv2d-8           [-1, 64, 64, 32]          36,864\n",
            "         BatchNorm-9           [-1, 64, 64, 32]             128\n",
            "             ReLU-10           [-1, 64, 64, 32]               0\n",
            "           Conv2d-11          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-12          [-1, 256, 64, 32]             512\n",
            "         Identity-13          [-1, 256, 64, 32]               0\n",
            "           Conv2d-14          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-15          [-1, 256, 64, 32]             512\n",
            "             ReLU-16          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-17          [-1, 256, 64, 32]               0\n",
            "           Conv2d-18           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-19           [-1, 64, 64, 32]             128\n",
            "             ReLU-20           [-1, 64, 64, 32]               0\n",
            "           Conv2d-21           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-22           [-1, 64, 64, 32]             128\n",
            "             ReLU-23           [-1, 64, 64, 32]               0\n",
            "           Conv2d-24          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-25          [-1, 256, 64, 32]             512\n",
            "         Identity-26          [-1, 256, 64, 32]               0\n",
            "             ReLU-27          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-28          [-1, 256, 64, 32]               0\n",
            "           Conv2d-29           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-30           [-1, 64, 64, 32]             128\n",
            "             ReLU-31           [-1, 64, 64, 32]               0\n",
            "           Conv2d-32           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-33           [-1, 64, 64, 32]             128\n",
            "             ReLU-34           [-1, 64, 64, 32]               0\n",
            "           Conv2d-35          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-36          [-1, 256, 64, 32]             512\n",
            "         Identity-37          [-1, 256, 64, 32]               0\n",
            "             ReLU-38          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-39          [-1, 256, 64, 32]               0\n",
            "           Conv2d-40          [-1, 128, 64, 32]          32,768\n",
            "        BatchNorm-41          [-1, 128, 64, 32]             256\n",
            "             ReLU-42          [-1, 128, 64, 32]               0\n",
            "           Conv2d-43          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-44          [-1, 128, 32, 16]             256\n",
            "             ReLU-45          [-1, 128, 32, 16]               0\n",
            "           Conv2d-46          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-47          [-1, 512, 32, 16]           1,024\n",
            "         Identity-48          [-1, 512, 32, 16]               0\n",
            "           Conv2d-49          [-1, 512, 32, 16]         131,072\n",
            "        BatchNorm-50          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-51          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-52          [-1, 512, 32, 16]               0\n",
            "           Conv2d-53          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-54          [-1, 128, 32, 16]             256\n",
            "             ReLU-55          [-1, 128, 32, 16]               0\n",
            "           Conv2d-56          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-57          [-1, 128, 32, 16]             256\n",
            "             ReLU-58          [-1, 128, 32, 16]               0\n",
            "           Conv2d-59          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-60          [-1, 512, 32, 16]           1,024\n",
            "         Identity-61          [-1, 512, 32, 16]               0\n",
            "             ReLU-62          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-63          [-1, 512, 32, 16]               0\n",
            "           Conv2d-64          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-65          [-1, 128, 32, 16]             256\n",
            "             ReLU-66          [-1, 128, 32, 16]               0\n",
            "           Conv2d-67          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-68          [-1, 128, 32, 16]             256\n",
            "             ReLU-69          [-1, 128, 32, 16]               0\n",
            "           Conv2d-70          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-71          [-1, 512, 32, 16]           1,024\n",
            "         Identity-72          [-1, 512, 32, 16]               0\n",
            "             ReLU-73          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-74          [-1, 512, 32, 16]               0\n",
            "           Conv2d-75          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-76          [-1, 128, 32, 16]             256\n",
            "             ReLU-77          [-1, 128, 32, 16]               0\n",
            "           Conv2d-78          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-79          [-1, 128, 32, 16]             256\n",
            "             ReLU-80          [-1, 128, 32, 16]               0\n",
            "           Conv2d-81          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-82          [-1, 512, 32, 16]           1,024\n",
            "         Identity-83          [-1, 512, 32, 16]               0\n",
            "             ReLU-84          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-85          [-1, 512, 32, 16]               0\n",
            "           Conv2d-86          [-1, 256, 32, 16]         131,072\n",
            "        BatchNorm-87          [-1, 256, 32, 16]             512\n",
            "             ReLU-88          [-1, 256, 32, 16]               0\n",
            "           Conv2d-89           [-1, 256, 16, 8]         589,824\n",
            "        BatchNorm-90           [-1, 256, 16, 8]             512\n",
            "             ReLU-91           [-1, 256, 16, 8]               0\n",
            "           Conv2d-92          [-1, 1024, 16, 8]         262,144\n",
            "        BatchNorm-93          [-1, 1024, 16, 8]           2,048\n",
            "         Identity-94          [-1, 1024, 16, 8]               0\n",
            "           Conv2d-95          [-1, 1024, 16, 8]         524,288\n",
            "        BatchNorm-96          [-1, 1024, 16, 8]           2,048\n",
            "             ReLU-97          [-1, 1024, 16, 8]               0\n",
            "       Bottleneck-98          [-1, 1024, 16, 8]               0\n",
            "           Conv2d-99           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-100           [-1, 256, 16, 8]             512\n",
            "            ReLU-101           [-1, 256, 16, 8]               0\n",
            "          Conv2d-102           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-103           [-1, 256, 16, 8]             512\n",
            "            ReLU-104           [-1, 256, 16, 8]               0\n",
            "          Conv2d-105          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-106          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-107          [-1, 1024, 16, 8]               0\n",
            "            ReLU-108          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-109          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-110           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-111           [-1, 256, 16, 8]             512\n",
            "            ReLU-112           [-1, 256, 16, 8]               0\n",
            "          Conv2d-113           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-114           [-1, 256, 16, 8]             512\n",
            "            ReLU-115           [-1, 256, 16, 8]               0\n",
            "          Conv2d-116          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-117          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-118          [-1, 1024, 16, 8]               0\n",
            "            ReLU-119          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-120          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-121           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-122           [-1, 256, 16, 8]             512\n",
            "            ReLU-123           [-1, 256, 16, 8]               0\n",
            "          Conv2d-124           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-125           [-1, 256, 16, 8]             512\n",
            "            ReLU-126           [-1, 256, 16, 8]               0\n",
            "          Conv2d-127          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-128          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-129          [-1, 1024, 16, 8]               0\n",
            "            ReLU-130          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-131          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-132           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-133           [-1, 256, 16, 8]             512\n",
            "            ReLU-134           [-1, 256, 16, 8]               0\n",
            "          Conv2d-135           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-136           [-1, 256, 16, 8]             512\n",
            "            ReLU-137           [-1, 256, 16, 8]               0\n",
            "          Conv2d-138          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-139          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-140          [-1, 1024, 16, 8]               0\n",
            "            ReLU-141          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-142          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-143           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-144           [-1, 256, 16, 8]             512\n",
            "            ReLU-145           [-1, 256, 16, 8]               0\n",
            "          Conv2d-146           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-147           [-1, 256, 16, 8]             512\n",
            "            ReLU-148           [-1, 256, 16, 8]               0\n",
            "          Conv2d-149          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-150          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-151          [-1, 1024, 16, 8]               0\n",
            "            ReLU-152          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-153          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-154           [-1, 512, 16, 8]         524,288\n",
            "       BatchNorm-155           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-156           [-1, 512, 16, 8]               0\n",
            "          Conv2d-157           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-158           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-159           [-1, 512, 16, 8]               0\n",
            "          Conv2d-160          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-161          [-1, 2048, 16, 8]           4,096\n",
            "        Identity-162          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-163          [-1, 2048, 16, 8]       2,097,152\n",
            "       BatchNorm-164          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-165          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-166          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-167           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-168           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-169           [-1, 512, 16, 8]               0\n",
            "          Conv2d-170           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-171           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-172           [-1, 512, 16, 8]               0\n",
            "          Conv2d-173          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-174          [-1, 2048, 16, 8]           4,096\n",
            "        Identity-175          [-1, 2048, 16, 8]               0\n",
            "            ReLU-176          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-177          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-178           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-179           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-180           [-1, 512, 16, 8]               0\n",
            "          Conv2d-181           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-182           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-183           [-1, 512, 16, 8]               0\n",
            "          Conv2d-184          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-185          [-1, 2048, 16, 8]           4,096\n",
            "        Identity-186          [-1, 2048, 16, 8]               0\n",
            "            ReLU-187          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-188          [-1, 2048, 16, 8]               0\n",
            "          ResNet-189          [-1, 2048, 16, 8]               0\n",
            "   GlobalAvgPool-190           [-1, 2048, 1, 1]               0\n",
            "       BatchNorm-191           [-1, 2048, 1, 1]           4,096\n",
            "   EmbeddingHead-192                 [-1, 2048]               0\n",
            "================================================================\n",
            "Total params: 23,512,128\n",
            "Trainable params: 23,512,128\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 247.80\n",
            "Params size (MB): 89.69\n",
            "Estimated Total Size (MB): 337.86\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "# r50\n",
        "summary(model, (3, 256, 128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KXA0TA-_a9T",
        "outputId": "23bbd513-7a3a-47f5-81ed-8b5221dc5270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "         BatchNorm-2          [-1, 64, 128, 64]             128\n",
            "              ReLU-3          [-1, 64, 128, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]           4,096\n",
            "         BatchNorm-6           [-1, 64, 64, 32]             128\n",
            "              ReLU-7           [-1, 64, 64, 32]               0\n",
            "            Conv2d-8           [-1, 64, 64, 32]          36,864\n",
            "         BatchNorm-9           [-1, 64, 64, 32]             128\n",
            "             ReLU-10           [-1, 64, 64, 32]               0\n",
            "           Conv2d-11          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-12          [-1, 256, 64, 32]             512\n",
            "         Identity-13          [-1, 256, 64, 32]               0\n",
            "           Conv2d-14          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-15          [-1, 256, 64, 32]             512\n",
            "             ReLU-16          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-17          [-1, 256, 64, 32]               0\n",
            "           Conv2d-18           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-19           [-1, 64, 64, 32]             128\n",
            "             ReLU-20           [-1, 64, 64, 32]               0\n",
            "           Conv2d-21           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-22           [-1, 64, 64, 32]             128\n",
            "             ReLU-23           [-1, 64, 64, 32]               0\n",
            "           Conv2d-24          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-25          [-1, 256, 64, 32]             512\n",
            "         Identity-26          [-1, 256, 64, 32]               0\n",
            "             ReLU-27          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-28          [-1, 256, 64, 32]               0\n",
            "           Conv2d-29           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-30           [-1, 64, 64, 32]             128\n",
            "             ReLU-31           [-1, 64, 64, 32]               0\n",
            "           Conv2d-32           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-33           [-1, 64, 64, 32]             128\n",
            "             ReLU-34           [-1, 64, 64, 32]               0\n",
            "           Conv2d-35          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-36          [-1, 256, 64, 32]             512\n",
            "         Identity-37          [-1, 256, 64, 32]               0\n",
            "             ReLU-38          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-39          [-1, 256, 64, 32]               0\n",
            "           Conv2d-40          [-1, 128, 64, 32]          32,768\n",
            "        BatchNorm-41          [-1, 128, 64, 32]             256\n",
            "             ReLU-42          [-1, 128, 64, 32]               0\n",
            "           Conv2d-43          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-44          [-1, 128, 32, 16]             256\n",
            "             ReLU-45          [-1, 128, 32, 16]               0\n",
            "           Conv2d-46          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-47          [-1, 512, 32, 16]           1,024\n",
            "         Identity-48          [-1, 512, 32, 16]               0\n",
            "           Conv2d-49          [-1, 512, 32, 16]         131,072\n",
            "        BatchNorm-50          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-51          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-52          [-1, 512, 32, 16]               0\n",
            "           Conv2d-53          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-54          [-1, 128, 32, 16]             256\n",
            "             ReLU-55          [-1, 128, 32, 16]               0\n",
            "           Conv2d-56          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-57          [-1, 128, 32, 16]             256\n",
            "             ReLU-58          [-1, 128, 32, 16]               0\n",
            "           Conv2d-59          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-60          [-1, 512, 32, 16]           1,024\n",
            "         Identity-61          [-1, 512, 32, 16]               0\n",
            "             ReLU-62          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-63          [-1, 512, 32, 16]               0\n",
            "           Conv2d-64          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-65          [-1, 128, 32, 16]             256\n",
            "             ReLU-66          [-1, 128, 32, 16]               0\n",
            "           Conv2d-67          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-68          [-1, 128, 32, 16]             256\n",
            "             ReLU-69          [-1, 128, 32, 16]               0\n",
            "           Conv2d-70          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-71          [-1, 512, 32, 16]           1,024\n",
            "         Identity-72          [-1, 512, 32, 16]               0\n",
            "             ReLU-73          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-74          [-1, 512, 32, 16]               0\n",
            "           Conv2d-75          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-76          [-1, 128, 32, 16]             256\n",
            "             ReLU-77          [-1, 128, 32, 16]               0\n",
            "           Conv2d-78          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-79          [-1, 128, 32, 16]             256\n",
            "             ReLU-80          [-1, 128, 32, 16]               0\n",
            "           Conv2d-81          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-82          [-1, 512, 32, 16]           1,024\n",
            "         Identity-83          [-1, 512, 32, 16]               0\n",
            "             ReLU-84          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-85          [-1, 512, 32, 16]               0\n",
            "           Conv2d-86          [-1, 256, 32, 16]         131,072\n",
            "        BatchNorm-87          [-1, 256, 32, 16]             512\n",
            "             ReLU-88          [-1, 256, 32, 16]               0\n",
            "           Conv2d-89           [-1, 256, 16, 8]         589,824\n",
            "        BatchNorm-90           [-1, 256, 16, 8]             512\n",
            "             ReLU-91           [-1, 256, 16, 8]               0\n",
            "           Conv2d-92          [-1, 1024, 16, 8]         262,144\n",
            "        BatchNorm-93          [-1, 1024, 16, 8]           2,048\n",
            "         Identity-94          [-1, 1024, 16, 8]               0\n",
            "           Conv2d-95          [-1, 1024, 16, 8]         524,288\n",
            "        BatchNorm-96          [-1, 1024, 16, 8]           2,048\n",
            "             ReLU-97          [-1, 1024, 16, 8]               0\n",
            "       Bottleneck-98          [-1, 1024, 16, 8]               0\n",
            "           Conv2d-99           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-100           [-1, 256, 16, 8]             512\n",
            "            ReLU-101           [-1, 256, 16, 8]               0\n",
            "          Conv2d-102           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-103           [-1, 256, 16, 8]             512\n",
            "            ReLU-104           [-1, 256, 16, 8]               0\n",
            "          Conv2d-105          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-106          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-107          [-1, 1024, 16, 8]               0\n",
            "            ReLU-108          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-109          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-110           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-111           [-1, 256, 16, 8]             512\n",
            "            ReLU-112           [-1, 256, 16, 8]               0\n",
            "          Conv2d-113           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-114           [-1, 256, 16, 8]             512\n",
            "            ReLU-115           [-1, 256, 16, 8]               0\n",
            "          Conv2d-116          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-117          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-118          [-1, 1024, 16, 8]               0\n",
            "            ReLU-119          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-120          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-121           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-122           [-1, 256, 16, 8]             512\n",
            "            ReLU-123           [-1, 256, 16, 8]               0\n",
            "          Conv2d-124           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-125           [-1, 256, 16, 8]             512\n",
            "            ReLU-126           [-1, 256, 16, 8]               0\n",
            "          Conv2d-127          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-128          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-129          [-1, 1024, 16, 8]               0\n",
            "            ReLU-130          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-131          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-132           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-133           [-1, 256, 16, 8]             512\n",
            "            ReLU-134           [-1, 256, 16, 8]               0\n",
            "          Conv2d-135           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-136           [-1, 256, 16, 8]             512\n",
            "            ReLU-137           [-1, 256, 16, 8]               0\n",
            "          Conv2d-138          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-139          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-140          [-1, 1024, 16, 8]               0\n",
            "            ReLU-141          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-142          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-143           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-144           [-1, 256, 16, 8]             512\n",
            "            ReLU-145           [-1, 256, 16, 8]               0\n",
            "          Conv2d-146           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-147           [-1, 256, 16, 8]             512\n",
            "            ReLU-148           [-1, 256, 16, 8]               0\n",
            "          Conv2d-149          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-150          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-151          [-1, 1024, 16, 8]               0\n",
            "            ReLU-152          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-153          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-154           [-1, 512, 16, 8]         524,288\n",
            "       BatchNorm-155           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-156           [-1, 512, 16, 8]               0\n",
            "          Conv2d-157           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-158           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-159           [-1, 512, 16, 8]               0\n",
            "          Conv2d-160          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-161          [-1, 2048, 16, 8]           4,096\n",
            "        Identity-162          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-163          [-1, 2048, 16, 8]       2,097,152\n",
            "       BatchNorm-164          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-165          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-166          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-167           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-168           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-169           [-1, 512, 16, 8]               0\n",
            "          Conv2d-170           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-171           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-172           [-1, 512, 16, 8]               0\n",
            "          Conv2d-173          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-174          [-1, 2048, 16, 8]           4,096\n",
            "        Identity-175          [-1, 2048, 16, 8]               0\n",
            "            ReLU-176          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-177          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-178           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-179           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-180           [-1, 512, 16, 8]               0\n",
            "          Conv2d-181           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-182           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-183           [-1, 512, 16, 8]               0\n",
            "          Conv2d-184          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-185          [-1, 2048, 16, 8]           4,096\n",
            "        Identity-186          [-1, 2048, 16, 8]               0\n",
            "            ReLU-187          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-188          [-1, 2048, 16, 8]               0\n",
            "          ResNet-189          [-1, 2048, 16, 8]               0\n",
            "   GlobalAvgPool-190           [-1, 2048, 1, 1]               0\n",
            "       BatchNorm-191           [-1, 2048, 1, 1]           4,096\n",
            "   EmbeddingHead-192                 [-1, 2048]               0\n",
            "================================================================\n",
            "Total params: 23,512,128\n",
            "Trainable params: 23,512,128\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 247.80\n",
            "Params size (MB): 89.69\n",
            "Estimated Total Size (MB): 337.86\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "summary(model, (3, 256, 128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60zOr6srybVb",
        "outputId": "b6dc05ba-8826-403e-8621-f6770e1ebfd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "         BatchNorm-2          [-1, 64, 128, 64]             128\n",
            "              ReLU-3          [-1, 64, 128, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]           4,096\n",
            "         BatchNorm-6           [-1, 64, 64, 32]             128\n",
            "              ReLU-7           [-1, 64, 64, 32]               0\n",
            "            Conv2d-8           [-1, 64, 64, 32]          36,864\n",
            "         BatchNorm-9           [-1, 64, 64, 32]             128\n",
            "             ReLU-10           [-1, 64, 64, 32]               0\n",
            "           Conv2d-11          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-12          [-1, 256, 64, 32]             512\n",
            "         Identity-13          [-1, 256, 64, 32]               0\n",
            "           Conv2d-14          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-15          [-1, 256, 64, 32]             512\n",
            "             ReLU-16          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-17          [-1, 256, 64, 32]               0\n",
            "           Conv2d-18           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-19           [-1, 64, 64, 32]             128\n",
            "             ReLU-20           [-1, 64, 64, 32]               0\n",
            "           Conv2d-21           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-22           [-1, 64, 64, 32]             128\n",
            "             ReLU-23           [-1, 64, 64, 32]               0\n",
            "           Conv2d-24          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-25          [-1, 256, 64, 32]             512\n",
            "         Identity-26          [-1, 256, 64, 32]               0\n",
            "             ReLU-27          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-28          [-1, 256, 64, 32]               0\n",
            "           Conv2d-29           [-1, 64, 64, 32]          16,384\n",
            "        BatchNorm-30           [-1, 64, 64, 32]             128\n",
            "             ReLU-31           [-1, 64, 64, 32]               0\n",
            "           Conv2d-32           [-1, 64, 64, 32]          36,864\n",
            "        BatchNorm-33           [-1, 64, 64, 32]             128\n",
            "             ReLU-34           [-1, 64, 64, 32]               0\n",
            "           Conv2d-35          [-1, 256, 64, 32]          16,384\n",
            "        BatchNorm-36          [-1, 256, 64, 32]             512\n",
            "         Identity-37          [-1, 256, 64, 32]               0\n",
            "             ReLU-38          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-39          [-1, 256, 64, 32]               0\n",
            "           Conv2d-40          [-1, 128, 64, 32]          32,768\n",
            "        BatchNorm-41          [-1, 128, 64, 32]             256\n",
            "             ReLU-42          [-1, 128, 64, 32]               0\n",
            "           Conv2d-43          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-44          [-1, 128, 32, 16]             256\n",
            "             ReLU-45          [-1, 128, 32, 16]               0\n",
            "           Conv2d-46          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-47          [-1, 512, 32, 16]           1,024\n",
            "         Identity-48          [-1, 512, 32, 16]               0\n",
            "           Conv2d-49          [-1, 512, 32, 16]         131,072\n",
            "        BatchNorm-50          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-51          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-52          [-1, 512, 32, 16]               0\n",
            "           Conv2d-53          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-54          [-1, 128, 32, 16]             256\n",
            "             ReLU-55          [-1, 128, 32, 16]               0\n",
            "           Conv2d-56          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-57          [-1, 128, 32, 16]             256\n",
            "             ReLU-58          [-1, 128, 32, 16]               0\n",
            "           Conv2d-59          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-60          [-1, 512, 32, 16]           1,024\n",
            "         Identity-61          [-1, 512, 32, 16]               0\n",
            "             ReLU-62          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-63          [-1, 512, 32, 16]               0\n",
            "           Conv2d-64          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-65          [-1, 128, 32, 16]             256\n",
            "             ReLU-66          [-1, 128, 32, 16]               0\n",
            "           Conv2d-67          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-68          [-1, 128, 32, 16]             256\n",
            "             ReLU-69          [-1, 128, 32, 16]               0\n",
            "           Conv2d-70          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-71          [-1, 512, 32, 16]           1,024\n",
            "         Identity-72          [-1, 512, 32, 16]               0\n",
            "             ReLU-73          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-74          [-1, 512, 32, 16]               0\n",
            "           Conv2d-75            [-1, 1, 32, 16]             513\n",
            "           Conv2d-76            [-1, 1, 32, 16]             513\n",
            "           Conv2d-77            [-1, 1, 32, 16]             513\n",
            "           Conv2d-78          [-1, 512, 32, 16]           1,024\n",
            "        BatchNorm-79          [-1, 512, 32, 16]           1,024\n",
            "        Non_local-80          [-1, 512, 32, 16]               0\n",
            "           Conv2d-81          [-1, 128, 32, 16]          65,536\n",
            "        BatchNorm-82          [-1, 128, 32, 16]             256\n",
            "             ReLU-83          [-1, 128, 32, 16]               0\n",
            "           Conv2d-84          [-1, 128, 32, 16]         147,456\n",
            "        BatchNorm-85          [-1, 128, 32, 16]             256\n",
            "             ReLU-86          [-1, 128, 32, 16]               0\n",
            "           Conv2d-87          [-1, 512, 32, 16]          65,536\n",
            "        BatchNorm-88          [-1, 512, 32, 16]           1,024\n",
            "         Identity-89          [-1, 512, 32, 16]               0\n",
            "             ReLU-90          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-91          [-1, 512, 32, 16]               0\n",
            "           Conv2d-92            [-1, 1, 32, 16]             513\n",
            "           Conv2d-93            [-1, 1, 32, 16]             513\n",
            "           Conv2d-94            [-1, 1, 32, 16]             513\n",
            "           Conv2d-95          [-1, 512, 32, 16]           1,024\n",
            "        BatchNorm-96          [-1, 512, 32, 16]           1,024\n",
            "        Non_local-97          [-1, 512, 32, 16]               0\n",
            "           Conv2d-98          [-1, 256, 32, 16]         131,072\n",
            "        BatchNorm-99          [-1, 256, 32, 16]             512\n",
            "            ReLU-100          [-1, 256, 32, 16]               0\n",
            "          Conv2d-101           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-102           [-1, 256, 16, 8]             512\n",
            "            ReLU-103           [-1, 256, 16, 8]               0\n",
            "          Conv2d-104          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-105          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-106          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-107          [-1, 1024, 16, 8]         524,288\n",
            "       BatchNorm-108          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-109          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-110          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-111           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-112           [-1, 256, 16, 8]             512\n",
            "            ReLU-113           [-1, 256, 16, 8]               0\n",
            "          Conv2d-114           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-115           [-1, 256, 16, 8]             512\n",
            "            ReLU-116           [-1, 256, 16, 8]               0\n",
            "          Conv2d-117          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-118          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-119          [-1, 1024, 16, 8]               0\n",
            "            ReLU-120          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-121          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-122           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-123           [-1, 256, 16, 8]             512\n",
            "            ReLU-124           [-1, 256, 16, 8]               0\n",
            "          Conv2d-125           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-126           [-1, 256, 16, 8]             512\n",
            "            ReLU-127           [-1, 256, 16, 8]               0\n",
            "          Conv2d-128          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-129          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-130          [-1, 1024, 16, 8]               0\n",
            "            ReLU-131          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-132          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-133           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-134           [-1, 256, 16, 8]             512\n",
            "            ReLU-135           [-1, 256, 16, 8]               0\n",
            "          Conv2d-136           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-137           [-1, 256, 16, 8]             512\n",
            "            ReLU-138           [-1, 256, 16, 8]               0\n",
            "          Conv2d-139          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-140          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-141          [-1, 1024, 16, 8]               0\n",
            "            ReLU-142          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-143          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-144             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-145             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-146             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-147          [-1, 1024, 16, 8]           2,048\n",
            "       BatchNorm-148          [-1, 1024, 16, 8]           2,048\n",
            "       Non_local-149          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-150           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-151           [-1, 256, 16, 8]             512\n",
            "            ReLU-152           [-1, 256, 16, 8]               0\n",
            "          Conv2d-153           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-154           [-1, 256, 16, 8]             512\n",
            "            ReLU-155           [-1, 256, 16, 8]               0\n",
            "          Conv2d-156          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-157          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-158          [-1, 1024, 16, 8]               0\n",
            "            ReLU-159          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-160          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-161             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-162             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-163             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-164          [-1, 1024, 16, 8]           2,048\n",
            "       BatchNorm-165          [-1, 1024, 16, 8]           2,048\n",
            "       Non_local-166          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-167           [-1, 256, 16, 8]         262,144\n",
            "       BatchNorm-168           [-1, 256, 16, 8]             512\n",
            "            ReLU-169           [-1, 256, 16, 8]               0\n",
            "          Conv2d-170           [-1, 256, 16, 8]         589,824\n",
            "       BatchNorm-171           [-1, 256, 16, 8]             512\n",
            "            ReLU-172           [-1, 256, 16, 8]               0\n",
            "          Conv2d-173          [-1, 1024, 16, 8]         262,144\n",
            "       BatchNorm-174          [-1, 1024, 16, 8]           2,048\n",
            "        Identity-175          [-1, 1024, 16, 8]               0\n",
            "            ReLU-176          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-177          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-178             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-179             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-180             [-1, 1, 16, 8]           1,025\n",
            "          Conv2d-181          [-1, 1024, 16, 8]           2,048\n",
            "       BatchNorm-182          [-1, 1024, 16, 8]           2,048\n",
            "       Non_local-183          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-184           [-1, 512, 16, 8]         524,288\n",
            "       BatchNorm-185           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-186           [-1, 512, 16, 8]               0\n",
            "          Conv2d-187           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-188           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-189           [-1, 512, 16, 8]               0\n",
            "          Conv2d-190          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-191          [-1, 2048, 16, 8]           4,096\n",
            "        Identity-192          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-193          [-1, 2048, 16, 8]       2,097,152\n",
            "       BatchNorm-194          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-195          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-196          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-197           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-198           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-199           [-1, 512, 16, 8]               0\n",
            "          Conv2d-200           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-201           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-202           [-1, 512, 16, 8]               0\n",
            "          Conv2d-203          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-204          [-1, 2048, 16, 8]           4,096\n",
            "        Identity-205          [-1, 2048, 16, 8]               0\n",
            "            ReLU-206          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-207          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-208           [-1, 512, 16, 8]       1,048,576\n",
            "       BatchNorm-209           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-210           [-1, 512, 16, 8]               0\n",
            "          Conv2d-211           [-1, 512, 16, 8]       2,359,296\n",
            "       BatchNorm-212           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-213           [-1, 512, 16, 8]               0\n",
            "          Conv2d-214          [-1, 2048, 16, 8]       1,048,576\n",
            "       BatchNorm-215          [-1, 2048, 16, 8]           4,096\n",
            "        Identity-216          [-1, 2048, 16, 8]               0\n",
            "            ReLU-217          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-218          [-1, 2048, 16, 8]               0\n",
            "          ResNet-219          [-1, 2048, 16, 8]               0\n",
            "GeneralizedMeanPoolingP-220           [-1, 2048, 1, 1]               0\n",
            "       BatchNorm-221           [-1, 2048, 1, 1]           4,096\n",
            "   EmbeddingHead-222                 [-1, 2048]               0\n",
            "================================================================\n",
            "Total params: 23,540,815\n",
            "Trainable params: 23,540,815\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 268.83\n",
            "Params size (MB): 89.80\n",
            "Estimated Total Size (MB): 359.01\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 384, 128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-chpIWw2MaN",
        "outputId": "6db11b57-343d-4ccb-9808-8fcd3b6c9e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 192, 64]           9,408\n",
            "         BatchNorm-2          [-1, 64, 192, 64]             128\n",
            "              ReLU-3          [-1, 64, 192, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 96, 32]               0\n",
            "            Conv2d-5           [-1, 64, 96, 32]           4,096\n",
            "         BatchNorm-6           [-1, 64, 96, 32]             128\n",
            "              ReLU-7           [-1, 64, 96, 32]               0\n",
            "            Conv2d-8           [-1, 64, 96, 32]          36,864\n",
            "         BatchNorm-9           [-1, 64, 96, 32]             128\n",
            "             ReLU-10           [-1, 64, 96, 32]               0\n",
            "           Conv2d-11          [-1, 256, 96, 32]          16,384\n",
            "        BatchNorm-12          [-1, 256, 96, 32]             512\n",
            "         Identity-13          [-1, 256, 96, 32]               0\n",
            "           Conv2d-14          [-1, 256, 96, 32]          16,384\n",
            "        BatchNorm-15          [-1, 256, 96, 32]             512\n",
            "             ReLU-16          [-1, 256, 96, 32]               0\n",
            "       Bottleneck-17          [-1, 256, 96, 32]               0\n",
            "           Conv2d-18           [-1, 64, 96, 32]          16,384\n",
            "        BatchNorm-19           [-1, 64, 96, 32]             128\n",
            "             ReLU-20           [-1, 64, 96, 32]               0\n",
            "           Conv2d-21           [-1, 64, 96, 32]          36,864\n",
            "        BatchNorm-22           [-1, 64, 96, 32]             128\n",
            "             ReLU-23           [-1, 64, 96, 32]               0\n",
            "           Conv2d-24          [-1, 256, 96, 32]          16,384\n",
            "        BatchNorm-25          [-1, 256, 96, 32]             512\n",
            "         Identity-26          [-1, 256, 96, 32]               0\n",
            "             ReLU-27          [-1, 256, 96, 32]               0\n",
            "       Bottleneck-28          [-1, 256, 96, 32]               0\n",
            "           Conv2d-29           [-1, 64, 96, 32]          16,384\n",
            "        BatchNorm-30           [-1, 64, 96, 32]             128\n",
            "             ReLU-31           [-1, 64, 96, 32]               0\n",
            "           Conv2d-32           [-1, 64, 96, 32]          36,864\n",
            "        BatchNorm-33           [-1, 64, 96, 32]             128\n",
            "             ReLU-34           [-1, 64, 96, 32]               0\n",
            "           Conv2d-35          [-1, 256, 96, 32]          16,384\n",
            "        BatchNorm-36          [-1, 256, 96, 32]             512\n",
            "         Identity-37          [-1, 256, 96, 32]               0\n",
            "             ReLU-38          [-1, 256, 96, 32]               0\n",
            "       Bottleneck-39          [-1, 256, 96, 32]               0\n",
            "           Conv2d-40          [-1, 128, 96, 32]          32,768\n",
            "        BatchNorm-41          [-1, 128, 96, 32]             256\n",
            "             ReLU-42          [-1, 128, 96, 32]               0\n",
            "           Conv2d-43          [-1, 128, 48, 16]         147,456\n",
            "        BatchNorm-44          [-1, 128, 48, 16]             256\n",
            "             ReLU-45          [-1, 128, 48, 16]               0\n",
            "           Conv2d-46          [-1, 512, 48, 16]          65,536\n",
            "        BatchNorm-47          [-1, 512, 48, 16]           1,024\n",
            "         Identity-48          [-1, 512, 48, 16]               0\n",
            "           Conv2d-49          [-1, 512, 48, 16]         131,072\n",
            "        BatchNorm-50          [-1, 512, 48, 16]           1,024\n",
            "             ReLU-51          [-1, 512, 48, 16]               0\n",
            "       Bottleneck-52          [-1, 512, 48, 16]               0\n",
            "           Conv2d-53          [-1, 128, 48, 16]          65,536\n",
            "        BatchNorm-54          [-1, 128, 48, 16]             256\n",
            "             ReLU-55          [-1, 128, 48, 16]               0\n",
            "           Conv2d-56          [-1, 128, 48, 16]         147,456\n",
            "        BatchNorm-57          [-1, 128, 48, 16]             256\n",
            "             ReLU-58          [-1, 128, 48, 16]               0\n",
            "           Conv2d-59          [-1, 512, 48, 16]          65,536\n",
            "        BatchNorm-60          [-1, 512, 48, 16]           1,024\n",
            "         Identity-61          [-1, 512, 48, 16]               0\n",
            "             ReLU-62          [-1, 512, 48, 16]               0\n",
            "       Bottleneck-63          [-1, 512, 48, 16]               0\n",
            "           Conv2d-64          [-1, 128, 48, 16]          65,536\n",
            "        BatchNorm-65          [-1, 128, 48, 16]             256\n",
            "             ReLU-66          [-1, 128, 48, 16]               0\n",
            "           Conv2d-67          [-1, 128, 48, 16]         147,456\n",
            "        BatchNorm-68          [-1, 128, 48, 16]             256\n",
            "             ReLU-69          [-1, 128, 48, 16]               0\n",
            "           Conv2d-70          [-1, 512, 48, 16]          65,536\n",
            "        BatchNorm-71          [-1, 512, 48, 16]           1,024\n",
            "         Identity-72          [-1, 512, 48, 16]               0\n",
            "             ReLU-73          [-1, 512, 48, 16]               0\n",
            "       Bottleneck-74          [-1, 512, 48, 16]               0\n",
            "           Conv2d-75            [-1, 1, 48, 16]             513\n",
            "           Conv2d-76            [-1, 1, 48, 16]             513\n",
            "           Conv2d-77            [-1, 1, 48, 16]             513\n",
            "           Conv2d-78          [-1, 512, 48, 16]           1,024\n",
            "        BatchNorm-79          [-1, 512, 48, 16]           1,024\n",
            "        Non_local-80          [-1, 512, 48, 16]               0\n",
            "           Conv2d-81          [-1, 128, 48, 16]          65,536\n",
            "        BatchNorm-82          [-1, 128, 48, 16]             256\n",
            "             ReLU-83          [-1, 128, 48, 16]               0\n",
            "           Conv2d-84          [-1, 128, 48, 16]         147,456\n",
            "        BatchNorm-85          [-1, 128, 48, 16]             256\n",
            "             ReLU-86          [-1, 128, 48, 16]               0\n",
            "           Conv2d-87          [-1, 512, 48, 16]          65,536\n",
            "        BatchNorm-88          [-1, 512, 48, 16]           1,024\n",
            "         Identity-89          [-1, 512, 48, 16]               0\n",
            "             ReLU-90          [-1, 512, 48, 16]               0\n",
            "       Bottleneck-91          [-1, 512, 48, 16]               0\n",
            "           Conv2d-92            [-1, 1, 48, 16]             513\n",
            "           Conv2d-93            [-1, 1, 48, 16]             513\n",
            "           Conv2d-94            [-1, 1, 48, 16]             513\n",
            "           Conv2d-95          [-1, 512, 48, 16]           1,024\n",
            "        BatchNorm-96          [-1, 512, 48, 16]           1,024\n",
            "        Non_local-97          [-1, 512, 48, 16]               0\n",
            "           Conv2d-98          [-1, 256, 48, 16]         131,072\n",
            "        BatchNorm-99          [-1, 256, 48, 16]             512\n",
            "            ReLU-100          [-1, 256, 48, 16]               0\n",
            "          Conv2d-101           [-1, 256, 24, 8]         589,824\n",
            "       BatchNorm-102           [-1, 256, 24, 8]             512\n",
            "            ReLU-103           [-1, 256, 24, 8]               0\n",
            "          Conv2d-104          [-1, 1024, 24, 8]         262,144\n",
            "       BatchNorm-105          [-1, 1024, 24, 8]           2,048\n",
            "        Identity-106          [-1, 1024, 24, 8]               0\n",
            "          Conv2d-107          [-1, 1024, 24, 8]         524,288\n",
            "       BatchNorm-108          [-1, 1024, 24, 8]           2,048\n",
            "            ReLU-109          [-1, 1024, 24, 8]               0\n",
            "      Bottleneck-110          [-1, 1024, 24, 8]               0\n",
            "          Conv2d-111           [-1, 256, 24, 8]         262,144\n",
            "       BatchNorm-112           [-1, 256, 24, 8]             512\n",
            "            ReLU-113           [-1, 256, 24, 8]               0\n",
            "          Conv2d-114           [-1, 256, 24, 8]         589,824\n",
            "       BatchNorm-115           [-1, 256, 24, 8]             512\n",
            "            ReLU-116           [-1, 256, 24, 8]               0\n",
            "          Conv2d-117          [-1, 1024, 24, 8]         262,144\n",
            "       BatchNorm-118          [-1, 1024, 24, 8]           2,048\n",
            "        Identity-119          [-1, 1024, 24, 8]               0\n",
            "            ReLU-120          [-1, 1024, 24, 8]               0\n",
            "      Bottleneck-121          [-1, 1024, 24, 8]               0\n",
            "          Conv2d-122           [-1, 256, 24, 8]         262,144\n",
            "       BatchNorm-123           [-1, 256, 24, 8]             512\n",
            "            ReLU-124           [-1, 256, 24, 8]               0\n",
            "          Conv2d-125           [-1, 256, 24, 8]         589,824\n",
            "       BatchNorm-126           [-1, 256, 24, 8]             512\n",
            "            ReLU-127           [-1, 256, 24, 8]               0\n",
            "          Conv2d-128          [-1, 1024, 24, 8]         262,144\n",
            "       BatchNorm-129          [-1, 1024, 24, 8]           2,048\n",
            "        Identity-130          [-1, 1024, 24, 8]               0\n",
            "            ReLU-131          [-1, 1024, 24, 8]               0\n",
            "      Bottleneck-132          [-1, 1024, 24, 8]               0\n",
            "          Conv2d-133           [-1, 256, 24, 8]         262,144\n",
            "       BatchNorm-134           [-1, 256, 24, 8]             512\n",
            "            ReLU-135           [-1, 256, 24, 8]               0\n",
            "          Conv2d-136           [-1, 256, 24, 8]         589,824\n",
            "       BatchNorm-137           [-1, 256, 24, 8]             512\n",
            "            ReLU-138           [-1, 256, 24, 8]               0\n",
            "          Conv2d-139          [-1, 1024, 24, 8]         262,144\n",
            "       BatchNorm-140          [-1, 1024, 24, 8]           2,048\n",
            "        Identity-141          [-1, 1024, 24, 8]               0\n",
            "            ReLU-142          [-1, 1024, 24, 8]               0\n",
            "      Bottleneck-143          [-1, 1024, 24, 8]               0\n",
            "          Conv2d-144             [-1, 1, 24, 8]           1,025\n",
            "          Conv2d-145             [-1, 1, 24, 8]           1,025\n",
            "          Conv2d-146             [-1, 1, 24, 8]           1,025\n",
            "          Conv2d-147          [-1, 1024, 24, 8]           2,048\n",
            "       BatchNorm-148          [-1, 1024, 24, 8]           2,048\n",
            "       Non_local-149          [-1, 1024, 24, 8]               0\n",
            "          Conv2d-150           [-1, 256, 24, 8]         262,144\n",
            "       BatchNorm-151           [-1, 256, 24, 8]             512\n",
            "            ReLU-152           [-1, 256, 24, 8]               0\n",
            "          Conv2d-153           [-1, 256, 24, 8]         589,824\n",
            "       BatchNorm-154           [-1, 256, 24, 8]             512\n",
            "            ReLU-155           [-1, 256, 24, 8]               0\n",
            "          Conv2d-156          [-1, 1024, 24, 8]         262,144\n",
            "       BatchNorm-157          [-1, 1024, 24, 8]           2,048\n",
            "        Identity-158          [-1, 1024, 24, 8]               0\n",
            "            ReLU-159          [-1, 1024, 24, 8]               0\n",
            "      Bottleneck-160          [-1, 1024, 24, 8]               0\n",
            "          Conv2d-161             [-1, 1, 24, 8]           1,025\n",
            "          Conv2d-162             [-1, 1, 24, 8]           1,025\n",
            "          Conv2d-163             [-1, 1, 24, 8]           1,025\n",
            "          Conv2d-164          [-1, 1024, 24, 8]           2,048\n",
            "       BatchNorm-165          [-1, 1024, 24, 8]           2,048\n",
            "       Non_local-166          [-1, 1024, 24, 8]               0\n",
            "          Conv2d-167           [-1, 256, 24, 8]         262,144\n",
            "       BatchNorm-168           [-1, 256, 24, 8]             512\n",
            "            ReLU-169           [-1, 256, 24, 8]               0\n",
            "          Conv2d-170           [-1, 256, 24, 8]         589,824\n",
            "       BatchNorm-171           [-1, 256, 24, 8]             512\n",
            "            ReLU-172           [-1, 256, 24, 8]               0\n",
            "          Conv2d-173          [-1, 1024, 24, 8]         262,144\n",
            "       BatchNorm-174          [-1, 1024, 24, 8]           2,048\n",
            "        Identity-175          [-1, 1024, 24, 8]               0\n",
            "            ReLU-176          [-1, 1024, 24, 8]               0\n",
            "      Bottleneck-177          [-1, 1024, 24, 8]               0\n",
            "          Conv2d-178             [-1, 1, 24, 8]           1,025\n",
            "          Conv2d-179             [-1, 1, 24, 8]           1,025\n",
            "          Conv2d-180             [-1, 1, 24, 8]           1,025\n",
            "          Conv2d-181          [-1, 1024, 24, 8]           2,048\n",
            "       BatchNorm-182          [-1, 1024, 24, 8]           2,048\n",
            "       Non_local-183          [-1, 1024, 24, 8]               0\n",
            "          Conv2d-184           [-1, 512, 24, 8]         524,288\n",
            "       BatchNorm-185           [-1, 512, 24, 8]           1,024\n",
            "            ReLU-186           [-1, 512, 24, 8]               0\n",
            "          Conv2d-187           [-1, 512, 24, 8]       2,359,296\n",
            "       BatchNorm-188           [-1, 512, 24, 8]           1,024\n",
            "            ReLU-189           [-1, 512, 24, 8]               0\n",
            "          Conv2d-190          [-1, 2048, 24, 8]       1,048,576\n",
            "       BatchNorm-191          [-1, 2048, 24, 8]           4,096\n",
            "        Identity-192          [-1, 2048, 24, 8]               0\n",
            "          Conv2d-193          [-1, 2048, 24, 8]       2,097,152\n",
            "       BatchNorm-194          [-1, 2048, 24, 8]           4,096\n",
            "            ReLU-195          [-1, 2048, 24, 8]               0\n",
            "      Bottleneck-196          [-1, 2048, 24, 8]               0\n",
            "          Conv2d-197           [-1, 512, 24, 8]       1,048,576\n",
            "       BatchNorm-198           [-1, 512, 24, 8]           1,024\n",
            "            ReLU-199           [-1, 512, 24, 8]               0\n",
            "          Conv2d-200           [-1, 512, 24, 8]       2,359,296\n",
            "       BatchNorm-201           [-1, 512, 24, 8]           1,024\n",
            "            ReLU-202           [-1, 512, 24, 8]               0\n",
            "          Conv2d-203          [-1, 2048, 24, 8]       1,048,576\n",
            "       BatchNorm-204          [-1, 2048, 24, 8]           4,096\n",
            "        Identity-205          [-1, 2048, 24, 8]               0\n",
            "            ReLU-206          [-1, 2048, 24, 8]               0\n",
            "      Bottleneck-207          [-1, 2048, 24, 8]               0\n",
            "          Conv2d-208           [-1, 512, 24, 8]       1,048,576\n",
            "       BatchNorm-209           [-1, 512, 24, 8]           1,024\n",
            "            ReLU-210           [-1, 512, 24, 8]               0\n",
            "          Conv2d-211           [-1, 512, 24, 8]       2,359,296\n",
            "       BatchNorm-212           [-1, 512, 24, 8]           1,024\n",
            "            ReLU-213           [-1, 512, 24, 8]               0\n",
            "          Conv2d-214          [-1, 2048, 24, 8]       1,048,576\n",
            "       BatchNorm-215          [-1, 2048, 24, 8]           4,096\n",
            "        Identity-216          [-1, 2048, 24, 8]               0\n",
            "            ReLU-217          [-1, 2048, 24, 8]               0\n",
            "      Bottleneck-218          [-1, 2048, 24, 8]               0\n",
            "          ResNet-219          [-1, 2048, 24, 8]               0\n",
            "GeneralizedMeanPoolingP-220           [-1, 2048, 1, 1]               0\n",
            "       BatchNorm-221           [-1, 2048, 1, 1]           4,096\n",
            "   EmbeddingHead-222                 [-1, 2048]               0\n",
            "================================================================\n",
            "Total params: 23,540,815\n",
            "Trainable params: 23,540,815\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.56\n",
            "Forward/backward pass size (MB): 403.22\n",
            "Params size (MB): 89.80\n",
            "Estimated Total Size (MB): 493.58\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# build model light"
      ],
      "metadata": {
        "id": "qPTI4I8hD2Wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd light-reid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vx8bwaCB4jZ",
        "outputId": "8e90e67a-4742-42ae-a005-ace5224bfbb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/light-reid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightreid.models import build_model\n",
        "import torch"
      ],
      "metadata": {
        "id": "gc4wSqCrP77W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1qoudw_ibDltNu6MwHDhDEH7oEVYyypaX\n",
        "!unzip resnet18-ibn.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjiZ2ddJp3S5",
        "outputId": "24c59a5a-0631-413a-9536-63b81b652cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qoudw_ibDltNu6MwHDhDEH7oEVYyypaX\n",
            "To: /content/light-reid/resnet18-ibn.zip\n",
            "100% 86.3M/86.3M [00:01<00:00, 66.2MB/s]\n",
            "Archive:  resnet18-ibn.zip\n",
            "   creating: content/light-reid/results/market/resnet18-ibn/\n",
            "  inflating: content/light-reid/results/market/resnet18-ibn/base_config_market_res18ibna.yaml  \n",
            "  inflating: content/light-reid/results/market/resnet18-ibn/model_120.pth  \n",
            "  inflating: content/light-reid/results/market/resnet18-ibn/logging.txt  \n",
            "  inflating: content/light-reid/results/market/resnet18-ibn/final_model.pth.tar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1Q7C5mLtWGQTozYrsF-iMOr7Gg2h_BpZi\n",
        "!unzip res50.zip -d light-reid"
      ],
      "metadata": {
        "id": "YQwpis-0XkWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6d13b4-e50e-4235-cfe6-777b40d52491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Q7C5mLtWGQTozYrsF-iMOr7Gg2h_BpZi\n",
            "To: /content/res50.zip\n",
            "100% 187M/187M [00:03<00:00, 54.8MB/s]\n",
            "Archive:  res50.zip\n",
            "replace light-reid/results/market/resnet50/model_120.pth? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: light-reid/results/market/resnet50/model_120.pth  \n",
            "  inflating: light-reid/results/market/resnet50/logging.txt  \n",
            "  inflating: light-reid/results/market/resnet50/final_model.pth.tar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1--_8dgN28g3B46szMWDnOKSC4YrlAxxw\n",
        "!unzip resnet34-ibn.zip #-d light-reid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rkMSoJeBaVB",
        "outputId": "e173c44b-1313-424a-b9ca-edc99093957a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1--_8dgN28g3B46szMWDnOKSC4YrlAxxw\n",
            "To: /content/light-reid/resnet34-ibn.zip\n",
            "100% 157M/157M [00:00<00:00, 255MB/s]\n",
            "Archive:  resnet34-ibn.zip\n",
            "   creating: content/light-reid/results/market/resnet34-ibn/\n",
            "  inflating: content/light-reid/results/market/resnet34-ibn/base_config_market_res34ibna.yaml  \n",
            "  inflating: content/light-reid/results/market/resnet34-ibn/model_120.pth  \n",
            "  inflating: content/light-reid/results/market/resnet34-ibn/logging.txt  \n",
            "  inflating: content/light-reid/results/market/resnet34-ibn/final_model.pth.tar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1U0mLqpA3HiG2hTCyz05QNMAKkw3-_KaE\n",
        "!unzip res34-gem.zip #-d light-reid"
      ],
      "metadata": {
        "id": "B_EJKNjOKwRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "703574b0-3872-40a9-fdb7-4ce3ef4d2372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1U0mLqpA3HiG2hTCyz05QNMAKkw3-_KaE\n",
            "To: /content/light-reid/res34-gem.zip\n",
            "100% 157M/157M [00:00<00:00, 169MB/s]\n",
            "Archive:  res34-gem.zip\n",
            "   creating: content/light-reid/results/market/resnet34-gem/\n",
            "  inflating: content/light-reid/results/market/resnet34-gem/base_config_market_res50.yaml  \n",
            "  inflating: content/light-reid/results/market/resnet34-gem/final_model.pth.tar  \n",
            "  inflating: content/light-reid/results/market/resnet34-gem/model_120.pth  \n",
            "  inflating: content/light-reid/results/market/resnet34-gem/logging.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown 1Eg5fGawu0r0w6SfFD_LItoBEIvD8X___\n",
        "# !unzip res18_cosine.zip -d ../"
      ],
      "metadata": {
        "id": "ezEYd-7_XESG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from easydict import EasyDict as edict\n",
        "import yaml\n",
        "\n",
        "\n",
        "# config_file = \"/content/light-reid/content/light-reid/results/market/resnet34-gem/base_config_market_res50.yaml\"\n",
        "# config_file = \"/content/light-reid/results/market/resnet34-ibn/base_config_market_res34ibna.yaml\"\n",
        "# config_file = \"/content/light-reid/content/light-reid/results/market/resnet34-ibn/base_config_market_res34ibna.yaml\"\n",
        "\n",
        "\n",
        "# config_file = \"/content/light-reid/content/light-reid/results/market/resnet18-ibn/base_config_market_res18ibna.yaml\"\n",
        "config_file = \"/content/light-reid/examples/bagtricks_buildwithconfigs/configs/base_config_market_res18.yaml\"\n",
        "# config_file = \"/content/light-reid/examples/bagtricks_buildwithconfigs/configs/base_config_market_res50.yaml\"\n",
        "\n",
        "# load configs from yaml file\n",
        "with open(config_file) as file:\n",
        "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
        "\n",
        "# cfg\n",
        "cfg = edict(config) # model architecture and env params\n",
        "\n",
        "# classifier is never used during the inference stage\n",
        "cfg.model.head.class_num = 751 # (need for proper weights load)"
      ],
      "metadata": {
        "id": "0edfuZccD4vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "model = build_model(**cfg.model)\n",
        "print(cfg['model'])\n",
        "\n",
        "print(f\"parallel: {cfg['env']['data_parallel']}\")\n",
        "if cfg['env']['data_parallel']:\n",
        "    model = torch.nn.DataParallel(model)\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    cfg['env']['use_gpu'] = False\n",
        "\n",
        "print(f\"gpu: {cfg['env']['use_gpu']}\")\n",
        "if cfg['env']['use_gpu']:\n",
        "    device = torch.device('cuda')\n",
        "    print(\"cuda used\")\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "3wcu1ajJD4ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b31a35-2b93-4be1-fdeb-ee808fdbd3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 198MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'backbone': {'name': 'resnet18', 'last_stride_one': True, 'pretrained': True}, 'pooling': {'name': 'avgpool'}, 'head': {'name': 'bnhead', 'classifier': {'name': 'linear', 'in_dim': 512, 'out_dim': 751}, 'class_num': 751}}\n",
            "parallel: True\n",
            "gpu: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_path = \"content/light-reid/results/market/resnet34-ibn/model_120.pth\"\n",
        "# model_path = \"/content/light-reid/results/market/resnet50/model_120.pth\"\n",
        "model_path = \"results/market/resnet18_lightfeat/model_120.pth\"\n",
        "# model_path = \"/content/light-reid/content/light-reid/results/market/resnet34-gem/model_120.pth\"\n",
        "# model_path = \"/content/light-reid/content/light-reid/results/market/resnet18-ibn/model_120.pth\"\n",
        "\n",
        "state_dict = torch.load(model_path, map_location='cpu') # ['module']\n",
        "model.load_state_dict(state_dict, strict=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "samxHOF0KFYw",
        "outputId": "5a110cf0-5d98-43bb-e973-1c550ef82769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# summary\n"
      ],
      "metadata": {
        "id": "dmct_Y6CQAQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcpi1tVTU5Hu",
        "outputId": "e1092ade-cc15-4471-ecd4-ff439a6c09f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from thop import profile"
      ],
      "metadata": {
        "id": "BTWwJHL9U-U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = ...  # Twój model PyTorch\n",
        "input_size = (1,3,256,128)  # Rozmiar wejściowych danych do modelu\n",
        "input_data = torch.rand(input_size)  # Przykładowe dane wejściowe\n",
        "\n",
        "model = model.eval()\n",
        "flops, params = profile(model, inputs=(input_data,))\n",
        "print(f\"FLOPS: {flops}\")\n",
        "print(f\"FLOPS: {params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgpbk6SvXN2Z",
        "outputId": "21a18f74-f98f-47f7-abc0-1febfcbbc2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "FLOPS: 1997344256.0\n",
            "FLOPS: 11177536.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = ...  # Twój model PyTorch\n",
        "input_size = (1,3,256,128)  # Rozmiar wejściowych danych do modelu\n",
        "input_data = torch.rand(input_size)  # Przykładowe dane wejściowe\n",
        "\n",
        "model = model.eval()\n",
        "flops, params = profile(model, inputs=(input_data,))\n",
        "print(f\"FLOPS: {flops}\")\n",
        "print(f\"FLOPS: {params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1N7y_maVAoK",
        "outputId": "7579641a-68b1-403d-bc24-31853a9ebbd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "FLOPS: 12260112384.0\n",
            "FLOPS: 23512128.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.eval().to(device)\n",
        "\n",
        "summary(model, (3,256, 128)) #r50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs1_OyPsELcv",
        "outputId": "22840192-b3e8-4b2d-d7ee-c07ef8d62e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "return only bn in head\n",
            "return arch res\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "       BatchNorm2d-2          [-1, 64, 128, 64]             128\n",
            "         MaxPool2d-3           [-1, 64, 64, 32]               0\n",
            "              ReLU-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 64, 32]             128\n",
            "              ReLU-7           [-1, 64, 64, 32]               0\n",
            "            Conv2d-8           [-1, 64, 64, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 64, 32]             128\n",
            "             ReLU-10           [-1, 64, 64, 32]               0\n",
            "           Conv2d-11          [-1, 256, 64, 32]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 64, 32]             512\n",
            "           Conv2d-13          [-1, 256, 64, 32]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 64, 32]             512\n",
            "             ReLU-15          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-16          [-1, 256, 64, 32]               0\n",
            "           Conv2d-17           [-1, 64, 64, 32]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 64, 32]             128\n",
            "             ReLU-19           [-1, 64, 64, 32]               0\n",
            "           Conv2d-20           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 64, 32]             128\n",
            "             ReLU-22           [-1, 64, 64, 32]               0\n",
            "           Conv2d-23          [-1, 256, 64, 32]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 64, 32]             512\n",
            "             ReLU-25          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-26          [-1, 256, 64, 32]               0\n",
            "           Conv2d-27           [-1, 64, 64, 32]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 64, 32]             128\n",
            "             ReLU-29           [-1, 64, 64, 32]               0\n",
            "           Conv2d-30           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 64, 32]             128\n",
            "             ReLU-32           [-1, 64, 64, 32]               0\n",
            "           Conv2d-33          [-1, 256, 64, 32]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 64, 32]             512\n",
            "             ReLU-35          [-1, 256, 64, 32]               0\n",
            "       Bottleneck-36          [-1, 256, 64, 32]               0\n",
            "           Conv2d-37          [-1, 128, 64, 32]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 64, 32]             256\n",
            "             ReLU-39          [-1, 128, 64, 32]               0\n",
            "           Conv2d-40          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 32, 16]             256\n",
            "             ReLU-42          [-1, 128, 32, 16]               0\n",
            "           Conv2d-43          [-1, 512, 32, 16]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 32, 16]           1,024\n",
            "           Conv2d-45          [-1, 512, 32, 16]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-47          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-48          [-1, 512, 32, 16]               0\n",
            "           Conv2d-49          [-1, 128, 32, 16]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 32, 16]             256\n",
            "             ReLU-51          [-1, 128, 32, 16]               0\n",
            "           Conv2d-52          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 32, 16]             256\n",
            "             ReLU-54          [-1, 128, 32, 16]               0\n",
            "           Conv2d-55          [-1, 512, 32, 16]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-57          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-58          [-1, 512, 32, 16]               0\n",
            "           Conv2d-59          [-1, 128, 32, 16]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 32, 16]             256\n",
            "             ReLU-61          [-1, 128, 32, 16]               0\n",
            "           Conv2d-62          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 32, 16]             256\n",
            "             ReLU-64          [-1, 128, 32, 16]               0\n",
            "           Conv2d-65          [-1, 512, 32, 16]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-67          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-68          [-1, 512, 32, 16]               0\n",
            "           Conv2d-69          [-1, 128, 32, 16]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 32, 16]             256\n",
            "             ReLU-71          [-1, 128, 32, 16]               0\n",
            "           Conv2d-72          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 32, 16]             256\n",
            "             ReLU-74          [-1, 128, 32, 16]               0\n",
            "           Conv2d-75          [-1, 512, 32, 16]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 32, 16]           1,024\n",
            "             ReLU-77          [-1, 512, 32, 16]               0\n",
            "       Bottleneck-78          [-1, 512, 32, 16]               0\n",
            "           Conv2d-79          [-1, 256, 32, 16]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 32, 16]             512\n",
            "             ReLU-81          [-1, 256, 32, 16]               0\n",
            "           Conv2d-82           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-83           [-1, 256, 16, 8]             512\n",
            "             ReLU-84           [-1, 256, 16, 8]               0\n",
            "           Conv2d-85          [-1, 1024, 16, 8]         262,144\n",
            "      BatchNorm2d-86          [-1, 1024, 16, 8]           2,048\n",
            "           Conv2d-87          [-1, 1024, 16, 8]         524,288\n",
            "      BatchNorm2d-88          [-1, 1024, 16, 8]           2,048\n",
            "             ReLU-89          [-1, 1024, 16, 8]               0\n",
            "       Bottleneck-90          [-1, 1024, 16, 8]               0\n",
            "           Conv2d-91           [-1, 256, 16, 8]         262,144\n",
            "      BatchNorm2d-92           [-1, 256, 16, 8]             512\n",
            "             ReLU-93           [-1, 256, 16, 8]               0\n",
            "           Conv2d-94           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-95           [-1, 256, 16, 8]             512\n",
            "             ReLU-96           [-1, 256, 16, 8]               0\n",
            "           Conv2d-97          [-1, 1024, 16, 8]         262,144\n",
            "      BatchNorm2d-98          [-1, 1024, 16, 8]           2,048\n",
            "             ReLU-99          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-100          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-101           [-1, 256, 16, 8]         262,144\n",
            "     BatchNorm2d-102           [-1, 256, 16, 8]             512\n",
            "            ReLU-103           [-1, 256, 16, 8]               0\n",
            "          Conv2d-104           [-1, 256, 16, 8]         589,824\n",
            "     BatchNorm2d-105           [-1, 256, 16, 8]             512\n",
            "            ReLU-106           [-1, 256, 16, 8]               0\n",
            "          Conv2d-107          [-1, 1024, 16, 8]         262,144\n",
            "     BatchNorm2d-108          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-109          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-110          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-111           [-1, 256, 16, 8]         262,144\n",
            "     BatchNorm2d-112           [-1, 256, 16, 8]             512\n",
            "            ReLU-113           [-1, 256, 16, 8]               0\n",
            "          Conv2d-114           [-1, 256, 16, 8]         589,824\n",
            "     BatchNorm2d-115           [-1, 256, 16, 8]             512\n",
            "            ReLU-116           [-1, 256, 16, 8]               0\n",
            "          Conv2d-117          [-1, 1024, 16, 8]         262,144\n",
            "     BatchNorm2d-118          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-119          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-120          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-121           [-1, 256, 16, 8]         262,144\n",
            "     BatchNorm2d-122           [-1, 256, 16, 8]             512\n",
            "            ReLU-123           [-1, 256, 16, 8]               0\n",
            "          Conv2d-124           [-1, 256, 16, 8]         589,824\n",
            "     BatchNorm2d-125           [-1, 256, 16, 8]             512\n",
            "            ReLU-126           [-1, 256, 16, 8]               0\n",
            "          Conv2d-127          [-1, 1024, 16, 8]         262,144\n",
            "     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-129          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-130          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-131           [-1, 256, 16, 8]         262,144\n",
            "     BatchNorm2d-132           [-1, 256, 16, 8]             512\n",
            "            ReLU-133           [-1, 256, 16, 8]               0\n",
            "          Conv2d-134           [-1, 256, 16, 8]         589,824\n",
            "     BatchNorm2d-135           [-1, 256, 16, 8]             512\n",
            "            ReLU-136           [-1, 256, 16, 8]               0\n",
            "          Conv2d-137          [-1, 1024, 16, 8]         262,144\n",
            "     BatchNorm2d-138          [-1, 1024, 16, 8]           2,048\n",
            "            ReLU-139          [-1, 1024, 16, 8]               0\n",
            "      Bottleneck-140          [-1, 1024, 16, 8]               0\n",
            "          Conv2d-141           [-1, 512, 16, 8]         524,288\n",
            "     BatchNorm2d-142           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-143           [-1, 512, 16, 8]               0\n",
            "          Conv2d-144           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-145           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-146           [-1, 512, 16, 8]               0\n",
            "          Conv2d-147          [-1, 2048, 16, 8]       1,048,576\n",
            "     BatchNorm2d-148          [-1, 2048, 16, 8]           4,096\n",
            "          Conv2d-149          [-1, 2048, 16, 8]       2,097,152\n",
            "     BatchNorm2d-150          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-151          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-152          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-153           [-1, 512, 16, 8]       1,048,576\n",
            "     BatchNorm2d-154           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-155           [-1, 512, 16, 8]               0\n",
            "          Conv2d-156           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-157           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-158           [-1, 512, 16, 8]               0\n",
            "          Conv2d-159          [-1, 2048, 16, 8]       1,048,576\n",
            "     BatchNorm2d-160          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-161          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-162          [-1, 2048, 16, 8]               0\n",
            "          Conv2d-163           [-1, 512, 16, 8]       1,048,576\n",
            "     BatchNorm2d-164           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-165           [-1, 512, 16, 8]               0\n",
            "          Conv2d-166           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-167           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-168           [-1, 512, 16, 8]               0\n",
            "          Conv2d-169          [-1, 2048, 16, 8]       1,048,576\n",
            "     BatchNorm2d-170          [-1, 2048, 16, 8]           4,096\n",
            "            ReLU-171          [-1, 2048, 16, 8]               0\n",
            "      Bottleneck-172          [-1, 2048, 16, 8]               0\n",
            "          ResNet-173          [-1, 2048, 16, 8]               0\n",
            "AdaptiveAvgPool2d-174           [-1, 2048, 1, 1]               0\n",
            "     BatchNorm1d-175                 [-1, 2048]           4,096\n",
            "          BNHead-176                 [-1, 2048]               0\n",
            "   BaseReIDModel-177                 [-1, 2048]               0\n",
            "================================================================\n",
            "Total params: 23,512,128\n",
            "Trainable params: 23,512,128\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 212.81\n",
            "Params size (MB): 89.69\n",
            "Estimated Total Size (MB): 302.88\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.eval().to(device)\n",
        "\n",
        "summary(model, (3,256, 128)) #r18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxGoncQ4D_Ae",
        "outputId": "e5b0a82e-85bd-4c13-dc55-351f186dd962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "return only bn in head\n",
            "return arch res\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "       BatchNorm2d-2          [-1, 64, 128, 64]             128\n",
            "         MaxPool2d-3           [-1, 64, 64, 32]               0\n",
            "              ReLU-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 64, 32]             128\n",
            "              ReLU-7           [-1, 64, 64, 32]               0\n",
            "            Conv2d-8           [-1, 64, 64, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 64, 32]             128\n",
            "             ReLU-10           [-1, 64, 64, 32]               0\n",
            "       BasicBlock-11           [-1, 64, 64, 32]               0\n",
            "           Conv2d-12           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 64, 32]             128\n",
            "             ReLU-14           [-1, 64, 64, 32]               0\n",
            "           Conv2d-15           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 64, 32]             128\n",
            "             ReLU-17           [-1, 64, 64, 32]               0\n",
            "       BasicBlock-18           [-1, 64, 64, 32]               0\n",
            "           Conv2d-19          [-1, 128, 32, 16]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 32, 16]             256\n",
            "             ReLU-21          [-1, 128, 32, 16]               0\n",
            "           Conv2d-22          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 32, 16]             256\n",
            "           Conv2d-24          [-1, 128, 32, 16]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 32, 16]             256\n",
            "             ReLU-26          [-1, 128, 32, 16]               0\n",
            "       BasicBlock-27          [-1, 128, 32, 16]               0\n",
            "           Conv2d-28          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 32, 16]             256\n",
            "             ReLU-30          [-1, 128, 32, 16]               0\n",
            "           Conv2d-31          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 32, 16]             256\n",
            "             ReLU-33          [-1, 128, 32, 16]               0\n",
            "       BasicBlock-34          [-1, 128, 32, 16]               0\n",
            "           Conv2d-35           [-1, 256, 16, 8]         294,912\n",
            "      BatchNorm2d-36           [-1, 256, 16, 8]             512\n",
            "             ReLU-37           [-1, 256, 16, 8]               0\n",
            "           Conv2d-38           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-39           [-1, 256, 16, 8]             512\n",
            "           Conv2d-40           [-1, 256, 16, 8]          32,768\n",
            "      BatchNorm2d-41           [-1, 256, 16, 8]             512\n",
            "             ReLU-42           [-1, 256, 16, 8]               0\n",
            "       BasicBlock-43           [-1, 256, 16, 8]               0\n",
            "           Conv2d-44           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-45           [-1, 256, 16, 8]             512\n",
            "             ReLU-46           [-1, 256, 16, 8]               0\n",
            "           Conv2d-47           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-48           [-1, 256, 16, 8]             512\n",
            "             ReLU-49           [-1, 256, 16, 8]               0\n",
            "       BasicBlock-50           [-1, 256, 16, 8]               0\n",
            "           Conv2d-51           [-1, 512, 16, 8]       1,179,648\n",
            "      BatchNorm2d-52           [-1, 512, 16, 8]           1,024\n",
            "             ReLU-53           [-1, 512, 16, 8]               0\n",
            "           Conv2d-54           [-1, 512, 16, 8]       2,359,296\n",
            "      BatchNorm2d-55           [-1, 512, 16, 8]           1,024\n",
            "           Conv2d-56           [-1, 512, 16, 8]         131,072\n",
            "      BatchNorm2d-57           [-1, 512, 16, 8]           1,024\n",
            "             ReLU-58           [-1, 512, 16, 8]               0\n",
            "       BasicBlock-59           [-1, 512, 16, 8]               0\n",
            "           Conv2d-60           [-1, 512, 16, 8]       2,359,296\n",
            "      BatchNorm2d-61           [-1, 512, 16, 8]           1,024\n",
            "             ReLU-62           [-1, 512, 16, 8]               0\n",
            "           Conv2d-63           [-1, 512, 16, 8]       2,359,296\n",
            "      BatchNorm2d-64           [-1, 512, 16, 8]           1,024\n",
            "             ReLU-65           [-1, 512, 16, 8]               0\n",
            "       BasicBlock-66           [-1, 512, 16, 8]               0\n",
            "           ResNet-67           [-1, 512, 16, 8]               0\n",
            "AdaptiveAvgPool2d-68            [-1, 512, 1, 1]               0\n",
            "      BatchNorm1d-69                  [-1, 512]           1,024\n",
            "           BNHead-70                  [-1, 512]               0\n",
            "    BaseReIDModel-71                  [-1, 512]               0\n",
            "================================================================\n",
            "Total params: 11,177,536\n",
            "Trainable params: 11,177,536\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 44.52\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 87.53\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.eval().to(device)\n",
        "# r34\n",
        "summary(model, (3,256, 128)) #r34ibn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjuQ6LSSDv-A",
        "outputId": "0c67b810-b2a0-474f-aaa6-c0c420e7c1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "return only bn in head\n",
            "return arch res\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "       BatchNorm2d-2          [-1, 64, 128, 64]             128\n",
            "         MaxPool2d-3           [-1, 64, 64, 32]               0\n",
            "              ReLU-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]          36,864\n",
            "    InstanceNorm2d-6           [-1, 32, 64, 32]              64\n",
            "       BatchNorm2d-7           [-1, 32, 64, 32]              64\n",
            "               IBN-8           [-1, 64, 64, 32]               0\n",
            "              ReLU-9           [-1, 64, 64, 32]               0\n",
            "           Conv2d-10           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 64, 32]             128\n",
            "             ReLU-12           [-1, 64, 64, 32]               0\n",
            "   BasicBlock_IBN-13           [-1, 64, 64, 32]               0\n",
            "           Conv2d-14           [-1, 64, 64, 32]          36,864\n",
            "   InstanceNorm2d-15           [-1, 32, 64, 32]              64\n",
            "      BatchNorm2d-16           [-1, 32, 64, 32]              64\n",
            "              IBN-17           [-1, 64, 64, 32]               0\n",
            "             ReLU-18           [-1, 64, 64, 32]               0\n",
            "           Conv2d-19           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-20           [-1, 64, 64, 32]             128\n",
            "             ReLU-21           [-1, 64, 64, 32]               0\n",
            "   BasicBlock_IBN-22           [-1, 64, 64, 32]               0\n",
            "           Conv2d-23           [-1, 64, 64, 32]          36,864\n",
            "   InstanceNorm2d-24           [-1, 32, 64, 32]              64\n",
            "      BatchNorm2d-25           [-1, 32, 64, 32]              64\n",
            "              IBN-26           [-1, 64, 64, 32]               0\n",
            "             ReLU-27           [-1, 64, 64, 32]               0\n",
            "           Conv2d-28           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-29           [-1, 64, 64, 32]             128\n",
            "             ReLU-30           [-1, 64, 64, 32]               0\n",
            "   BasicBlock_IBN-31           [-1, 64, 64, 32]               0\n",
            "           Conv2d-32          [-1, 128, 32, 16]          73,728\n",
            "   InstanceNorm2d-33           [-1, 64, 32, 16]             128\n",
            "      BatchNorm2d-34           [-1, 64, 32, 16]             128\n",
            "              IBN-35          [-1, 128, 32, 16]               0\n",
            "             ReLU-36          [-1, 128, 32, 16]               0\n",
            "           Conv2d-37          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-38          [-1, 128, 32, 16]             256\n",
            "           Conv2d-39          [-1, 128, 32, 16]           8,192\n",
            "      BatchNorm2d-40          [-1, 128, 32, 16]             256\n",
            "             ReLU-41          [-1, 128, 32, 16]               0\n",
            "   BasicBlock_IBN-42          [-1, 128, 32, 16]               0\n",
            "           Conv2d-43          [-1, 128, 32, 16]         147,456\n",
            "   InstanceNorm2d-44           [-1, 64, 32, 16]             128\n",
            "      BatchNorm2d-45           [-1, 64, 32, 16]             128\n",
            "              IBN-46          [-1, 128, 32, 16]               0\n",
            "             ReLU-47          [-1, 128, 32, 16]               0\n",
            "           Conv2d-48          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-49          [-1, 128, 32, 16]             256\n",
            "             ReLU-50          [-1, 128, 32, 16]               0\n",
            "   BasicBlock_IBN-51          [-1, 128, 32, 16]               0\n",
            "           Conv2d-52          [-1, 128, 32, 16]         147,456\n",
            "   InstanceNorm2d-53           [-1, 64, 32, 16]             128\n",
            "      BatchNorm2d-54           [-1, 64, 32, 16]             128\n",
            "              IBN-55          [-1, 128, 32, 16]               0\n",
            "             ReLU-56          [-1, 128, 32, 16]               0\n",
            "           Conv2d-57          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-58          [-1, 128, 32, 16]             256\n",
            "             ReLU-59          [-1, 128, 32, 16]               0\n",
            "   BasicBlock_IBN-60          [-1, 128, 32, 16]               0\n",
            "           Conv2d-61          [-1, 128, 32, 16]         147,456\n",
            "   InstanceNorm2d-62           [-1, 64, 32, 16]             128\n",
            "      BatchNorm2d-63           [-1, 64, 32, 16]             128\n",
            "              IBN-64          [-1, 128, 32, 16]               0\n",
            "             ReLU-65          [-1, 128, 32, 16]               0\n",
            "           Conv2d-66          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-67          [-1, 128, 32, 16]             256\n",
            "             ReLU-68          [-1, 128, 32, 16]               0\n",
            "   BasicBlock_IBN-69          [-1, 128, 32, 16]               0\n",
            "           Conv2d-70           [-1, 256, 16, 8]         294,912\n",
            "   InstanceNorm2d-71           [-1, 128, 16, 8]             256\n",
            "      BatchNorm2d-72           [-1, 128, 16, 8]             256\n",
            "              IBN-73           [-1, 256, 16, 8]               0\n",
            "             ReLU-74           [-1, 256, 16, 8]               0\n",
            "           Conv2d-75           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-76           [-1, 256, 16, 8]             512\n",
            "           Conv2d-77           [-1, 256, 16, 8]          32,768\n",
            "      BatchNorm2d-78           [-1, 256, 16, 8]             512\n",
            "             ReLU-79           [-1, 256, 16, 8]               0\n",
            "   BasicBlock_IBN-80           [-1, 256, 16, 8]               0\n",
            "           Conv2d-81           [-1, 256, 16, 8]         589,824\n",
            "   InstanceNorm2d-82           [-1, 128, 16, 8]             256\n",
            "      BatchNorm2d-83           [-1, 128, 16, 8]             256\n",
            "              IBN-84           [-1, 256, 16, 8]               0\n",
            "             ReLU-85           [-1, 256, 16, 8]               0\n",
            "           Conv2d-86           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-87           [-1, 256, 16, 8]             512\n",
            "             ReLU-88           [-1, 256, 16, 8]               0\n",
            "   BasicBlock_IBN-89           [-1, 256, 16, 8]               0\n",
            "           Conv2d-90           [-1, 256, 16, 8]         589,824\n",
            "   InstanceNorm2d-91           [-1, 128, 16, 8]             256\n",
            "      BatchNorm2d-92           [-1, 128, 16, 8]             256\n",
            "              IBN-93           [-1, 256, 16, 8]               0\n",
            "             ReLU-94           [-1, 256, 16, 8]               0\n",
            "           Conv2d-95           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-96           [-1, 256, 16, 8]             512\n",
            "             ReLU-97           [-1, 256, 16, 8]               0\n",
            "   BasicBlock_IBN-98           [-1, 256, 16, 8]               0\n",
            "           Conv2d-99           [-1, 256, 16, 8]         589,824\n",
            "  InstanceNorm2d-100           [-1, 128, 16, 8]             256\n",
            "     BatchNorm2d-101           [-1, 128, 16, 8]             256\n",
            "             IBN-102           [-1, 256, 16, 8]               0\n",
            "            ReLU-103           [-1, 256, 16, 8]               0\n",
            "          Conv2d-104           [-1, 256, 16, 8]         589,824\n",
            "     BatchNorm2d-105           [-1, 256, 16, 8]             512\n",
            "            ReLU-106           [-1, 256, 16, 8]               0\n",
            "  BasicBlock_IBN-107           [-1, 256, 16, 8]               0\n",
            "          Conv2d-108           [-1, 256, 16, 8]         589,824\n",
            "  InstanceNorm2d-109           [-1, 128, 16, 8]             256\n",
            "     BatchNorm2d-110           [-1, 128, 16, 8]             256\n",
            "             IBN-111           [-1, 256, 16, 8]               0\n",
            "            ReLU-112           [-1, 256, 16, 8]               0\n",
            "          Conv2d-113           [-1, 256, 16, 8]         589,824\n",
            "     BatchNorm2d-114           [-1, 256, 16, 8]             512\n",
            "            ReLU-115           [-1, 256, 16, 8]               0\n",
            "  BasicBlock_IBN-116           [-1, 256, 16, 8]               0\n",
            "          Conv2d-117           [-1, 256, 16, 8]         589,824\n",
            "  InstanceNorm2d-118           [-1, 128, 16, 8]             256\n",
            "     BatchNorm2d-119           [-1, 128, 16, 8]             256\n",
            "             IBN-120           [-1, 256, 16, 8]               0\n",
            "            ReLU-121           [-1, 256, 16, 8]               0\n",
            "          Conv2d-122           [-1, 256, 16, 8]         589,824\n",
            "     BatchNorm2d-123           [-1, 256, 16, 8]             512\n",
            "            ReLU-124           [-1, 256, 16, 8]               0\n",
            "  BasicBlock_IBN-125           [-1, 256, 16, 8]               0\n",
            "          Conv2d-126           [-1, 512, 16, 8]       1,179,648\n",
            "     BatchNorm2d-127           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-128           [-1, 512, 16, 8]               0\n",
            "          Conv2d-129           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-130           [-1, 512, 16, 8]           1,024\n",
            "          Conv2d-131           [-1, 512, 16, 8]         131,072\n",
            "     BatchNorm2d-132           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-133           [-1, 512, 16, 8]               0\n",
            "  BasicBlock_IBN-134           [-1, 512, 16, 8]               0\n",
            "          Conv2d-135           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-136           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-137           [-1, 512, 16, 8]               0\n",
            "          Conv2d-138           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-139           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-140           [-1, 512, 16, 8]               0\n",
            "  BasicBlock_IBN-141           [-1, 512, 16, 8]               0\n",
            "          Conv2d-142           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-143           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-144           [-1, 512, 16, 8]               0\n",
            "          Conv2d-145           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-146           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-147           [-1, 512, 16, 8]               0\n",
            "  BasicBlock_IBN-148           [-1, 512, 16, 8]               0\n",
            "          ResNet-149           [-1, 512, 16, 8]               0\n",
            "GeneralizedMeanPoolingP-150            [-1, 512, 1, 1]               0\n",
            "     BatchNorm1d-151                  [-1, 512]           1,024\n",
            "          BNHead-152                  [-1, 512]               0\n",
            "   BaseReIDModel-153                  [-1, 512]               0\n",
            "================================================================\n",
            "Total params: 21,285,696\n",
            "Trainable params: 21,285,696\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 75.52\n",
            "Params size (MB): 81.20\n",
            "Estimated Total Size (MB): 157.09\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "model = model.eval().to(device)\n",
        "# r34\n",
        "summary(model, (3,256, 128)) #r34"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xci6_aB3GdOK",
        "outputId": "019e9183-0b25-4ee9-8a12-c3e600de1c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "return only bn in head\n",
            "return arch res\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "       BatchNorm2d-2          [-1, 64, 128, 64]             128\n",
            "         MaxPool2d-3           [-1, 64, 64, 32]               0\n",
            "              ReLU-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 64, 32]             128\n",
            "              ReLU-7           [-1, 64, 64, 32]               0\n",
            "            Conv2d-8           [-1, 64, 64, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 64, 32]             128\n",
            "             ReLU-10           [-1, 64, 64, 32]               0\n",
            "       BasicBlock-11           [-1, 64, 64, 32]               0\n",
            "           Conv2d-12           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 64, 32]             128\n",
            "             ReLU-14           [-1, 64, 64, 32]               0\n",
            "           Conv2d-15           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 64, 32]             128\n",
            "             ReLU-17           [-1, 64, 64, 32]               0\n",
            "       BasicBlock-18           [-1, 64, 64, 32]               0\n",
            "           Conv2d-19           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-20           [-1, 64, 64, 32]             128\n",
            "             ReLU-21           [-1, 64, 64, 32]               0\n",
            "           Conv2d-22           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-23           [-1, 64, 64, 32]             128\n",
            "             ReLU-24           [-1, 64, 64, 32]               0\n",
            "       BasicBlock-25           [-1, 64, 64, 32]               0\n",
            "           Conv2d-26          [-1, 128, 32, 16]          73,728\n",
            "      BatchNorm2d-27          [-1, 128, 32, 16]             256\n",
            "             ReLU-28          [-1, 128, 32, 16]               0\n",
            "           Conv2d-29          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-30          [-1, 128, 32, 16]             256\n",
            "           Conv2d-31          [-1, 128, 32, 16]           8,192\n",
            "      BatchNorm2d-32          [-1, 128, 32, 16]             256\n",
            "             ReLU-33          [-1, 128, 32, 16]               0\n",
            "       BasicBlock-34          [-1, 128, 32, 16]               0\n",
            "           Conv2d-35          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-36          [-1, 128, 32, 16]             256\n",
            "             ReLU-37          [-1, 128, 32, 16]               0\n",
            "           Conv2d-38          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-39          [-1, 128, 32, 16]             256\n",
            "             ReLU-40          [-1, 128, 32, 16]               0\n",
            "       BasicBlock-41          [-1, 128, 32, 16]               0\n",
            "           Conv2d-42          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-43          [-1, 128, 32, 16]             256\n",
            "             ReLU-44          [-1, 128, 32, 16]               0\n",
            "           Conv2d-45          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-46          [-1, 128, 32, 16]             256\n",
            "             ReLU-47          [-1, 128, 32, 16]               0\n",
            "       BasicBlock-48          [-1, 128, 32, 16]               0\n",
            "           Conv2d-49          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-50          [-1, 128, 32, 16]             256\n",
            "             ReLU-51          [-1, 128, 32, 16]               0\n",
            "           Conv2d-52          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 32, 16]             256\n",
            "             ReLU-54          [-1, 128, 32, 16]               0\n",
            "       BasicBlock-55          [-1, 128, 32, 16]               0\n",
            "           Conv2d-56           [-1, 256, 16, 8]         294,912\n",
            "      BatchNorm2d-57           [-1, 256, 16, 8]             512\n",
            "             ReLU-58           [-1, 256, 16, 8]               0\n",
            "           Conv2d-59           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-60           [-1, 256, 16, 8]             512\n",
            "           Conv2d-61           [-1, 256, 16, 8]          32,768\n",
            "      BatchNorm2d-62           [-1, 256, 16, 8]             512\n",
            "             ReLU-63           [-1, 256, 16, 8]               0\n",
            "       BasicBlock-64           [-1, 256, 16, 8]               0\n",
            "           Conv2d-65           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-66           [-1, 256, 16, 8]             512\n",
            "             ReLU-67           [-1, 256, 16, 8]               0\n",
            "           Conv2d-68           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-69           [-1, 256, 16, 8]             512\n",
            "             ReLU-70           [-1, 256, 16, 8]               0\n",
            "       BasicBlock-71           [-1, 256, 16, 8]               0\n",
            "           Conv2d-72           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-73           [-1, 256, 16, 8]             512\n",
            "             ReLU-74           [-1, 256, 16, 8]               0\n",
            "           Conv2d-75           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-76           [-1, 256, 16, 8]             512\n",
            "             ReLU-77           [-1, 256, 16, 8]               0\n",
            "       BasicBlock-78           [-1, 256, 16, 8]               0\n",
            "           Conv2d-79           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-80           [-1, 256, 16, 8]             512\n",
            "             ReLU-81           [-1, 256, 16, 8]               0\n",
            "           Conv2d-82           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-83           [-1, 256, 16, 8]             512\n",
            "             ReLU-84           [-1, 256, 16, 8]               0\n",
            "       BasicBlock-85           [-1, 256, 16, 8]               0\n",
            "           Conv2d-86           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-87           [-1, 256, 16, 8]             512\n",
            "             ReLU-88           [-1, 256, 16, 8]               0\n",
            "           Conv2d-89           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-90           [-1, 256, 16, 8]             512\n",
            "             ReLU-91           [-1, 256, 16, 8]               0\n",
            "       BasicBlock-92           [-1, 256, 16, 8]               0\n",
            "           Conv2d-93           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-94           [-1, 256, 16, 8]             512\n",
            "             ReLU-95           [-1, 256, 16, 8]               0\n",
            "           Conv2d-96           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-97           [-1, 256, 16, 8]             512\n",
            "             ReLU-98           [-1, 256, 16, 8]               0\n",
            "       BasicBlock-99           [-1, 256, 16, 8]               0\n",
            "          Conv2d-100           [-1, 512, 16, 8]       1,179,648\n",
            "     BatchNorm2d-101           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-102           [-1, 512, 16, 8]               0\n",
            "          Conv2d-103           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-104           [-1, 512, 16, 8]           1,024\n",
            "          Conv2d-105           [-1, 512, 16, 8]         131,072\n",
            "     BatchNorm2d-106           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-107           [-1, 512, 16, 8]               0\n",
            "      BasicBlock-108           [-1, 512, 16, 8]               0\n",
            "          Conv2d-109           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-110           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-111           [-1, 512, 16, 8]               0\n",
            "          Conv2d-112           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-113           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-114           [-1, 512, 16, 8]               0\n",
            "      BasicBlock-115           [-1, 512, 16, 8]               0\n",
            "          Conv2d-116           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-117           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-118           [-1, 512, 16, 8]               0\n",
            "          Conv2d-119           [-1, 512, 16, 8]       2,359,296\n",
            "     BatchNorm2d-120           [-1, 512, 16, 8]           1,024\n",
            "            ReLU-121           [-1, 512, 16, 8]               0\n",
            "      BasicBlock-122           [-1, 512, 16, 8]               0\n",
            "          ResNet-123           [-1, 512, 16, 8]               0\n",
            "GeneralizedMeanPoolingP-124            [-1, 512, 1, 1]               0\n",
            "     BatchNorm1d-125                  [-1, 512]           1,024\n",
            "          BNHead-126                  [-1, 512]               0\n",
            "   BaseReIDModel-127                  [-1, 512]               0\n",
            "================================================================\n",
            "Total params: 21,285,696\n",
            "Trainable params: 21,285,696\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 69.02\n",
            "Params size (MB): 81.20\n",
            "Estimated Total Size (MB): 150.59\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.eval().to(device)\n",
        "\n",
        "summary(model, (3,256, 128)) #r18ibn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_mmJghn1q1g",
        "outputId": "088787b6-90e8-40ff-8eea-6a6f98d9d879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "return only bn in head\n",
            "return arch res\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 128, 64]           9,408\n",
            "       BatchNorm2d-2          [-1, 64, 128, 64]             128\n",
            "         MaxPool2d-3           [-1, 64, 64, 32]               0\n",
            "              ReLU-4           [-1, 64, 64, 32]               0\n",
            "            Conv2d-5           [-1, 64, 64, 32]          36,864\n",
            "    InstanceNorm2d-6           [-1, 32, 64, 32]              64\n",
            "       BatchNorm2d-7           [-1, 32, 64, 32]              64\n",
            "               IBN-8           [-1, 64, 64, 32]               0\n",
            "              ReLU-9           [-1, 64, 64, 32]               0\n",
            "           Conv2d-10           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 64, 32]             128\n",
            "             ReLU-12           [-1, 64, 64, 32]               0\n",
            "   BasicBlock_IBN-13           [-1, 64, 64, 32]               0\n",
            "           Conv2d-14           [-1, 64, 64, 32]          36,864\n",
            "   InstanceNorm2d-15           [-1, 32, 64, 32]              64\n",
            "      BatchNorm2d-16           [-1, 32, 64, 32]              64\n",
            "              IBN-17           [-1, 64, 64, 32]               0\n",
            "             ReLU-18           [-1, 64, 64, 32]               0\n",
            "           Conv2d-19           [-1, 64, 64, 32]          36,864\n",
            "      BatchNorm2d-20           [-1, 64, 64, 32]             128\n",
            "             ReLU-21           [-1, 64, 64, 32]               0\n",
            "   BasicBlock_IBN-22           [-1, 64, 64, 32]               0\n",
            "           Conv2d-23          [-1, 128, 32, 16]          73,728\n",
            "   InstanceNorm2d-24           [-1, 64, 32, 16]             128\n",
            "      BatchNorm2d-25           [-1, 64, 32, 16]             128\n",
            "              IBN-26          [-1, 128, 32, 16]               0\n",
            "             ReLU-27          [-1, 128, 32, 16]               0\n",
            "           Conv2d-28          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 32, 16]             256\n",
            "           Conv2d-30          [-1, 128, 32, 16]           8,192\n",
            "      BatchNorm2d-31          [-1, 128, 32, 16]             256\n",
            "             ReLU-32          [-1, 128, 32, 16]               0\n",
            "   BasicBlock_IBN-33          [-1, 128, 32, 16]               0\n",
            "           Conv2d-34          [-1, 128, 32, 16]         147,456\n",
            "   InstanceNorm2d-35           [-1, 64, 32, 16]             128\n",
            "      BatchNorm2d-36           [-1, 64, 32, 16]             128\n",
            "              IBN-37          [-1, 128, 32, 16]               0\n",
            "             ReLU-38          [-1, 128, 32, 16]               0\n",
            "           Conv2d-39          [-1, 128, 32, 16]         147,456\n",
            "      BatchNorm2d-40          [-1, 128, 32, 16]             256\n",
            "             ReLU-41          [-1, 128, 32, 16]               0\n",
            "   BasicBlock_IBN-42          [-1, 128, 32, 16]               0\n",
            "           Conv2d-43           [-1, 256, 16, 8]         294,912\n",
            "   InstanceNorm2d-44           [-1, 128, 16, 8]             256\n",
            "      BatchNorm2d-45           [-1, 128, 16, 8]             256\n",
            "              IBN-46           [-1, 256, 16, 8]               0\n",
            "             ReLU-47           [-1, 256, 16, 8]               0\n",
            "           Conv2d-48           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-49           [-1, 256, 16, 8]             512\n",
            "           Conv2d-50           [-1, 256, 16, 8]          32,768\n",
            "      BatchNorm2d-51           [-1, 256, 16, 8]             512\n",
            "             ReLU-52           [-1, 256, 16, 8]               0\n",
            "   BasicBlock_IBN-53           [-1, 256, 16, 8]               0\n",
            "           Conv2d-54           [-1, 256, 16, 8]         589,824\n",
            "   InstanceNorm2d-55           [-1, 128, 16, 8]             256\n",
            "      BatchNorm2d-56           [-1, 128, 16, 8]             256\n",
            "              IBN-57           [-1, 256, 16, 8]               0\n",
            "             ReLU-58           [-1, 256, 16, 8]               0\n",
            "           Conv2d-59           [-1, 256, 16, 8]         589,824\n",
            "      BatchNorm2d-60           [-1, 256, 16, 8]             512\n",
            "             ReLU-61           [-1, 256, 16, 8]               0\n",
            "   BasicBlock_IBN-62           [-1, 256, 16, 8]               0\n",
            "           Conv2d-63           [-1, 512, 16, 8]       1,179,648\n",
            "      BatchNorm2d-64           [-1, 512, 16, 8]           1,024\n",
            "             ReLU-65           [-1, 512, 16, 8]               0\n",
            "           Conv2d-66           [-1, 512, 16, 8]       2,359,296\n",
            "      BatchNorm2d-67           [-1, 512, 16, 8]           1,024\n",
            "           Conv2d-68           [-1, 512, 16, 8]         131,072\n",
            "      BatchNorm2d-69           [-1, 512, 16, 8]           1,024\n",
            "             ReLU-70           [-1, 512, 16, 8]               0\n",
            "   BasicBlock_IBN-71           [-1, 512, 16, 8]               0\n",
            "           Conv2d-72           [-1, 512, 16, 8]       2,359,296\n",
            "      BatchNorm2d-73           [-1, 512, 16, 8]           1,024\n",
            "             ReLU-74           [-1, 512, 16, 8]               0\n",
            "           Conv2d-75           [-1, 512, 16, 8]       2,359,296\n",
            "      BatchNorm2d-76           [-1, 512, 16, 8]           1,024\n",
            "             ReLU-77           [-1, 512, 16, 8]               0\n",
            "   BasicBlock_IBN-78           [-1, 512, 16, 8]               0\n",
            "           ResNet-79           [-1, 512, 16, 8]               0\n",
            "GeneralizedMeanPoolingP-80            [-1, 512, 1, 1]               0\n",
            "      BatchNorm1d-81                  [-1, 512]           1,024\n",
            "           BNHead-82                  [-1, 512]               0\n",
            "    BaseReIDModel-83                  [-1, 512]               0\n",
            "================================================================\n",
            "Total params: 11,177,536\n",
            "Trainable params: 11,177,536\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 48.02\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 91.03\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def infer"
      ],
      "metadata": {
        "id": "Rnl1izc8IXty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "J9xoIo7DL_pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CatMeter:\n",
        "    '''\n",
        "    Concatenate Meter for torch.Tensor\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = None\n",
        "\n",
        "    def update(self, val):\n",
        "        if self.val is None:\n",
        "            self.val = val\n",
        "        else:\n",
        "            self.val = torch.cat([self.val, val], dim=0)\n",
        "    def get_val(self):\n",
        "        return self.val\n",
        "\n",
        "    def get_val_numpy(self):\n",
        "        return self.val.data.cpu().numpy()\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"\n",
        "    Average Meter\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        self.sum += val\n",
        "        self.count += 1\n",
        "\n",
        "    def get_val(self):\n",
        "        return self.sum / self.count"
      ],
      "metadata": {
        "id": "18t2rFYXIsON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_feats(model, loader, device=\"cuda\", batch_num=None, return_tensor=False):\n",
        "    # record avg time\n",
        "    time_meter = AverageMeter()\n",
        "\n",
        "    # record features\n",
        "    features_meter, pids_meter, camids_meter = CatMeter(), CatMeter(), CatMeter()\n",
        "\n",
        "    print(f\"batch size: {loader.batch_size}\")\n",
        "    iterator = [next(iter(loader)) for i in range(batch_num)] if batch_num else loader\n",
        "    print(f\"batch num: {len(iterator)}\")\n",
        "\n",
        "    print(f\"model to device: {device}\")\n",
        "    model = model.eval().to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            # imgs = batch['images']\n",
        "            # pids = batch['targets']\n",
        "            # cids = batch['camids']\n",
        "            imgs, pids, cids = batch\n",
        "            imgs, pids, cids = imgs.to(device), pids.to(device), cids.to(device)\n",
        "\n",
        "            if time_meter is not None:\n",
        "                torch.cuda.synchronize()\n",
        "                ts = time.time()\n",
        "\n",
        "            # extract feats\n",
        "            feats = model(imgs)\n",
        "\n",
        "            if time_meter is not None:\n",
        "                torch.cuda.synchronize()\n",
        "                time_meter.update(time.time()-ts)\n",
        "                if i%30==1: print(f\"avg so far: {time_meter.get_val()}\")\n",
        "\n",
        "            # register feats\n",
        "            if isinstance(feats, torch.Tensor):\n",
        "                features_meter.update(feats.data)\n",
        "            elif isinstance(feats, list):\n",
        "                print(\"feats returned as list\")\n",
        "                features_meter = [CatMeter() for _ in range(len(feats))]\n",
        "                for idx, feats_i in enumerate(feats):\n",
        "                    features_meter[idx].update(feats_i.data)\n",
        "            else:\n",
        "                assert 0\n",
        "\n",
        "            pids_meter.update(pids.data)\n",
        "            camids_meter.update(cids.data)\n",
        "\n",
        "\n",
        "    if isinstance(features_meter, list):\n",
        "        print(\"feats meter is list\")\n",
        "        feats = [val.get_val_numpy() for val in features_meter]\n",
        "    else:\n",
        "        if return_tensor:\n",
        "            feats = features_meter.get_val()\n",
        "            # feats = F.normalize(feats)\n",
        "            # feats = feats.cpu().numpy()\n",
        "        else:\n",
        "            feats = features_meter.get_val_numpy()\n",
        "\n",
        "\n",
        "    pids = pids_meter.get_val_numpy()\n",
        "    camids = camids_meter.get_val_numpy()\n",
        "\n",
        "\n",
        "    print(f\"\\nfeature extraction time per batch (avg): {time_meter.get_val()}s\")\n",
        "    print(f\"extracted feats: {feats.shape}\")\n",
        "    print(f\"extracted pids: {pids.shape}\")\n",
        "    print(f\"extracted cams: {camids.shape}\")\n",
        "    return feats, pids, camids"
      ],
      "metadata": {
        "id": "etUqcMLGIsgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def eval"
      ],
      "metadata": {
        "id": "xKmSPFeuNwBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics as sk_metrics"
      ],
      "metadata": {
        "id": "MpSflr7sMnNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install hexhamming  # fast hamming lib in C\n",
        "# !pip install gmpy2 # popcount/bitcount\n",
        "\n",
        "# from hexhamming import hamming_distance_bytes\n",
        "# import gmpy2"
      ],
      "metadata": {
        "id": "PbnFHi3vmKwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(query_features, query_camids, query_pids, gallery_features, gallery_camids, gallery_pids,\n",
        "             metric='cosine', mode='inter-camera', loop=1):\n",
        "        '''\n",
        "        query_features(np.ndarray): [sample_num, feat_dim]\n",
        "        query_camids(np.ndarray): [sample_num]\n",
        "        query_pids(np.ndarray): [sample_num]\n",
        "        gallery_features(np.ndarray): [sample_num, feat_dim]\n",
        "        gallery_camids(np.ndarray): [sample_num]\n",
        "        gallery_pids(np.ndarray): [sample_num]\n",
        "        '''\n",
        "        print(f\"\\n====\\nloop: {loop}\")\n",
        "        print(f\"metric: {metric}\")\n",
        "        print(f\"mode: {mode}\\n====\\n\")\n",
        "\n",
        "        '''compute distance matrix'''\n",
        "        time_s = time.time()\n",
        "        for i in range(loop):\n",
        "            if metric == 'cosine':\n",
        "                scores = cosine_dist(query_features, gallery_features)\n",
        "            elif metric == 'euclidean':\n",
        "                scores = euclidean_dist(query_features, gallery_features)\n",
        "            elif metric == 'hamming':\n",
        "                print('converting to {-1,1}...')\n",
        "                assert(query_features.min()<0)\n",
        "                assert(query_features.mean()<0.1)\n",
        "                query_features = np.sign(query_features)# --> {-1,1}\n",
        "                gallery_features = np.sign(gallery_features)\n",
        "                scores = hamming_dist(query_features, gallery_features)\n",
        "            elif metric == 'hamming_1b1':\n",
        "                print('converting to {0,1}...')\n",
        "                # assert(query_features.min()<0)\n",
        "                # assert(query_features.mean()<0.1)\n",
        "                # query_features = np.sign(query_features + 1.0) / 2.0 #[-1,1] --> {0,1}\n",
        "                # gallery_features = np.sign(gallery_features + 1.0) / 2.0\n",
        "                # scores = hamming_dist(query_features, gallery_features)\n",
        "            else:\n",
        "                assert 0, 'metric error, got {}.'.format(metric)\n",
        "        print(f\"distance time avg: {(time.time()-time_s)/loop}\")\n",
        "\n",
        "        time_s = time.time()\n",
        "        for i in range(loop):\n",
        "            rank_results = np.argsort(scores)\n",
        "        print(f\"sort time avg: {(time.time()-time_s)/loop}\")\n",
        "\n",
        "        '''evaluate every query'''\n",
        "        APs, CMC = [], []\n",
        "        for idx, data in enumerate(zip(rank_results, query_camids, query_pids)):\n",
        "            a_rank, query_camid, query_pid = data\n",
        "            ap, cmc = compute_AP(a_rank, query_camid, query_pid, gallery_camids, gallery_pids, mode)\n",
        "            APs.append(ap), CMC.append(cmc)\n",
        "\n",
        "        '''compute CMC and mAP'''\n",
        "        MAP = np.array(APs).mean()\n",
        "        min_len = min([len(cmc) for cmc in CMC])\n",
        "        CMC = [cmc[:min_len] for cmc in CMC]\n",
        "        CMC = np.mean(np.array(CMC), axis=0)\n",
        "\n",
        "        return MAP, CMC\n",
        "\n",
        "\n",
        "def compute_AP(a_rank, query_camid, query_pid, gallery_camids, gallery_pids, mode):\n",
        "    '''given a query and all galleries, compute its ap and cmc'''\n",
        "\n",
        "    if mode == 'inter-camera':\n",
        "        junk_index_1 = in1d(np.argwhere(query_pid == gallery_pids), np.argwhere(query_camid == gallery_camids))\n",
        "        junk_index_2 = np.argwhere(gallery_pids == -1)\n",
        "        junk_index = np.append(junk_index_1, junk_index_2)\n",
        "        index_wo_junk = notin1d(a_rank, junk_index)\n",
        "        good_index = in1d(np.argwhere(query_pid == gallery_pids), np.argwhere(query_camid != gallery_camids))\n",
        "    elif mode == 'intra-camera':\n",
        "        junk_index_1 = np.argwhere(query_camid != gallery_camids)\n",
        "        junk_index_2 = np.argwhere(gallery_pids == -1)\n",
        "        junk_index = np.append(junk_index_1, junk_index_2)\n",
        "        index_wo_junk = notin1d(a_rank, junk_index)\n",
        "        good_index = np.argwhere(query_pid == gallery_pids)\n",
        "        # self_junk = a_rank[0] if a_rank[0] == 1 or a_rank[0] == 0 else []# remove self\n",
        "        self_junk = a_rank[0]\n",
        "        index_wo_junk = np.delete(index_wo_junk, np.where(self_junk == index_wo_junk))\n",
        "        good_index = np.delete(good_index, np.where(self_junk == good_index))\n",
        "    elif mode == 'all':\n",
        "        junk_index = np.argwhere(gallery_pids == -1)\n",
        "        index_wo_junk = notin1d(a_rank, junk_index)\n",
        "        good_index = np.argwhere(query_pid == gallery_pids)\n",
        "        self_junk = a_rank[0] if a_rank[0] == 1 or a_rank[0] == 0 else [] # remove self if euclidean distance == 0 or cosine similarity == 1\n",
        "        index_wo_junk = np.delete(index_wo_junk, np.where(self_junk == index_wo_junk))\n",
        "        good_index = np.delete(good_index, np.where(self_junk == good_index))\n",
        "\n",
        "    # num_good = len(good_index)\n",
        "    hit = np.in1d(index_wo_junk, good_index)\n",
        "    index_hit = np.argwhere(hit == True).flatten()\n",
        "    if len(index_hit) == 0:\n",
        "        AP = 0\n",
        "        cmc = np.zeros([len(index_wo_junk)])\n",
        "    else:\n",
        "        precision = []\n",
        "        for i in range(len(index_hit)):\n",
        "            precision.append(float(i + 1) / float((index_hit[i] + 1)))\n",
        "        AP = np.mean(np.array(precision))\n",
        "        cmc = np.zeros([len(index_wo_junk)])\n",
        "        cmc[index_hit[0]:] = 1\n",
        "    return AP, cmc\n",
        "\n",
        "def in1d(array1, array2, invert=False):\n",
        "    '''\n",
        "    :param set1: np.array, 1d\n",
        "    :param set2: np.array, 1d\n",
        "    :return:\n",
        "    '''\n",
        "    mask = np.in1d(array1, array2, invert=invert)\n",
        "    return array1[mask]\n",
        "\n",
        "def notin1d(array1, array2):\n",
        "    return in1d(array1, array2, invert=True)\n",
        "\n",
        "def cosine_distance_parallel(X, Y):\n",
        "    # Normalize the vectors in X and Y\n",
        "    X_norm = X / np.linalg.norm(X, axis=1, keepdims=True)\n",
        "    Y_norm = Y / np.linalg.norm(Y, axis=1, keepdims=True)\n",
        "\n",
        "    # Compute the dot product of X_norm and Y_norm using matrix multiplication\n",
        "    dot_product = np.dot(X_norm, Y_norm.T)\n",
        "\n",
        "    # Compute the element-wise difference between the dot product and a matrix of ones\n",
        "    cosine_distance = 1 - dot_product\n",
        "    return cosine_distance\n",
        "\n",
        "def cosine_dist(x, y):\n",
        "    '''compute cosine distance between two martrix x and y with sizes (n1, d), (n2, d)'''\n",
        "    return sk_metrics.pairwise.cosine_distances(x, y)\n",
        "\n",
        "def euclidean_dist(x, y):\n",
        "    '''compute eculidean distance between two martrix x and y with sizes (n1, d), (n2, d)'''\n",
        "    return sk_metrics.pairwise.euclidean_distances(x, y)\n",
        "\n",
        "def hamming_dist(x, y):\n",
        "    '''The dot product of x and y gives us a matrix where each element\n",
        "     (i,j) represents the number of positions in which the ith and jth rows of x and y differ.\n",
        "     Then the length of the binary vector is added to this matrix and divided by 2 to obtain the Hamming distance.'''\n",
        "    assert x.shape[1] == y.shape[1]\n",
        "    code_len = x.shape[1]\n",
        "    if x.min() == 0: #{0,1} --> {-1,1}\n",
        "        print(\"xmin=0\")\n",
        "        x = (x - 0.5)*2\n",
        "        y = (y - 0.5)*2\n",
        "    return code_len - (np.matmul(x, y.transpose([1,0])) + code_len) /2.0\n",
        "    # return sk_metrics.pairwise_distances(x, y, metric=scipy_dist.hamming)\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "metadata": {
        "id": "Sp-R_aqONyQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# infer"
      ],
      "metadata": {
        "id": "PSNSF2_wN0yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV7MzIwvw7yu",
        "outputId": "cf0c05b4-a9d8-4def-eb00-54fbb0dfe4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\"\n",
        "print(f\"batch size: {gallery_loader.batch_size}\")\n",
        "iterator = [next(iter(gallery_loader)) for i in range(1)]\n",
        "print(f\"batch num: {len(iterator)}\")\n",
        "\n",
        "print(f\"model to device: {device}\")\n",
        "model = model.eval().to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(iterator):\n",
        "        # imgs = batch['images']\n",
        "        # pids = batch['targets']\n",
        "        # cids = batch['camids']\n",
        "        imgs, pids, cids = batch\n",
        "        imgs, pids, cids = imgs.to(device), pids.to(device), cids.to(device)\n",
        "\n",
        "        # if time_meter is not None:\n",
        "            # torch.cuda.synchronize()\n",
        "            # ts = time.time()\n",
        "\n",
        "        # extract feats\n",
        "        print(\"ex\")\n",
        "        feats = model(imgs)\n",
        "        print(feats.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhLApbaY_c9E",
        "outputId": "85d8f77a-9b81-45bd-90f9-aa71445daf15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size: 4\n",
            "batch num: 1\n",
            "model to device: cpu\n",
            "ex\n",
            "torch.Size([4, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "\n",
        "# query_loader = data.DataLoader(query_dataset, batch_size=64, num_workers=1, drop_last=False, shuffle=False)\n",
        "gallery_loader = data.DataLoader(gallery_dataset, batch_size=4, num_workers=1, drop_last=False, shuffle=False)"
      ],
      "metadata": {
        "id": "6NO3e0bHNtqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\") # 256\n",
        "# query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W-CFi8qLwa9F",
        "outputId": "f32c2e3b-ec4f-43f6-afd3-1399ae98942c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "batch size: 4\n",
            "batch num: 4933\n",
            "model to device: cuda\n",
            "avg so far: 0.025928735733032227\n",
            "avg so far: 0.013998247683048248\n",
            "avg so far: 0.012268935480425435\n",
            "avg so far: 0.011456717615542204\n",
            "avg so far: 0.011131308117850881\n",
            "avg so far: 0.010966876619740537\n",
            "avg so far: 0.010821935894725087\n",
            "avg so far: 0.010724141912640265\n",
            "avg so far: 0.010670180163107628\n",
            "avg so far: 0.010611853178809671\n",
            "avg so far: 0.010576564744608292\n",
            "avg so far: 0.010540320212582508\n",
            "avg so far: 0.01052549728372479\n",
            "avg so far: 0.010548037533857385\n",
            "avg so far: 0.01053017010620985\n",
            "avg so far: 0.010501632648231708\n",
            "avg so far: 0.010480042315122992\n",
            "avg so far: 0.010462429374456406\n",
            "avg so far: 0.010449678695509794\n",
            "avg so far: 0.010536117153567868\n",
            "avg so far: 0.010742507503674276\n",
            "avg so far: 0.0108505917500846\n",
            "avg so far: 0.011037756669197197\n",
            "avg so far: 0.01121804479918728\n",
            "avg so far: 0.011340382686942568\n",
            "avg so far: 0.011298777892234478\n",
            "avg so far: 0.01127165632174753\n",
            "avg so far: 0.011226691342339726\n",
            "avg so far: 0.011190672668312055\n",
            "avg so far: 0.011168059405930545\n",
            "avg so far: 0.011140536574725302\n",
            "avg so far: 0.01111349271602385\n",
            "avg so far: 0.011082219482707382\n",
            "avg so far: 0.011058593949963969\n",
            "avg so far: 0.011036512436465508\n",
            "avg so far: 0.011008750349849803\n",
            "avg so far: 0.0109876292910902\n",
            "avg so far: 0.010968223535757271\n",
            "avg so far: 0.010943815712335858\n",
            "avg so far: 0.010922558885385559\n",
            "avg so far: 0.010906795495361735\n",
            "avg so far: 0.0108867556630791\n",
            "avg so far: 0.010880555668270153\n",
            "avg so far: 0.010871183946036702\n",
            "avg so far: 0.010851682585054014\n",
            "avg so far: 0.010835866074590288\n",
            "avg so far: 0.010821665420200993\n",
            "avg so far: 0.010811644978293617\n",
            "avg so far: 0.010796990705429268\n",
            "avg so far: 0.010785776311936586\n",
            "avg so far: 0.010818945425010712\n",
            "avg so far: 0.010901105777401837\n",
            "avg so far: 0.010952388278653465\n",
            "avg so far: 0.011037988129572653\n",
            "avg so far: 0.011093810072074542\n",
            "avg so far: 0.011112887980574268\n",
            "avg so far: 0.01109855311095502\n",
            "avg so far: 0.011080085813442123\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-34e75547abc7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgallery_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_pids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_camids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-d422b5e924fc>\u001b[0m in \u001b[0;36mextract_feats\u001b[0;34m(model, loader, device, batch_num, return_tensor)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# extract feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime_meter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/light-reid/lightreid/models/architectures/base_arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, fixcnn)\u001b[0m\n\u001b[1;32m     33\u001b[0m         '''\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# cnn backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mfeats_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfixcnn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mfeats_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/light-reid/lightreid/models/backbones/resnet/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2448\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2451\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"r18-ibn\") # 256\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfQSBvLoHRSe",
        "outputId": "3fed811a-a122-47a0-e7f6-4e124d702ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r18-ibn\n",
            "batch size: 64\n",
            "batch num: 53\n",
            "model to device: cuda\n",
            "avg so far: 0.05711650848388672\n",
            "avg so far: 0.0555085614323616\n",
            "\n",
            "feature extraction time per batch (avg): 0.049429079271712396s\n",
            "extracted feats: (3368, 512)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.04141688346862793\n",
            "avg so far: 0.040514834225177765\n",
            "avg so far: 0.04573171369491085\n",
            "avg so far: 0.04487573582193126\n",
            "avg so far: 0.04363937260674649\n",
            "avg so far: 0.044667488650271765\n",
            "avg so far: 0.04486010886810638\n",
            "avg so far: 0.04512190031555464\n",
            "avg so far: 0.0454010460987564\n",
            "avg so far: 0.046367297277731055\n",
            "avg so far: 0.045822801968909255\n",
            "\n",
            "feature extraction time per batch (avg): 0.04562746668324887s\n",
            "extracted feats: (19732, 512)\n",
            "extracted pids: (19732,)\n",
            "extracted cams: (19732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"r34-ibn\") # 256\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkbJVfpcCOa2",
        "outputId": "f9d81648-1089-4b4f-e184-e034d4a7a532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r34-ibn\n",
            "batch size: 64\n",
            "batch num: 53\n",
            "model to device: cuda\n",
            "avg so far: 0.09710955619812012\n",
            "avg so far: 0.07551909983158112\n",
            "\n",
            "feature extraction time per batch (avg): 0.07252122321218815s\n",
            "extracted feats: (3368, 512)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.06996643543243408\n",
            "avg so far: 0.0709739625453949\n",
            "avg so far: 0.07206127335948329\n",
            "avg so far: 0.07127532751663872\n",
            "avg so far: 0.07110263675939842\n",
            "avg so far: 0.07125250759877656\n",
            "avg so far: 0.07108447577927139\n",
            "avg so far: 0.07103005557690027\n",
            "avg so far: 0.07109246864791743\n",
            "avg so far: 0.0708247572183609\n",
            "avg so far: 0.07074244448680751\n",
            "\n",
            "feature extraction time per batch (avg): 0.07070373794407521s\n",
            "extracted feats: (19732, 512)\n",
            "extracted pids: (19732,)\n",
            "extracted cams: (19732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"r50\") # 256\n",
        "# query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SNeUtxmz_fe-",
        "outputId": "c33639b4-910f-4ceb-a187-3ef58d24a9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r50\n",
            "batch size: 1\n",
            "batch num: 19732\n",
            "model to device: cuda\n",
            "avg so far: 0.013696908950805664\n",
            "avg so far: 0.010541871190071106\n",
            "avg so far: 0.010269276557430145\n",
            "avg so far: 0.01019824328629867\n",
            "avg so far: 0.010055608436709544\n",
            "avg so far: 0.009937691061120284\n",
            "avg so far: 0.009952927683735941\n",
            "avg so far: 0.00994739442501428\n",
            "avg so far: 0.009916155791479694\n",
            "avg so far: 0.00988893473849577\n",
            "avg so far: 0.00984698652431665\n",
            "avg so far: 0.009827641119439918\n",
            "avg so far: 0.009840727511031851\n",
            "avg so far: 0.009879282542637416\n",
            "avg so far: 0.010000416452850776\n",
            "avg so far: 0.0100966818564761\n",
            "avg so far: 0.010185978719307674\n",
            "avg so far: 0.010261579882353544\n",
            "avg so far: 0.010412495514563528\n",
            "avg so far: 0.01055325578142713\n",
            "avg so far: 0.010695134286468608\n",
            "avg so far: 0.010669723341736612\n",
            "avg so far: 0.010634239346599291\n",
            "avg so far: 0.010608430542697797\n",
            "avg so far: 0.010570251050087884\n",
            "avg so far: 0.010526163463896893\n",
            "avg so far: 0.010487095779165283\n",
            "avg so far: 0.01044462731319108\n",
            "avg so far: 0.010435480403220568\n",
            "avg so far: 0.010408900473095955\n",
            "avg so far: 0.010386145564246337\n",
            "avg so far: 0.01037576679508062\n",
            "avg so far: 0.01034868358326553\n",
            "avg so far: 0.010342707797404259\n",
            "avg so far: 0.010328678002329488\n",
            "avg so far: 0.010314707293709875\n",
            "avg so far: 0.010298635073818693\n",
            "avg so far: 0.01028144080861867\n",
            "avg so far: 0.010259885086487137\n",
            "avg so far: 0.0102515007041827\n",
            "avg so far: 0.010230048722316342\n",
            "avg so far: 0.010217717715672084\n",
            "avg so far: 0.01020424641822295\n",
            "avg so far: 0.010188390411459625\n",
            "avg so far: 0.01017444974175019\n",
            "avg so far: 0.0101637713302522\n",
            "avg so far: 0.01015273517189081\n",
            "avg so far: 0.010143837746412154\n",
            "avg so far: 0.01014899430427075\n",
            "avg so far: 0.010165079132370327\n",
            "avg so far: 0.010180986356163787\n",
            "avg so far: 0.010211661963798982\n",
            "avg so far: 0.01023642201735024\n",
            "avg so far: 0.010280180965835726\n",
            "avg so far: 0.010338706241142\n",
            "avg so far: 0.01037552498154721\n",
            "avg so far: 0.010368381896001972\n",
            "avg so far: 0.010363914420671552\n",
            "avg so far: 0.010354048485870886\n",
            "avg so far: 0.01034193275744436\n",
            "avg so far: 0.010330577140113754\n",
            "avg so far: 0.010320582894779188\n",
            "avg so far: 0.010309541007757956\n",
            "avg so far: 0.010302882995968389\n",
            "avg so far: 0.010293903137469019\n",
            "avg so far: 0.01028471085868898\n",
            "avg so far: 0.010281052526864707\n",
            "avg so far: 0.010271407145392113\n",
            "avg so far: 0.010258886302720087\n",
            "avg so far: 0.010248994965350765\n",
            "avg so far: 0.010238792190769534\n",
            "avg so far: 0.010234348993140359\n",
            "avg so far: 0.010223975785896802\n",
            "avg so far: 0.010218260605839918\n",
            "avg so far: 0.010219807242832132\n",
            "avg so far: 0.010216734337340876\n",
            "avg so far: 0.010212014162362823\n",
            "avg so far: 0.010205787564643938\n",
            "avg so far: 0.010199084330785996\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-30e8e3e76b7b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"r50\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgallery_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_pids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_camids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-d422b5e924fc>\u001b[0m in \u001b[0;36mextract_feats\u001b[0;34m(model, loader, device, batch_num, return_tensor)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# extract feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime_meter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/light-reid/lightreid/models/architectures/base_arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, fixcnn)\u001b[0m\n\u001b[1;32m     33\u001b[0m         '''\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# cnn backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mfeats_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfixcnn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mfeats_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/light-reid/lightreid/models/backbones/resnet/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/light-reid/lightreid/models/backbones/resnet/resnet_ibn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/light-reid/lightreid/models/backbones/resnet/resnet_ibn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2448\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2451\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"sbs50\") # 384\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "0yYrGPF4-dhU",
        "outputId": "93e4a892-c0d5-451a-bbfc-5c900651b39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sbs50\n",
            "batch size: 64\n",
            "batch num: 53\n",
            "model to device: cuda\n",
            "avg so far: 0.24795448780059814\n",
            "avg so far: 0.23252172023057938\n",
            "\n",
            "feature extraction time per batch (avg): 0.23206625344618312s\n",
            "extracted feats: (3368, 2048)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.2336055040359497\n",
            "avg so far: 0.2399265244603157\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-21c8e8ae8781>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sbs50\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mquery_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_pids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_camids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgallery_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_pids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_camids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-d422b5e924fc>\u001b[0m in \u001b[0;36mextract_feats\u001b[0;34m(model, loader, device, batch_num, return_tensor)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime_meter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mtime_meter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"avg so far: {time_meter.get_val()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36msynchronize\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_synchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"sbs50ibn\") # 256\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8bJYsei5gMw",
        "outputId": "6f7a59a5-378b-45d0-d5b6-f2dec17ec461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sbs50\n",
            "batch size: 64\n",
            "batch num: 53\n",
            "model to device: cuda\n",
            "avg so far: 0.4031931161880493\n",
            "avg so far: 0.23035725951194763\n",
            "\n",
            "feature extraction time per batch (avg): 0.23424100875854492s\n",
            "extracted feats: (3368, 2048)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.3575756549835205\n",
            "avg so far: 0.2334204465150833\n",
            "avg so far: 0.23823065527023807\n",
            "avg so far: 0.23327252398366513\n",
            "avg so far: 0.2320687497248415\n",
            "avg so far: 0.23354790242094742\n",
            "avg so far: 0.22787881159520412\n",
            "avg so far: 0.22706769322449305\n",
            "avg so far: 0.2285027819231522\n",
            "avg so far: 0.22888082879431107\n",
            "avg so far: 0.2254814998993021\n",
            "\n",
            "feature extraction time per batch (avg): 0.22992035254691412s\n",
            "extracted feats: (19732, 2048)\n",
            "extracted pids: (19732,)\n",
            "extracted cams: (19732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"r50ibn\") # 384\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05IT9dMvx6xk",
        "outputId": "03f63e73-c972-4874-8663-817f2772c039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r50ibn\n",
            "batch size: 64\n",
            "batch num: 53\n",
            "model to device: cuda\n",
            "avg so far: 0.2585134506225586\n",
            "avg so far: 0.22809476405382156\n",
            "\n",
            "feature extraction time per batch (avg): 0.22616117855287948s\n",
            "extracted feats: (3368, 2048)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.22228384017944336\n",
            "avg so far: 0.2235107272863388\n",
            "avg so far: 0.22318176684841032\n",
            "avg so far: 0.22255859167679495\n",
            "avg so far: 0.22251548532579765\n",
            "avg so far: 0.22250016896348251\n",
            "avg so far: 0.22263528488494538\n",
            "avg so far: 0.22300139125787988\n",
            "avg so far: 0.22327314723621716\n",
            "avg so far: 0.22345970395733328\n",
            "avg so far: 0.223607757233626\n",
            "\n",
            "feature extraction time per batch (avg): 0.22317308052458038s\n",
            "extracted feats: (19732, 2048)\n",
            "extracted pids: (19732,)\n",
            "extracted cams: (19732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"r50ibn\")\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZnps5zFwVGk",
        "outputId": "26453ee3-670b-4c27-c7f2-e4a9558848f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r50ibn\n",
            "batch size: 64\n",
            "batch num: 53\n",
            "model to device: cuda\n",
            "avg so far: 3.9364309310913086\n",
            "avg so far: 0.37673889845609665\n",
            "\n",
            "feature extraction time per batch (avg): 0.28218516763651147s\n",
            "extracted feats: (3368, 2048)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.14140689373016357\n",
            "avg so far: 0.14068438857793808\n",
            "avg so far: 0.14121249414259388\n",
            "avg so far: 0.14174054239107214\n",
            "avg so far: 0.14239226599208643\n",
            "avg so far: 0.14303417895969592\n",
            "avg so far: 0.1437858303824624\n",
            "avg so far: 0.14457680931631126\n",
            "avg so far: 0.14527197514683748\n",
            "avg so far: 0.14594446823877447\n",
            "avg so far: 0.14637446798236164\n",
            "\n",
            "feature extraction time per batch (avg): 0.14620118079447825s\n",
            "extracted feats: (19732, 2048)\n",
            "extracted pids: (19732,)\n",
            "extracted cams: (19732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"r50sbs\")\n",
        "# query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ltpfIzEKVfi9",
        "outputId": "0df3c4e5-990a-4b45-8b36-1d2cdcf70f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r50sbs\n",
            "batch size: 4\n",
            "batch num: 4933\n",
            "model to device: cuda\n",
            "avg so far: 0.03880465030670166\n",
            "avg so far: 0.02205853909254074\n",
            "avg so far: 0.020737448046284336\n",
            "avg so far: 0.020284375418787418\n",
            "avg so far: 0.01989526240552058\n",
            "avg so far: 0.019709461613705282\n",
            "avg so far: 0.019515061116480565\n",
            "avg so far: 0.019423752460839612\n",
            "avg so far: 0.019312147266608626\n",
            "avg so far: 0.019264084451338825\n",
            "avg so far: 0.019188140401777052\n",
            "avg so far: 0.019119973642280304\n",
            "avg so far: 0.019070952636760903\n",
            "avg so far: 0.01902362339350642\n",
            "avg so far: 0.01899464265995116\n",
            "avg so far: 0.0190463208519252\n",
            "avg so far: 0.019233661568511078\n",
            "avg so far: 0.019449178595095873\n",
            "avg so far: 0.019581039893231268\n",
            "avg so far: 0.019574822245777904\n",
            "avg so far: 0.019550743293128538\n",
            "avg so far: 0.01953082786330694\n",
            "avg so far: 0.019500588362310587\n",
            "avg so far: 0.019493361084447432\n",
            "avg so far: 0.01946175461660792\n",
            "avg so far: 0.019442858531119975\n",
            "avg so far: 0.019411932476951034\n",
            "avg so far: 0.019385029529703075\n",
            "avg so far: 0.019359051473350253\n",
            "avg so far: 0.01933633624960523\n",
            "avg so far: 0.019324731139544638\n",
            "avg so far: 0.019322944557206314\n",
            "avg so far: 0.019333122921584796\n",
            "avg so far: 0.019338911579501246\n",
            "avg so far: 0.019444925211180446\n",
            "avg so far: 0.01953636602757095\n",
            "avg so far: 0.019623034762807343\n",
            "avg so far: 0.019594112746149518\n",
            "avg so far: 0.019579185704633777\n",
            "avg so far: 0.019559203357826727\n",
            "avg so far: 0.019545522188386583\n",
            "avg so far: 0.01952360144683293\n",
            "avg so far: 0.01950319500997214\n",
            "avg so far: 0.019480204988190263\n",
            "avg so far: 0.019456751948946725\n",
            "avg so far: 0.019453126297899956\n",
            "avg so far: 0.019438273827349917\n",
            "avg so far: 0.019418955693501588\n",
            "avg so far: 0.01940289846571077\n",
            "avg so far: 0.01938087687544201\n",
            "avg so far: 0.019362045032841547\n",
            "avg so far: 0.019355131035996478\n",
            "avg so far: 0.019400838547876335\n",
            "avg so far: 0.019434081699380924\n",
            "avg so far: 0.019474395841323343\n",
            "avg so far: 0.019461765560630447\n",
            "avg so far: 0.01943703766526847\n",
            "avg so far: 0.019420570023706025\n",
            "avg so far: 0.019401340068549978\n",
            "avg so far: 0.019389899132214065\n",
            "avg so far: 0.019371458216592023\n",
            "avg so far: 0.01935629175740038\n",
            "avg so far: 0.019342720828686315\n",
            "avg so far: 0.019329825239000058\n",
            "avg so far: 0.019320530276144703\n",
            "avg so far: 0.019312666698557433\n",
            "avg so far: 0.01930413753786674\n",
            "avg so far: 0.01929013202963008\n",
            "avg so far: 0.019280467981456193\n",
            "avg so far: 0.019276333706719533\n",
            "avg so far: 0.019295456747459753\n",
            "avg so far: 0.019318023832832893\n",
            "avg so far: 0.019350017032393915\n",
            "avg so far: 0.019336075569591382\n",
            "avg so far: 0.019320318658109403\n",
            "avg so far: 0.019313997210236678\n",
            "avg so far: 0.019305670292726427\n",
            "avg so far: 0.01929122281734506\n",
            "avg so far: 0.019281253155025022\n",
            "avg so far: 0.019277035687464285\n",
            "avg so far: 0.019272468965516102\n",
            "avg so far: 0.01925990112910145\n",
            "avg so far: 0.019253933265091054\n",
            "avg so far: 0.01924256413553155\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-af7231e3e981>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"r50sbs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgallery_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_pids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_camids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-d422b5e924fc>\u001b[0m in \u001b[0;36mextract_feats\u001b[0;34m(model, loader, device, batch_num, return_tensor)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m# imgs = batch['images']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# pids = batch['targets']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RecordFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"sbs50ibn\")\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "mtCFWAC0Rtwx",
        "outputId": "8b306c6f-b8e5-4ead-8c66-e07f5db30a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sbs50ibn\n",
            "batch size: 64\n",
            "batch num: 53\n",
            "model to device: cuda\n",
            "avg so far: 0.2523852586746216\n",
            "avg so far: 0.2329326868057251\n",
            "\n",
            "feature extraction time per batch (avg): 0.23084333707701485s\n",
            "extracted feats: (3368, 2048)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.23034286499023438\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-ce95a0296c7e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sbs50ibn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mquery_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_pids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_camids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgallery_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_pids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_camids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-d422b5e924fc>\u001b[0m in \u001b[0;36mextract_feats\u001b[0;34m(model, loader, device, batch_num, return_tensor)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime_meter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mtime_meter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"avg so far: {time_meter.get_val()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36msynchronize\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_synchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"r50ibn\")\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm9udndjQ58x",
        "outputId": "1702941e-0872-4dd2-9655-d9caaabcee28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r50ibn\n",
            "batch size: 1\n",
            "batch num: 3368\n",
            "model to device: cuda\n",
            "avg so far: 0.19410622119903564\n",
            "avg so far: 0.02375151962041855\n",
            "avg so far: 0.017337764463117047\n",
            "avg so far: 0.015309758808301844\n",
            "avg so far: 0.014109736583271965\n",
            "avg so far: 0.013418873673991152\n",
            "avg so far: 0.01292570737692026\n",
            "avg so far: 0.012546456085061128\n",
            "avg so far: 0.012273396342253882\n",
            "avg so far: 0.012054215459262623\n",
            "avg so far: 0.011939000609694727\n",
            "avg so far: 0.011792195848671787\n",
            "avg so far: 0.011700257411977864\n",
            "avg so far: 0.011591054347096657\n",
            "avg so far: 0.011507420178273277\n",
            "avg so far: 0.011444824986753211\n",
            "avg so far: 0.01139742408055982\n",
            "avg so far: 0.011450130958110094\n",
            "avg so far: 0.011506367433555011\n",
            "avg so far: 0.011539097015674297\n",
            "avg so far: 0.011554520787590762\n",
            "avg so far: 0.011631670631939851\n",
            "avg so far: 0.011687261100261954\n",
            "avg so far: 0.011643199562337357\n",
            "avg so far: 0.011591707570400924\n",
            "avg so far: 0.011552901978188373\n",
            "avg so far: 0.011507229731820733\n",
            "avg so far: 0.01146792895688212\n",
            "avg so far: 0.01143227308776203\n",
            "avg so far: 0.011395973623345752\n",
            "avg so far: 0.01135820982990138\n",
            "avg so far: 0.011326833344324464\n",
            "avg so far: 0.011306538403405965\n",
            "avg so far: 0.011283739199561457\n",
            "avg so far: 0.011275363994904461\n",
            "avg so far: 0.01127285921075045\n",
            "avg so far: 0.01125112192467709\n",
            "avg so far: 0.011224847045733774\n",
            "avg so far: 0.011205884078338143\n",
            "avg so far: 0.011179968358713613\n",
            "avg so far: 0.011156354093313614\n",
            "avg so far: 0.011141042237157946\n",
            "avg so far: 0.0111228773597681\n",
            "avg so far: 0.01111041687590419\n",
            "avg so far: 0.011110532301817647\n",
            "avg so far: 0.011091748461920833\n",
            "avg so far: 0.011075052442150419\n",
            "avg so far: 0.011058601711694647\n",
            "avg so far: 0.011081959933414539\n",
            "avg so far: 0.01110846921801567\n",
            "avg so far: 0.011136855647344882\n",
            "avg so far: 0.011161984880661528\n",
            "avg so far: 0.011207710460267207\n",
            "avg so far: 0.011243855983168636\n",
            "avg so far: 0.011232646561139314\n",
            "avg so far: 0.011221223246964646\n",
            "avg so far: 0.011205663295478232\n",
            "avg so far: 0.011190387550915512\n",
            "avg so far: 0.011175909628139982\n",
            "avg so far: 0.01115856415531167\n",
            "avg so far: 0.01114851110651014\n",
            "avg so far: 0.01113004754724461\n",
            "avg so far: 0.011114396803105045\n",
            "avg so far: 0.011106469414450905\n",
            "avg so far: 0.01109651261388201\n",
            "avg so far: 0.011091816865029882\n",
            "avg so far: 0.011073908940574115\n",
            "avg so far: 0.01106011559427614\n",
            "avg so far: 0.011050357407617522\n",
            "avg so far: 0.011041190058108002\n",
            "avg so far: 0.011031779530613225\n",
            "avg so far: 0.011022967088960573\n",
            "avg so far: 0.011011668204379016\n",
            "avg so far: 0.01100803008914864\n",
            "avg so far: 0.011000765968721049\n",
            "avg so far: 0.01099446495303464\n",
            "avg so far: 0.01099460601388729\n",
            "avg so far: 0.010983587548807006\n",
            "avg so far: 0.01097503795672644\n",
            "avg so far: 0.01098831226612625\n",
            "avg so far: 0.01100142939104625\n",
            "avg so far: 0.01100652606079453\n",
            "avg so far: 0.011039717714540558\n",
            "avg so far: 0.01106916308211668\n",
            "avg so far: 0.011084087210737647\n",
            "avg so far: 0.011073424524648063\n",
            "avg so far: 0.011066186621981383\n",
            "avg so far: 0.01106284570182812\n",
            "avg so far: 0.01105717517136625\n",
            "avg so far: 0.01105183710952005\n",
            "avg so far: 0.011044742176922756\n",
            "avg so far: 0.01103642255635073\n",
            "avg so far: 0.011031001050950479\n",
            "avg so far: 0.011023530475048076\n",
            "avg so far: 0.011018422459305642\n",
            "avg so far: 0.011017508961542459\n",
            "avg so far: 0.011008567978821224\n",
            "avg so far: 0.01100051550419776\n",
            "avg so far: 0.01099260399570115\n",
            "avg so far: 0.010989184174210355\n",
            "avg so far: 0.010983452727046511\n",
            "avg so far: 0.010975904703769331\n",
            "avg so far: 0.010968640612123217\n",
            "avg so far: 0.010963568249464343\n",
            "avg so far: 0.010958172204324941\n",
            "avg so far: 0.010956504093814018\n",
            "avg so far: 0.010949530068019289\n",
            "avg so far: 0.010942799736227223\n",
            "avg so far: 0.010936271989882397\n",
            "avg so far: 0.010929550256006292\n",
            "avg so far: 0.010936463406272256\n",
            "avg so far: 0.010939279094892961\n",
            "avg so far: 0.010947535677653988\n",
            "\n",
            "feature extraction time per batch (avg): 0.01094850515526434s\n",
            "extracted feats: (3368, 2048)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.21863007545471191\n",
            "avg so far: 0.21206773072481155\n",
            "avg so far: 0.21163793148532992\n",
            "avg so far: 0.2111889564472696\n",
            "avg so far: 0.2108439793352221\n",
            "avg so far: 0.2106246807073292\n",
            "avg so far: 0.21061933040618896\n",
            "avg so far: 0.2107631429186407\n",
            "avg so far: 0.21081285732836763\n",
            "avg so far: 0.21087667871924007\n",
            "avg so far: 0.21086377023861108\n",
            "\n",
            "feature extraction time per batch (avg): 0.21041257636060992s\n",
            "extracted feats: (19732, 2048)\n",
            "extracted pids: (19732,)\n",
            "extracted cams: (19732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"sbs50\")\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4_IGTvgOwNc",
        "outputId": "d494bba8-9a9c-479e-d1ec-723a25a0703e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sbs50\n",
            "batch size: 64\n",
            "batch num: 53\n",
            "model to device: cuda\n",
            "avg so far: 0.2657935619354248\n",
            "avg so far: 0.22497771680355072\n",
            "\n",
            "feature extraction time per batch (avg): 0.22268384807514693s\n",
            "extracted feats: (3368, 2048)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.23035621643066406\n",
            "avg so far: 0.22508013248443604\n",
            "avg so far: 0.22549973380181096\n",
            "avg so far: 0.22580700853596564\n",
            "avg so far: 0.22583236264400794\n",
            "avg so far: 0.22549638308976827\n",
            "avg so far: 0.2251254713142311\n",
            "avg so far: 0.22478655149351875\n",
            "avg so far: 0.22456579464526216\n",
            "avg so far: 0.22441156997400172\n",
            "avg so far: 0.2242275042249667\n",
            "\n",
            "feature extraction time per batch (avg): 0.2237321119092429s\n",
            "extracted feats: (19732, 2048)\n",
            "extracted pids: (19732,)\n",
            "extracted cams: (19732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"r34\")\n",
        "# query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeJCUumXeh_a",
        "outputId": "00ce7cbc-b9d7-4267-eb3a-37b3475e9e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r34\n",
            "batch size: 16\n",
            "batch num: 1234\n",
            "model to device: cuda\n",
            "avg so far: 0.052582740783691406\n",
            "avg so far: 0.02543453872203827\n",
            "avg so far: 0.0234720976121964\n",
            "avg so far: 0.02290095971978229\n",
            "avg so far: 0.022613965097020884\n",
            "avg so far: 0.022210485056826944\n",
            "avg so far: 0.022643934239397992\n",
            "avg so far: 0.023435625265229423\n",
            "avg so far: 0.02459934723278708\n",
            "avg so far: 0.02470375772784738\n",
            "avg so far: 0.024319201115740846\n",
            "avg so far: 0.023856140762926584\n",
            "avg so far: 0.02357159925429202\n",
            "avg so far: 0.023308744235914582\n",
            "avg so far: 0.022994031838331177\n",
            "avg so far: 0.022815503905304766\n",
            "avg so far: 0.022672347013386454\n",
            "avg so far: 0.02249274682253599\n",
            "avg so far: 0.022433881830025423\n",
            "avg so far: 0.02249900902901496\n",
            "avg so far: 0.022957543598060987\n",
            "avg so far: 0.02321575261369536\n",
            "avg so far: 0.02336810470707827\n",
            "avg so far: 0.023215594663785373\n",
            "avg so far: 0.023163190839033048\n",
            "avg so far: 0.02303620158357823\n",
            "avg so far: 0.02292132316647893\n",
            "avg so far: 0.0228418470016254\n",
            "avg so far: 0.022739231728035027\n",
            "avg so far: 0.02266791271507193\n",
            "avg so far: 0.022562130856143926\n",
            "avg so far: 0.02243560603759831\n",
            "avg so far: 0.022407986022330618\n",
            "avg so far: 0.022615610351485592\n",
            "avg so far: 0.023267641692712115\n",
            "avg so far: 0.023447546895465923\n",
            "avg so far: 0.023409712556990588\n",
            "avg so far: 0.023304018185293075\n",
            "avg so far: 0.02322082866094158\n",
            "avg so far: 0.02311165422302871\n",
            "avg so far: 0.02299874892052319\n",
            "avg so far: 0.02289377772188806\n",
            "\n",
            "feature extraction time per batch (avg): 0.022878489965751068s\n",
            "extracted feats: (19732, 512)\n",
            "extracted pids: (19732,)\n",
            "extracted cams: (19732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"r50\")\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ_g_z9-Yk5w",
        "outputId": "5c3bf614-9cd3-4532-c578-acb012664825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r50\n",
            "batch size: 64\n",
            "batch num: 53\n",
            "model to device: cuda\n",
            "avg so far: 0.1670619249343872\n",
            "avg so far: 0.13507118821144104\n",
            "\n",
            "feature extraction time per batch (avg): 0.13353578999357404s\n",
            "extracted feats: (3368, 2048)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.13749361038208008\n",
            "avg so far: 0.13810430467128754\n",
            "avg so far: 0.13678093494907503\n",
            "avg so far: 0.13704743074334186\n",
            "avg so far: 0.1375874984459799\n",
            "avg so far: 0.1369383382169824\n",
            "avg so far: 0.1364801021722647\n",
            "avg so far: 0.13657278947110446\n",
            "avg so far: 0.13634185554567446\n",
            "avg so far: 0.1357968361938701\n",
            "avg so far: 0.13587170010370925\n",
            "\n",
            "feature extraction time per batch (avg): 0.13549082796164702s\n",
            "extracted feats: (19732, 2048)\n",
            "extracted pids: (19732,)\n",
            "extracted cams: (19732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"r34gem\")\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju5M6uODN92_",
        "outputId": "51e42b8e-af20-45df-b2f3-3101b02bec11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r34gem\n",
            "batch size: 64\n",
            "batch num: 53\n",
            "model to device: cuda\n",
            "avg so far: 3.218201756477356\n",
            "avg so far: 0.26070665568113327\n",
            "\n",
            "feature extraction time per batch (avg): 0.18306384446485988s\n",
            "extracted feats: (3368, 512)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.06497740745544434\n",
            "avg so far: 0.06490655243396759\n",
            "avg so far: 0.06508945265123921\n",
            "avg so far: 0.06468118014542953\n",
            "avg so far: 0.06405863800986869\n",
            "avg so far: 0.06432877559410899\n",
            "avg so far: 0.06467055357419528\n",
            "avg so far: 0.0642145703423698\n",
            "avg so far: 0.0639874235657621\n",
            "avg so far: 0.06395015383467954\n",
            "avg so far: 0.06393472722034581\n",
            "\n",
            "feature extraction time per batch (avg): 0.06378001071102797s\n",
            "extracted feats: (19732, 512)\n",
            "extracted pids: (19732,)\n",
            "extracted cams: (19732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"r18\")\n",
        "query_feats, query_pids, query_camids = extract_feats(model, query_loader, return_tensor=False)\n",
        "gallery_feats, gallery_pids, gallery_camids = extract_feats(model, gallery_loader, return_tensor=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tGCSMOqY_n2",
        "outputId": "292b66b0-56c8-4014-ef8a-55d968f2407d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r18\n",
            "batch size: 64\n",
            "batch num: 53\n",
            "model to device: cuda\n",
            "avg so far: 0.06430363655090332\n",
            "avg so far: 0.04409576952457428\n",
            "\n",
            "feature extraction time per batch (avg): 0.044079924529453494s\n",
            "extracted feats: (3368, 512)\n",
            "extracted pids: (3368,)\n",
            "extracted cams: (3368,)\n",
            "batch size: 64\n",
            "batch num: 309\n",
            "model to device: cuda\n",
            "avg so far: 0.043543457984924316\n",
            "avg so far: 0.03881211578845978\n",
            "avg so far: 0.0391709650716474\n",
            "avg so far: 0.03860562521478404\n",
            "avg so far: 0.0397578556029523\n",
            "avg so far: 0.03993890787425794\n",
            "avg so far: 0.03997716798887148\n",
            "avg so far: 0.03980858370942889\n",
            "avg so far: 0.03999360435265155\n",
            "avg so far: 0.04021115425754996\n",
            "avg so far: 0.04005152500228377\n",
            "\n",
            "feature extraction time per batch (avg): 0.03991459257008574s\n",
            "extracted feats: (19732, 512)\n",
            "extracted pids: (19732,)\n",
            "extracted cams: (19732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# eval"
      ],
      "metadata": {
        "id": "aFawNt8oOode"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# r18-ibn 256\n",
        "\n",
        "for metric in [\"euclidean\", \"cosine\", \"hamming\"]:\n",
        "    for mode in [\"inter-camera\"]:\n",
        "        MAP, CMC = evaluate(\n",
        "            query_feats, query_camids, query_pids,\n",
        "            gallery_feats, gallery_camids, gallery_pids,\n",
        "            metric=metric, mode=mode, loop=1)\n",
        "        print(f'\\nmAP {MAP}, rank1: {CMC[0]}, rank5: {CMC[4]}, rank10: {CMC[9]}\\n===\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO96UrHKq9gv",
        "outputId": "3236063c-e798-4fd4-9938-01578336633f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: euclidean\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 4.242339611053467\n",
            "sort time avg: 5.270522594451904\n",
            "\n",
            "mAP 0.7924616417563951, rank1: 0.9251781472684085, rank5: 0.9723871733966746, rank10: 0.9848574821852731\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: cosine\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 1.0997254848480225\n",
            "sort time avg: 5.087620973587036\n",
            "\n",
            "mAP 0.8065070358452993, rank1: 0.9225059382422803, rank5: 0.9706057007125891, rank10: 0.9839667458432304\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: hamming\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "converting to {-1,1}...\n",
            "distance time avg: 1.0685086250305176\n",
            "sort time avg: 3.475472927093506\n",
            "\n",
            "mAP 0.7697108283156442, rank1: 0.9097387173396675, rank5: 0.9676365795724465, rank10: 0.9798099762470309\n",
            "===\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# r34-ibn 256\n",
        "\n",
        "for metric in [\"euclidean\", \"cosine\", \"hamming\"]:\n",
        "    for mode in [\"inter-camera\"]:\n",
        "        MAP, CMC = evaluate(\n",
        "            query_feats, query_camids, query_pids,\n",
        "            gallery_feats, gallery_camids, gallery_pids,\n",
        "            metric=metric, mode=mode, loop=1)\n",
        "        print(f'\\nmAP {MAP}, rank1: {CMC[0]}, rank5: {CMC[4]}, rank10: {CMC[9]}\\n===\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu4h9DZ5DYkL",
        "outputId": "529092ee-a753-4368-bd73-d4a29f79120c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: euclidean\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 3.2645883560180664\n",
            "sort time avg: 6.245826005935669\n",
            "\n",
            "mAP 0.8400261270459563, rank1: 0.9406175771971497, rank5: 0.9786223277909739, rank10: 0.9866389548693587\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: cosine\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 1.1082236766815186\n",
            "sort time avg: 5.959513902664185\n",
            "\n",
            "mAP 0.8484605961881202, rank1: 0.9376484560570071, rank5: 0.9780285035629454, rank10: 0.9860451306413301\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: hamming\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "converting to {-1,1}...\n",
            "distance time avg: 2.99619460105896\n",
            "sort time avg: 4.694507837295532\n",
            "\n",
            "mAP 0.8158082291668695, rank1: 0.9263657957244655, rank5: 0.9747624703087886, rank10: 0.9848574821852731\n",
            "===\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sbs50 256\n",
        "\n",
        "for metric in [\"euclidean\", \"cosine\", \"hamming\"]:\n",
        "    for mode in [\"inter-camera\"]:\n",
        "        MAP, CMC = evaluate(\n",
        "            query_feats, query_camids, query_pids,\n",
        "            gallery_feats, gallery_camids, gallery_pids,\n",
        "            metric=metric, mode=mode, loop=1)\n",
        "        print(f'\\nmAP {MAP}, rank1: {CMC[0]}, rank5: {CMC[4]}, rank10: {CMC[9]}\\n===\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "EcCJEDBy6wG0",
        "outputId": "948738ac-61af-4fe8-97df-f2b76404eb02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: euclidean\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 8.286629676818848\n",
            "sort time avg: 5.784104824066162\n",
            "\n",
            "mAP 0.26594306757419844, rank1: 0.5531472684085511, rank5: 0.7458432304038005, rank10: 0.8165083135391924\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: cosine\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 3.76579213142395\n",
            "sort time avg: 5.071172475814819\n",
            "\n",
            "mAP 0.25975862016214496, rank1: 0.5570071258907363, rank5: 0.7505938242280285, rank10: 0.8194774346793349\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: hamming\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "converting to {-1,1}...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-c7d28b5eb9f7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"euclidean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hamming\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"inter-camera\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         MAP, CMC = evaluate(\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mquery_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_camids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_pids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mgallery_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_camids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_pids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-1b3d0262acab>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(query_features, query_camids, query_pids, gallery_features, gallery_camids, gallery_pids, metric, mode, loop)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'converting to {-1,1}...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mquery_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# --> {-1,1}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mgallery_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgallery_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# r50ibn\n",
        "\n",
        "for metric in [\"euclidean\", \"cosine\", \"hamming\"]:\n",
        "    for mode in [\"inter-camera\"]:\n",
        "        MAP, CMC = evaluate(\n",
        "            query_feats, query_camids, query_pids,\n",
        "            gallery_feats, gallery_camids, gallery_pids,\n",
        "            metric=metric, mode=mode, loop=1)\n",
        "        print(f'\\nmAP {MAP}, rank1: {CMC[0]}, rank5: {CMC[4]}, rank10: {CMC[9]}\\n===\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkNrK3iexTxI",
        "outputId": "9c86fae9-132b-4338-9713-9486a3c1c44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: euclidean\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 9.389036178588867\n",
            "sort time avg: 5.785638809204102\n",
            "\n",
            "mAP 0.868568520741283, rank1: 0.9545724465558195, rank5: 0.9860451306413301, rank10: 0.9907957244655582\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: cosine\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 5.3629889488220215\n",
            "sort time avg: 5.146390199661255\n",
            "\n",
            "mAP 0.8826035765263968, rank1: 0.9536817102137767, rank5: 0.9866389548693587, rank10: 0.9902019002375297\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: hamming\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "converting to {-1,1}...\n",
            "distance time avg: 3.6221022605895996\n",
            "sort time avg: 4.325645923614502\n",
            "\n",
            "mAP 0.8771110289813795, rank1: 0.9519002375296912, rank5: 0.9857482185273159, rank10: 0.9910926365795725\n",
            "===\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sbs50ibn\n",
        "\n",
        "for metric in [\"euclidean\", \"cosine\", \"hamming\"]:\n",
        "    for mode in [\"inter-camera\"]:\n",
        "        MAP, CMC = evaluate(\n",
        "            query_feats, query_camids, query_pids,\n",
        "            gallery_feats, gallery_camids, gallery_pids,\n",
        "            metric=metric, mode=mode, loop=1)\n",
        "        print(f'\\nmAP {MAP}, rank1: {CMC[0]}, rank5: {CMC[4]}, rank10: {CMC[9]}\\n===\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkcNtyPqRzDa",
        "outputId": "f8103134-d8de-41d4-ded3-fbbed15baf38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: euclidean\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 9.34218978881836\n",
            "sort time avg: 5.054846286773682\n",
            "\n",
            "mAP 0.8869883001725376, rank1: 0.9569477434679335, rank5: 0.9839667458432304, rank10: 0.9907957244655582\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: cosine\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 3.596400499343872\n",
            "sort time avg: 5.460536003112793\n",
            "\n",
            "mAP 0.891437156543535, rank1: 0.9557600950118765, rank5: 0.9851543942992874, rank10: 0.9899049881235155\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: hamming\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "converting to {-1,1}...\n",
            "distance time avg: 4.287283182144165\n",
            "sort time avg: 3.93998646736145\n",
            "\n",
            "mAP 0.8818136469895226, rank1: 0.9545724465558195, rank5: 0.9836698337292161, rank10: 0.9896080760095012\n",
            "===\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# r50ibn\n",
        "\n",
        "for metric in [\"euclidean\", \"cosine\", \"hamming\"]:\n",
        "    for mode in [\"inter-camera\"]:\n",
        "        MAP, CMC = evaluate(\n",
        "            query_feats, query_camids, query_pids,\n",
        "            gallery_feats, gallery_camids, gallery_pids,\n",
        "            metric=metric, mode=mode, loop=1)\n",
        "        print(f'\\nmAP {MAP}, rank1: {CMC[0]}, rank5: {CMC[4]}, rank10: {CMC[9]}\\n===\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snqAn0oYRYLm",
        "outputId": "5e91843f-989d-429e-f12d-29b25dffc5ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: euclidean\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 9.17070198059082\n",
            "sort time avg: 5.0917322635650635\n",
            "\n",
            "mAP 0.7958614267246408, rank1: 0.9290380047505938, rank5: 0.9741686460807601, rank10: 0.982185273159145\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: cosine\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 5.8077263832092285\n",
            "sort time avg: 5.281135320663452\n",
            "\n",
            "mAP 0.8030065231307515, rank1: 0.9245843230403801, rank5: 0.9714964370546318, rank10: 0.9804038004750594\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: hamming\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "converting to {-1,1}...\n",
            "distance time avg: 3.682814359664917\n",
            "sort time avg: 4.669729471206665\n",
            "\n",
            "mAP 0.798618687915612, rank1: 0.922209026128266, rank5: 0.9726840855106889, rank10: 0.9809976247030879\n",
            "===\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sbs 50\n",
        "\n",
        "for metric in [\"euclidean\", \"cosine\", \"hamming\"]:\n",
        "    for mode in [\"inter-camera\"]:\n",
        "        MAP, CMC = evaluate(\n",
        "            query_feats, query_camids, query_pids,\n",
        "            gallery_feats, gallery_camids, gallery_pids,\n",
        "            metric=metric, mode=mode, loop=1)\n",
        "        print(f'\\nmAP {MAP}, rank1: {CMC[0]}, rank5: {CMC[4]}, rank10: {CMC[9]}\\n===\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOr5U0hAPLw5",
        "outputId": "62b0b3ff-4078-48fd-9f14-c0b8008f7598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: euclidean\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 9.698390483856201\n",
            "sort time avg: 7.95522403717041\n",
            "\n",
            "mAP 0.880309013530357, rank1: 0.9548693586698337, rank5: 0.9848574821852731, rank10: 0.9902019002375297\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: cosine\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 4.3260276317596436\n",
            "sort time avg: 4.936956405639648\n",
            "\n",
            "mAP 0.8848758257247293, rank1: 0.9513064133016627, rank5: 0.9845605700712589, rank10: 0.9893111638954869\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: hamming\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "converting to {-1,1}...\n",
            "distance time avg: 3.4381115436553955\n",
            "sort time avg: 4.473315000534058\n",
            "\n",
            "mAP 0.874914701919157, rank1: 0.9492280285035629, rank5: 0.9845605700712589, rank10: 0.9890142517814727\n",
            "===\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# r50\n",
        "\n",
        "for metric in [\"euclidean\", \"cosine\", \"hamming\"]:\n",
        "    for mode in [\"inter-camera\"]:\n",
        "        MAP, CMC = evaluate(\n",
        "            query_feats, query_camids, query_pids,\n",
        "            gallery_feats, gallery_camids, gallery_pids,\n",
        "            metric=metric, mode=mode, loop=1)\n",
        "        print(f'\\nmAP {MAP}, rank1: {CMC[0]}, rank5: {CMC[4]}, rank10: {CMC[9]}\\n===\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHkqmKs4Y6Gt",
        "outputId": "9ff7e2f7-49d9-49d9-e9cb-aab2eb2ce620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: euclidean\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 10.749228477478027\n",
            "sort time avg: 5.444883823394775\n",
            "\n",
            "mAP 0.8414414379181911, rank1: 0.9423990498812351, rank5: 0.9818883610451307, rank10: 0.9878266033254157\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: cosine\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 5.632965326309204\n",
            "sort time avg: 5.0750627517700195\n",
            "\n",
            "mAP 0.855008414643874, rank1: 0.9403206650831354, rank5: 0.9827790973871734, rank10: 0.9881235154394299\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: hamming\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "converting to {-1,1}...\n",
            "distance time avg: 3.443045139312744\n",
            "sort time avg: 3.7103545665740967\n",
            "\n",
            "mAP 0.8510599000114445, rank1: 0.9394299287410927, rank5: 0.9818883610451307, rank10: 0.9887173396674585\n",
            "===\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# r34gem\n",
        "\n",
        "for metric in [\"euclidean\", \"cosine\", \"hamming\"]:\n",
        "    for mode in [\"inter-camera\"]:\n",
        "        MAP, CMC = evaluate(\n",
        "            query_feats, query_camids, query_pids,\n",
        "            gallery_feats, gallery_camids, gallery_pids,\n",
        "            metric=metric, mode=mode, loop=1)\n",
        "        print(f'\\nmAP {MAP}, rank1: {CMC[0]}, rank5: {CMC[4]}, rank10: {CMC[9]}\\n===\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8ze72_BN_22",
        "outputId": "6951ad36-ae8d-4e84-95b7-6529e2b57d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: euclidean\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 2.935072660446167\n",
            "sort time avg: 5.45467472076416\n",
            "\n",
            "mAP 0.8148824899500912, rank1: 0.9275534441805225, rank5: 0.9703087885985748, rank10: 0.9845605700712589\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: cosine\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 1.0504302978515625\n",
            "sort time avg: 5.975067615509033\n",
            "\n",
            "mAP 0.8260703172944104, rank1: 0.9284441805225653, rank5: 0.9688242280285035, rank10: 0.9809976247030879\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: hamming\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "converting to {-1,1}...\n",
            "distance time avg: 1.920888900756836\n",
            "sort time avg: 3.4076108932495117\n",
            "\n",
            "mAP 0.7890511513777251, rank1: 0.9144893111638955, rank5: 0.9685273159144893, rank10: 0.9783254156769596\n",
            "===\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# r18?\n",
        "\n",
        "for metric in [\"euclidean\", \"cosine\", \"hamming\"]:\n",
        "    for mode in [\"inter-camera\"]:\n",
        "        MAP, CMC = evaluate(\n",
        "            query_feats, query_camids, query_pids,\n",
        "            gallery_feats, gallery_camids, gallery_pids,\n",
        "            metric=metric, mode=mode, loop=1)\n",
        "        print(f'\\nmAP {MAP}, rank1: {CMC[0]}, rank5: {CMC[4]}, rank10: {CMC[9]}\\n===\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-mrO1z6XATY",
        "outputId": "7bd9d673-350f-4e91-b6c9-79d8785ee388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: euclidean\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 2.3603785037994385\n",
            "sort time avg: 5.621717691421509\n",
            "\n",
            "mAP 0.7689637410219052, rank1: 0.9097387173396675, rank5: 0.9714964370546318, rank10: 0.9815914489311164\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: cosine\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "distance time avg: 2.43491268157959\n",
            "sort time avg: 5.303782224655151\n",
            "\n",
            "mAP 0.7856343935564581, rank1: 0.916270783847981, rank5: 0.9747624703087886, rank10: 0.9845605700712589\n",
            "===\n",
            "\n",
            "\n",
            "====\n",
            "loop: 1\n",
            "metric: hamming\n",
            "mode: inter-camera\n",
            "====\n",
            "\n",
            "converting to {-1,1}...\n",
            "distance time avg: 1.022209882736206\n",
            "sort time avg: 3.26345157623291\n",
            "\n",
            "mAP 0.7453947882610286, rank1: 0.8969714964370546, rank5: 0.9637767220902613, rank10: 0.9809976247030879\n",
            "===\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w_rEqGKUZL7S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}